{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-30T23:02:48.038403Z",
     "iopub.status.busy": "2022-06-30T23:02:48.038182Z",
     "iopub.status.idle": "2022-06-30T23:03:43.653796Z",
     "shell.execute_reply": "2022-06-30T23:03:43.652933Z",
     "shell.execute_reply.started": "2022-06-30T23:02:48.038379Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torch\n",
      "  Downloading torch-1.12.0-cp37-cp37m-manylinux1_x86_64.whl (776.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 776.3 MB 8.6 kB/s s eta 0:00:01     |██████████████████████████████▋ | 742.9 MB 114.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting transformers\n",
      "  Downloading transformers-4.20.1-py3-none-any.whl (4.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.4 MB 85.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pandas in /mnt/notebook-env/lib/python3.7/site-packages (1.3.5)\n",
      "Collecting datasets\n",
      "  Downloading datasets-2.3.2-py3-none-any.whl (362 kB)\n",
      "\u001b[K     |████████████████████████████████| 362 kB 97.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting accelerate\n",
      "  Downloading accelerate-0.10.0-py3-none-any.whl (117 kB)\n",
      "\u001b[K     |████████████████████████████████| 117 kB 112.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn in /mnt/notebook-env/lib/python3.7/site-packages (1.0.2)\n",
      "Collecting mlflow\n",
      "  Downloading mlflow-1.27.0-py3-none-any.whl (17.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 17.9 MB 98.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: ray[all] in /mnt/notebook-env/lib/python3.7/site-packages (1.13.0)\n",
      "Collecting tensorboard\n",
      "  Downloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.8 MB 79.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /mnt/notebook-env/lib/python3.7/site-packages (from torch) (4.1.1)\n",
      "Requirement already satisfied: importlib-metadata in /mnt/notebook-env/lib/python3.7/site-packages (from transformers) (4.8.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /mnt/notebook-env/lib/python3.7/site-packages (from transformers) (1.21.2)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2022.6.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (749 kB)\n",
      "\u001b[K     |████████████████████████████████| 749 kB 91.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /mnt/notebook-env/lib/python3.7/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /mnt/notebook-env/lib/python3.7/site-packages (from transformers) (4.63.0)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0\n",
      "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
      "\u001b[K     |████████████████████████████████| 101 kB 26.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: filelock in /mnt/notebook-env/lib/python3.7/site-packages (from transformers) (3.7.1)\n",
      "Requirement already satisfied: requests in /mnt/notebook-env/lib/python3.7/site-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /mnt/notebook-env/lib/python3.7/site-packages (from transformers) (21.3)\n",
      "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
      "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.6 MB 76.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /mnt/notebook-env/lib/python3.7/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /mnt/notebook-env/lib/python3.7/site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /mnt/notebook-env/lib/python3.7/site-packages (from datasets) (6.0.1)\n",
      "Collecting responses<0.19\n",
      "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Collecting dill<0.3.6\n",
      "  Downloading dill-0.3.5.1-py2.py3-none-any.whl (95 kB)\n",
      "\u001b[K     |████████████████████████████████| 95 kB 4.1 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.05.0 in /mnt/notebook-env/lib/python3.7/site-packages (from datasets) (2022.5.0)\n",
      "Collecting multiprocess\n",
      "  Downloading multiprocess-0.70.13-py37-none-any.whl (115 kB)\n",
      "\u001b[K     |████████████████████████████████| 115 kB 102.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting xxhash\n",
      "  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
      "\u001b[K     |████████████████████████████████| 212 kB 82.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: aiohttp in /mnt/notebook-env/lib/python3.7/site-packages (from datasets) (3.8.1)\n",
      "Requirement already satisfied: psutil in /mnt/notebook-env/lib/python3.7/site-packages (from accelerate) (5.9.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /mnt/notebook-env/lib/python3.7/site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /mnt/notebook-env/lib/python3.7/site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /mnt/notebook-env/lib/python3.7/site-packages (from scikit-learn) (1.7.3)\n",
      "Collecting gunicorn\n",
      "  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
      "\u001b[K     |████████████████████████████████| 79 kB 15.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting gitpython>=2.1.0\n",
      "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
      "\u001b[K     |████████████████████████████████| 181 kB 115.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting Flask\n",
      "  Downloading Flask-2.1.2-py3-none-any.whl (95 kB)\n",
      "\u001b[K     |████████████████████████████████| 95 kB 11.4 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: entrypoints in /mnt/notebook-env/lib/python3.7/site-packages (from mlflow) (0.3)\n",
      "Collecting databricks-cli>=0.8.7\n",
      "  Downloading databricks-cli-0.17.0.tar.gz (81 kB)\n",
      "\u001b[K     |████████████████████████████████| 81 kB 20.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: docker>=4.0.0 in /mnt/notebook-env/lib/python3.7/site-packages (from mlflow) (4.4.1)\n",
      "Collecting sqlalchemy>=1.4.0\n",
      "  Downloading SQLAlchemy-1.4.39-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 52.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: cloudpickle in /mnt/notebook-env/lib/python3.7/site-packages (from mlflow) (2.1.0)\n",
      "Collecting sqlparse>=0.3.1\n",
      "  Downloading sqlparse-0.4.2-py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 3.1 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting prometheus-flask-exporter\n",
      "  Downloading prometheus_flask_exporter-0.20.2-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /mnt/notebook-env/lib/python3.7/site-packages (from mlflow) (3.20.1)\n",
      "Requirement already satisfied: click>=7.0 in /mnt/notebook-env/lib/python3.7/site-packages (from mlflow) (8.0.4)\n",
      "Collecting alembic\n",
      "  Downloading alembic-1.8.0-py3-none-any.whl (209 kB)\n",
      "\u001b[K     |████████████████████████████████| 209 kB 99.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting querystring-parser\n",
      "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
      "Requirement already satisfied: jsonschema in /mnt/notebook-env/lib/python3.7/site-packages (from ray[all]) (3.2.0)\n",
      "Requirement already satisfied: grpcio<=1.43.0,>=1.28.1 in /mnt/notebook-env/lib/python3.7/site-packages (from ray[all]) (1.43.0)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /mnt/notebook-env/lib/python3.7/site-packages (from ray[all]) (1.0.4)\n",
      "Requirement already satisfied: frozenlist in /mnt/notebook-env/lib/python3.7/site-packages (from ray[all]) (1.2.0)\n",
      "Requirement already satisfied: aiosignal in /mnt/notebook-env/lib/python3.7/site-packages (from ray[all]) (1.2.0)\n",
      "Requirement already satisfied: virtualenv in /mnt/notebook-env/lib/python3.7/site-packages (from ray[all]) (20.15.1)\n",
      "Requirement already satisfied: attrs in /mnt/notebook-env/lib/python3.7/site-packages (from ray[all]) (21.4.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp==1.1.0 in /mnt/notebook-env/lib/python3.7/site-packages (from ray[all]) (1.1.0)\n",
      "Requirement already satisfied: uvicorn==0.16.0 in /mnt/notebook-env/lib/python3.7/site-packages (from ray[all]) (0.16.0)\n",
      "Requirement already satisfied: colorful in /mnt/notebook-env/lib/python3.7/site-packages (from ray[all]) (0.5.4)\n",
      "Requirement already satisfied: py-spy>=0.2.0 in /mnt/notebook-env/lib/python3.7/site-packages (from ray[all]) (0.3.12)\n",
      "Requirement already satisfied: aiohttp-cors in /mnt/notebook-env/lib/python3.7/site-packages (from ray[all]) (0.7.0)\n",
      "Requirement already satisfied: opentelemetry-sdk==1.1.0 in /mnt/notebook-env/lib/python3.7/site-packages (from ray[all]) (1.1.0)\n",
      "Requirement already satisfied: aiorwlock in /mnt/notebook-env/lib/python3.7/site-packages (from ray[all]) (1.3.0)\n",
      "Requirement already satisfied: prometheus-client<0.14.0,>=0.7.1 in /mnt/notebook-env/lib/python3.7/site-packages (from ray[all]) (0.13.1)\n",
      "Requirement already satisfied: opencensus in /mnt/notebook-env/lib/python3.7/site-packages (from ray[all]) (0.9.0)\n",
      "Requirement already satisfied: kopf in /mnt/notebook-env/lib/python3.7/site-packages (from ray[all]) (1.35.5)\n",
      "Requirement already satisfied: gym<0.22 in /mnt/notebook-env/lib/python3.7/site-packages (from ray[all]) (0.21.0)\n",
      "Requirement already satisfied: matplotlib!=3.4.3 in /mnt/notebook-env/lib/python3.7/site-packages (from ray[all]) (3.5.2)\n",
      "Requirement already satisfied: lz4 in /mnt/notebook-env/lib/python3.7/site-packages (from ray[all]) (4.0.1)\n",
      "Requirement already satisfied: smart-open in /mnt/notebook-env/lib/python3.7/site-packages (from ray[all]) (6.0.0)\n",
      "Requirement already satisfied: kubernetes in /mnt/notebook-env/lib/python3.7/site-packages (from ray[all]) (17.17.0)\n",
      "Requirement already satisfied: gpustat>=1.0.0b1 in /mnt/notebook-env/lib/python3.7/site-packages (from ray[all]) (1.0.0b1)\n",
      "Requirement already satisfied: urllib3 in /mnt/notebook-env/lib/python3.7/site-packages (from ray[all]) (1.25.11)\n",
      "Requirement already satisfied: starlette in /mnt/notebook-env/lib/python3.7/site-packages (from ray[all]) (0.19.1)\n",
      "Requirement already satisfied: scikit-image in /mnt/notebook-env/lib/python3.7/site-packages (from ray[all]) (0.19.3)\n",
      "Requirement already satisfied: tensorboardX>=1.9 in /mnt/notebook-env/lib/python3.7/site-packages (from ray[all]) (2.5.1)\n",
      "Requirement already satisfied: dm-tree in /mnt/notebook-env/lib/python3.7/site-packages (from ray[all]) (0.1.7)\n",
      "Requirement already satisfied: ray-cpp==1.13.0 in /mnt/notebook-env/lib/python3.7/site-packages (from ray[all]) (1.13.0)\n",
      "Requirement already satisfied: opentelemetry-api==1.1.0 in /mnt/notebook-env/lib/python3.7/site-packages (from ray[all]) (1.1.0)\n",
      "Requirement already satisfied: tabulate in /mnt/notebook-env/lib/python3.7/site-packages (from ray[all]) (0.8.10)\n",
      "Requirement already satisfied: fastapi in /mnt/notebook-env/lib/python3.7/site-packages (from ray[all]) (0.78.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc==1.1.0 in /mnt/notebook-env/lib/python3.7/site-packages (from opentelemetry-exporter-otlp==1.1.0->ray[all]) (1.1.0)\n",
      "Requirement already satisfied: backoff~=1.10.0 in /mnt/notebook-env/lib/python3.7/site-packages (from opentelemetry-exporter-otlp-proto-grpc==1.1.0->opentelemetry-exporter-otlp==1.1.0->ray[all]) (1.10.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /mnt/notebook-env/lib/python3.7/site-packages (from opentelemetry-exporter-otlp-proto-grpc==1.1.0->opentelemetry-exporter-otlp==1.1.0->ray[all]) (1.56.3)\n",
      "Requirement already satisfied: opentelemetry-proto==1.1.0 in /mnt/notebook-env/lib/python3.7/site-packages (from opentelemetry-exporter-otlp-proto-grpc==1.1.0->opentelemetry-exporter-otlp==1.1.0->ray[all]) (1.1.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.20b0 in /mnt/notebook-env/lib/python3.7/site-packages (from opentelemetry-sdk==1.1.0->ray[all]) (0.20b0)\n",
      "Requirement already satisfied: h11>=0.8 in /mnt/notebook-env/lib/python3.7/site-packages (from uvicorn==0.16.0->ray[all]) (0.13.0)\n",
      "Requirement already satisfied: asgiref>=3.4.0 in /mnt/notebook-env/lib/python3.7/site-packages (from uvicorn==0.16.0->ray[all]) (3.5.2)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /mnt/notebook-env/lib/python3.7/site-packages (from tensorboard) (58.0.4)\n",
      "Collecting absl-py>=0.4\n",
      "  Downloading absl_py-1.1.0-py3-none-any.whl (123 kB)\n",
      "\u001b[K     |████████████████████████████████| 123 kB 72.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: google-auth<3,>=1.6.3 in /mnt/notebook-env/lib/python3.7/site-packages (from tensorboard) (2.6.0)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.7-py3-none-any.whl (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 19.3 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /mnt/notebook-env/lib/python3.7/site-packages (from tensorboard) (0.37.1)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.9 MB 81.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting werkzeug>=1.0.1\n",
      "  Downloading Werkzeug-2.1.2-py3-none-any.whl (224 kB)\n",
      "\u001b[K     |████████████████████████████████| 224 kB 76.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting protobuf>=3.12.0\n",
      "  Downloading protobuf-3.19.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 64.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "\u001b[K     |████████████████████████████████| 781 kB 71.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /mnt/notebook-env/lib/python3.7/site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /mnt/notebook-env/lib/python3.7/site-packages (from aiohttp->datasets) (4.0.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /mnt/notebook-env/lib/python3.7/site-packages (from aiohttp->datasets) (1.6.3)\n",
      "Requirement already satisfied: asynctest==0.13.0 in /mnt/notebook-env/lib/python3.7/site-packages (from aiohttp->datasets) (0.13.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /mnt/notebook-env/lib/python3.7/site-packages (from aiohttp->datasets) (5.2.0)\n",
      "Requirement already satisfied: pyjwt>=1.7.0 in /mnt/notebook-env/lib/python3.7/site-packages (from databricks-cli>=0.8.7->mlflow) (2.1.0)\n",
      "Requirement already satisfied: oauthlib>=3.1.0 in /mnt/notebook-env/lib/python3.7/site-packages (from databricks-cli>=0.8.7->mlflow) (3.2.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /mnt/notebook-env/lib/python3.7/site-packages (from databricks-cli>=0.8.7->mlflow) (1.16.0)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in /mnt/notebook-env/lib/python3.7/site-packages (from docker>=4.0.0->mlflow) (0.58.0)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
      "\u001b[K     |████████████████████████████████| 63 kB 4.9 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /mnt/notebook-env/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /mnt/notebook-env/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /mnt/notebook-env/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /mnt/notebook-env/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.0)\n",
      "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /mnt/notebook-env/lib/python3.7/site-packages (from gpustat>=1.0.0b1->ray[all]) (7.352.0)\n",
      "Requirement already satisfied: blessed>=1.17.1 in /mnt/notebook-env/lib/python3.7/site-packages (from gpustat>=1.0.0b1->ray[all]) (1.19.1)\n",
      "Requirement already satisfied: wcwidth>=0.1.4 in /mnt/notebook-env/lib/python3.7/site-packages (from blessed>=1.17.1->gpustat>=1.0.0b1->ray[all]) (0.2.5)\n",
      "Requirement already satisfied: zipp>=0.5 in /mnt/notebook-env/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.7.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /mnt/notebook-env/lib/python3.7/site-packages (from matplotlib!=3.4.3->ray[all]) (9.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /mnt/notebook-env/lib/python3.7/site-packages (from matplotlib!=3.4.3->ray[all]) (3.0.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /mnt/notebook-env/lib/python3.7/site-packages (from matplotlib!=3.4.3->ray[all]) (4.33.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /mnt/notebook-env/lib/python3.7/site-packages (from matplotlib!=3.4.3->ray[all]) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /mnt/notebook-env/lib/python3.7/site-packages (from matplotlib!=3.4.3->ray[all]) (1.4.3)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /mnt/notebook-env/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /mnt/notebook-env/lib/python3.7/site-packages (from requests->transformers) (2022.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /mnt/notebook-env/lib/python3.7/site-packages (from requests->transformers) (3.3)\n",
      "Collecting greenlet!=0.4.17\n",
      "  Downloading greenlet-1.1.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (150 kB)\n",
      "\u001b[K     |████████████████████████████████| 150 kB 104.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting Mako\n",
      "  Downloading Mako-1.2.1-py3-none-any.whl (78 kB)\n",
      "\u001b[K     |████████████████████████████████| 78 kB 18.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting importlib-resources\n",
      "  Downloading importlib_resources-5.8.0-py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2 in /mnt/notebook-env/lib/python3.7/site-packages (from fastapi->ray[all]) (1.9.1)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /mnt/notebook-env/lib/python3.7/site-packages (from starlette->ray[all]) (3.6.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /mnt/notebook-env/lib/python3.7/site-packages (from anyio<5,>=3.4.0->starlette->ray[all]) (1.2.0)\n",
      "Collecting itsdangerous>=2.0\n",
      "  Downloading itsdangerous-2.1.2-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: Jinja2>=3.0 in /mnt/notebook-env/lib/python3.7/site-packages (from Flask->mlflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /mnt/notebook-env/lib/python3.7/site-packages (from Jinja2>=3.0->Flask->mlflow) (2.0.1)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /mnt/notebook-env/lib/python3.7/site-packages (from jsonschema->ray[all]) (0.18.0)\n",
      "Requirement already satisfied: iso8601 in /mnt/notebook-env/lib/python3.7/site-packages (from kopf->ray[all]) (1.0.2)\n",
      "Requirement already satisfied: python-json-logger in /mnt/notebook-env/lib/python3.7/site-packages (from kopf->ray[all]) (2.0.2)\n",
      "Requirement already satisfied: opencensus-context>=0.1.2 in /mnt/notebook-env/lib/python3.7/site-packages (from opencensus->ray[all]) (0.1.2)\n",
      "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /mnt/notebook-env/lib/python3.7/site-packages (from opencensus->ray[all]) (2.8.2)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /mnt/notebook-env/lib/python3.7/site-packages (from scikit-image->ray[all]) (1.3.0)\n",
      "Requirement already satisfied: networkx>=2.2 in /mnt/notebook-env/lib/python3.7/site-packages (from scikit-image->ray[all]) (2.6.3)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /mnt/notebook-env/lib/python3.7/site-packages (from scikit-image->ray[all]) (2.19.3)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /mnt/notebook-env/lib/python3.7/site-packages (from scikit-image->ray[all]) (2021.11.2)\n",
      "Requirement already satisfied: distlib<1,>=0.3.1 in /mnt/notebook-env/lib/python3.7/site-packages (from virtualenv->ray[all]) (0.3.4)\n",
      "Requirement already satisfied: platformdirs<3,>=2 in /mnt/notebook-env/lib/python3.7/site-packages (from virtualenv->ray[all]) (2.5.2)\n",
      "Building wheels for collected packages: databricks-cli\n",
      "  Building wheel for databricks-cli (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for databricks-cli: filename=databricks_cli-0.17.0-py3-none-any.whl size=141960 sha256=9782105eea2ee78415a147c145d18d84cb96ec3f90e72f85f31a311d849325b9\n",
      "  Stored in directory: /home/emr-notebook/.cache/pip/wheels/55/c3/db/33705569425fd2bdc9ea73051a8053fa26965c2bce8a146747\n",
      "Successfully built databricks-cli\n",
      "Installing collected packages: protobuf, werkzeug, smmap, itsdangerous, greenlet, sqlalchemy, Mako, importlib-resources, gitdb, Flask, dill, xxhash, torch, tokenizers, tensorboard-plugin-wit, tensorboard-data-server, sqlparse, responses, regex, querystring-parser, prometheus-flask-exporter, multiprocess, markdown, huggingface-hub, gunicorn, google-auth-oauthlib, gitpython, databricks-cli, alembic, absl-py, transformers, tensorboard, mlflow, datasets, accelerate\n",
      "\u001b[33m  WARNING: The script mako-render is installed in '/home/emr-notebook/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script flask is installed in '/home/emr-notebook/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The scripts convert-caffe2-to-onnx, convert-onnx-to-caffe2 and torchrun are installed in '/home/emr-notebook/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script sqlformat is installed in '/home/emr-notebook/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script markdown_py is installed in '/home/emr-notebook/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script huggingface-cli is installed in '/home/emr-notebook/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script gunicorn is installed in '/home/emr-notebook/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script google-oauthlib-tool is installed in '/home/emr-notebook/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The scripts databricks and dbfs are installed in '/home/emr-notebook/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script alembic is installed in '/home/emr-notebook/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script transformers-cli is installed in '/home/emr-notebook/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script tensorboard is installed in '/home/emr-notebook/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The scripts mlflow and mlp are installed in '/home/emr-notebook/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script datasets-cli is installed in '/home/emr-notebook/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The scripts accelerate, accelerate-config and accelerate-launch are installed in '/home/emr-notebook/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed Flask-2.1.2 Mako-1.2.1 absl-py-1.1.0 accelerate-0.10.0 alembic-1.8.0 databricks-cli-0.17.0 datasets-2.3.2 dill-0.3.5.1 gitdb-4.0.9 gitpython-3.1.27 google-auth-oauthlib-0.4.6 greenlet-1.1.2 gunicorn-20.1.0 huggingface-hub-0.8.1 importlib-resources-5.8.0 itsdangerous-2.1.2 markdown-3.3.7 mlflow-1.27.0 multiprocess-0.70.13 prometheus-flask-exporter-0.20.2 protobuf-3.19.4 querystring-parser-1.2.4 regex-2022.6.2 responses-0.18.0 smmap-5.0.0 sqlalchemy-1.4.39 sqlparse-0.4.2 tensorboard-2.9.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tokenizers-0.12.1 torch-1.12.0 transformers-4.20.1 werkzeug-2.1.2 xxhash-3.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch transformers pandas datasets accelerate scikit-learn mlflow tensorboard ray[all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!/emr/notebook-env/bin/python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "\n",
    "IPython.Application.instance().kernel.do_shutdown(True) #automatically restarts kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-30T23:31:18.099022Z",
     "iopub.status.busy": "2022-06-30T23:31:18.098759Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-30 23:31:22,094\tINFO trainer.py:243 -- Trainer logs will be logged in: /home/emr-notebook/ray_results/train_2022-06-30_23-31-22\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=8825, ip=172.31.25.104)\u001b[0m 2022-06-30 23:31:27,554\tINFO torch.py:347 -- Setting up process group for: env:// [rank=2, world_size=10]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=22578, ip=172.31.24.251)\u001b[0m 2022-06-30 23:31:27,553\tINFO torch.py:347 -- Setting up process group for: env:// [rank=8, world_size=10]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=22493, ip=172.31.22.253)\u001b[0m 2022-06-30 23:31:27,575\tINFO torch.py:347 -- Setting up process group for: env:// [rank=4, world_size=10]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=22499, ip=172.31.26.71)\u001b[0m 2022-06-30 23:31:27,578\tINFO torch.py:347 -- Setting up process group for: env:// [rank=0, world_size=10]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=17170)\u001b[0m 2022-06-30 23:31:27,583\tINFO torch.py:347 -- Setting up process group for: env:// [rank=9, world_size=10]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=22493, ip=172.31.20.70)\u001b[0m 2022-06-30 23:31:27,626\tINFO torch.py:347 -- Setting up process group for: env:// [rank=6, world_size=10]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=22616, ip=172.31.21.170)\u001b[0m 2022-06-30 23:31:27,556\tINFO torch.py:347 -- Setting up process group for: env:// [rank=7, world_size=10]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=9374, ip=172.31.26.25)\u001b[0m 2022-06-30 23:31:27,565\tINFO torch.py:347 -- Setting up process group for: env:// [rank=1, world_size=10]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=22546, ip=172.31.19.54)\u001b[0m 2022-06-30 23:31:27,640\tINFO torch.py:347 -- Setting up process group for: env:// [rank=3, world_size=10]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=22513, ip=172.31.26.121)\u001b[0m 2022-06-30 23:31:27,579\tINFO torch.py:347 -- Setting up process group for: env:// [rank=5, world_size=10]\n",
      "2022-06-30 23:31:28,708\tINFO trainer.py:249 -- Run results will be logged in: /home/emr-notebook/ray_results/train_2022-06-30_23-31-22/run_001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=22578, ip=172.31.24.251)\u001b[0m Downloading and preparing dataset csv/default to /home/hadoop/.cache/huggingface/datasets/csv/default-b9a4f1bc4b903808/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58...\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=22499, ip=172.31.26.71)\u001b[0m Downloading and preparing dataset csv/default to /home/hadoop/.cache/huggingface/datasets/csv/default-b9a4f1bc4b903808/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58...\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=22493, ip=172.31.20.70)\u001b[0m Downloading and preparing dataset csv/default to /home/hadoop/.cache/huggingface/datasets/csv/default-b9a4f1bc4b903808/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58...\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=22616, ip=172.31.21.170)\u001b[0m Downloading and preparing dataset csv/default to /home/hadoop/.cache/huggingface/datasets/csv/default-b9a4f1bc4b903808/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58...\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=22546, ip=172.31.19.54)\u001b[0m Downloading and preparing dataset csv/default to /home/hadoop/.cache/huggingface/datasets/csv/default-b9a4f1bc4b903808/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58...\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=22513, ip=172.31.26.121)\u001b[0m Downloading and preparing dataset csv/default to /home/hadoop/.cache/huggingface/datasets/csv/default-b9a4f1bc4b903808/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58...\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=9374, ip=172.31.26.25)\u001b[0m Downloading and preparing dataset csv/default to /home/hadoop/.cache/huggingface/datasets/csv/default-b9a4f1bc4b903808/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58...\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=8825, ip=172.31.25.104)\u001b[0m Downloading and preparing dataset csv/default to /home/hadoop/.cache/huggingface/datasets/csv/default-b9a4f1bc4b903808/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58...\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=8825, ip=172.31.25.104)\u001b[0m Dataset csv downloaded and prepared to /home/hadoop/.cache/huggingface/datasets/csv/default-b9a4f1bc4b903808/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58. Subsequent calls will reuse this data.\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=22493, ip=172.31.22.253)\u001b[0m Downloading and preparing dataset csv/default to /home/hadoop/.cache/huggingface/datasets/csv/default-b9a4f1bc4b903808/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58...\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=22493, ip=172.31.22.253)\u001b[0m Dataset csv downloaded and prepared to /home/hadoop/.cache/huggingface/datasets/csv/default-b9a4f1bc4b903808/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58. Subsequent calls will reuse this data.\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=22578, ip=172.31.24.251)\u001b[0m Dataset csv downloaded and prepared to /home/hadoop/.cache/huggingface/datasets/csv/default-b9a4f1bc4b903808/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58. Subsequent calls will reuse this data.\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=22499, ip=172.31.26.71)\u001b[0m Dataset csv downloaded and prepared to /home/hadoop/.cache/huggingface/datasets/csv/default-b9a4f1bc4b903808/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58. Subsequent calls will reuse this data.\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=22493, ip=172.31.20.70)\u001b[0m Dataset csv downloaded and prepared to /home/hadoop/.cache/huggingface/datasets/csv/default-b9a4f1bc4b903808/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58. Subsequent calls will reuse this data.\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=22616, ip=172.31.21.170)\u001b[0m Dataset csv downloaded and prepared to /home/hadoop/.cache/huggingface/datasets/csv/default-b9a4f1bc4b903808/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58. Subsequent calls will reuse this data.\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=22546, ip=172.31.19.54)\u001b[0m Dataset csv downloaded and prepared to /home/hadoop/.cache/huggingface/datasets/csv/default-b9a4f1bc4b903808/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58. Subsequent calls will reuse this data.\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=22513, ip=172.31.26.121)\u001b[0m Dataset csv downloaded and prepared to /home/hadoop/.cache/huggingface/datasets/csv/default-b9a4f1bc4b903808/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58. Subsequent calls will reuse this data.\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=9374, ip=172.31.26.25)\u001b[0m Dataset csv downloaded and prepared to /home/hadoop/.cache/huggingface/datasets/csv/default-b9a4f1bc4b903808/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 2/2 [00:00<00:00, 11507.01it/s]\n",
      "Downloading data files: 100%|██████████| 2/2 [00:00<00:00, 11765.23it/s]\n",
      "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Downloading data files: 100%|██████████| 2/2 [00:00<00:00, 11522.81it/s]\n",
      "Extracting data files: 100%|██████████| 2/2 [00:00<00:00, 1569.43it/s]\n",
      "0 tables [00:00, ? tables/s]d=22493, ip=172.31.20.70)\u001b[0m \n",
      "Downloading data files: 100%|██████████| 2/2 [00:00<00:00, 11214.72it/s]\n",
      "Extracting data files: 100%|██████████| 2/2 [00:00<00:00, 1568.84it/s]\n",
      "0 tables [00:00, ? tables/s]d=22616, ip=172.31.21.170)\u001b[0m \n",
      "Downloading data files: 100%|██████████| 2/2 [00:00<00:00, 11781.75it/s]\n",
      "Extracting data files: 100%|██████████| 2/2 [00:00<00:00, 1534.69it/s]\n",
      "0 tables [00:00, ? tables/s]d=22546, ip=172.31.19.54)\u001b[0m \n",
      "Downloading data files: 100%|██████████| 2/2 [00:00<00:00, 10837.99it/s]\n",
      "Extracting data files: 100%|██████████| 2/2 [00:00<00:00, 1500.11it/s]\n",
      "0 tables [00:00, ? tables/s]d=22513, ip=172.31.26.121)\u001b[0m \n",
      "Downloading data files: 100%|██████████| 2/2 [00:00<00:00, 10143.42it/s]\n",
      "Extracting data files: 100%|██████████| 2/2 [00:00<00:00, 1628.54it/s]\n",
      "0 tables [00:00, ? tables/s]d=9374, ip=172.31.26.25)\u001b[0m \n",
      "Downloading data files: 100%|██████████| 2/2 [00:00<00:00, 11898.73it/s]\n",
      "Extracting data files: 100%|██████████| 2/2 [00:00<00:00, 1670.04it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 916.49it/s]25.104)\u001b[0m \n",
      "Downloading data files: 100%|██████████| 2/2 [00:00<00:00, 11881.88it/s]\n",
      "Extracting data files: 100%|██████████| 2/2 [00:00<00:00, 1514.46it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 890.79it/s].22.253)\u001b[0m \n",
      "Extracting data files: 100%|██████████| 2/2 [00:00<00:00, 1542.59it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 921.02it/s].24.251)\u001b[0m \n",
      "Extracting data files: 100%|██████████| 2/2 [00:00<00:00, 1541.17it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 931.24it/s].26.71)\u001b[0m \n",
      "100%|██████████| 2/2 [00:00<00:00, 902.39it/s].20.70)\u001b[0m \n",
      "100%|██████████| 2/2 [00:00<00:00, 885.90it/s].21.170)\u001b[0m \n",
      "100%|██████████| 2/2 [00:00<00:00, 910.02it/s].19.54)\u001b[0m \n",
      "100%|██████████| 2/2 [00:00<00:00, 908.35it/s].26.121)\u001b[0m \n",
      "Downloading: 100%|██████████| 481/481 [00:00<00:00, 539kB/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 858.96it/s]26.25)\u001b[0m \n",
      "Downloading: 100%|██████████| 481/481 [00:00<00:00, 609kB/s]\n",
      "Downloading: 100%|██████████| 481/481 [00:00<00:00, 572kB/s]\n",
      "Downloading: 100%|██████████| 481/481 [00:00<00:00, 742kB/s]\n",
      "Downloading: 100%|██████████| 481/481 [00:00<00:00, 651kB/s]\n",
      "Downloading: 100%|██████████| 481/481 [00:00<00:00, 509kB/s]\n",
      "Downloading: 100%|██████████| 481/481 [00:00<00:00, 662kB/s]\n",
      "Downloading: 100%|██████████| 481/481 [00:00<00:00, 675kB/s]\n",
      "Downloading: 100%|██████████| 481/481 [00:00<00:00, 489kB/s]\n",
      "Downloading: 100%|██████████| 878k/878k [00:00<00:00, 58.9MB/s]\n",
      "Downloading: 100%|██████████| 878k/878k [00:00<00:00, 61.2MB/s]\n",
      "Downloading: 100%|██████████| 878k/878k [00:00<00:00, 57.5MB/s]\n",
      "Downloading: 100%|██████████| 878k/878k [00:00<00:00, 56.8MB/s]\n",
      "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s][0m \n",
      "Downloading: 100%|██████████| 878k/878k [00:00<00:00, 58.6MB/s]\n",
      "Downloading: 100%|██████████| 878k/878k [00:00<00:00, 57.8MB/s]\n",
      "Downloading: 100%|██████████| 878k/878k [00:00<00:00, 59.5MB/s]\n",
      "Downloading: 100%|██████████| 878k/878k [00:00<00:00, 60.8MB/s]\n",
      "Downloading: 100%|██████████| 446k/446k [00:00<00:00, 55.2MB/s]\n",
      "Downloading: 100%|██████████| 446k/446k [00:00<00:00, 56.8MB/s]\n",
      "Downloading: 100%|██████████| 446k/446k [00:00<00:00, 60.0MB/s]\n",
      "Downloading: 100%|██████████| 446k/446k [00:00<00:00, 54.8MB/s]\n",
      "Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]0m \n",
      "Downloading: 100%|██████████| 878k/878k [00:00<00:00, 63.0MB/s]\n",
      "Downloading: 100%|██████████| 446k/446k [00:00<00:00, 54.4MB/s]\n",
      "Downloading: 100%|██████████| 446k/446k [00:00<00:00, 59.5MB/s]\n",
      "Downloading: 100%|██████████| 446k/446k [00:00<00:00, 54.9MB/s]\n",
      "Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]0m \n",
      "Downloading: 100%|██████████| 446k/446k [00:00<00:00, 59.7MB/s]\n",
      "Downloading: 100%|██████████| 446k/446k [00:00<00:00, 55.8MB/s]\n",
      "Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]m \n",
      "Downloading: 100%|██████████| 1.29M/1.29M [00:00<00:00, 59.6MB/s]\n",
      "Downloading: 100%|██████████| 1.29M/1.29M [00:00<00:00, 60.6MB/s]\n",
      "Downloading: 100%|██████████| 1.29M/1.29M [00:00<00:00, 58.7MB/s]\n",
      "Downloading: 100%|██████████| 1.29M/1.29M [00:00<00:00, 57.8MB/s]\n",
      "Downloading: 100%|██████████| 1.29M/1.29M [00:00<00:00, 60.1MB/s]\n",
      "Downloading: 100%|██████████| 1.29M/1.29M [00:00<00:00, 61.7MB/s]\n",
      "Downloading: 100%|██████████| 1.29M/1.29M [00:00<00:00, 58.1MB/s]\n",
      "Downloading: 100%|██████████| 1.29M/1.29M [00:00<00:00, 65.9MB/s]\n",
      "Downloading: 100%|██████████| 1.29M/1.29M [00:00<00:00, 58.9MB/s]\n",
      "Downloading:   0%|          | 0.00/478M [00:00<?, ?B/s]0m \n",
      "Downloading:   0%|          | 0.00/478M [00:00<?, ?B/s][0m \n",
      "Downloading:   0%|          | 0.00/478M [00:00<?, ?B/s]0m \n",
      "Downloading:   0%|          | 0.00/478M [00:00<?, ?B/s][0m \n",
      "Downloading:   0%|          | 0.00/478M [00:00<?, ?B/s]0m \n",
      "Downloading:   0%|          | 0.00/478M [00:00<?, ?B/s][0m \n",
      "Downloading:   0%|          | 0.00/478M [00:00<?, ?B/s][0m \n",
      "Downloading:   0%|          | 0.00/478M [00:00<?, ?B/s]0m \n",
      "Downloading:   1%|          | 5.79M/478M [00:00<00:08, 60.7MB/s]\n",
      "Downloading:   1%|▏         | 6.01M/478M [00:00<00:07, 63.0MB/s]\n",
      "Downloading:   1%|          | 5.78M/478M [00:00<00:08, 60.6MB/s]\n",
      "Downloading:   1%|          | 5.74M/478M [00:00<00:08, 60.2MB/s]\n",
      "Downloading:   0%|          | 0.00/478M [00:00<?, ?B/s]m \n",
      "Downloading:   1%|          | 5.80M/478M [00:00<00:08, 60.9MB/s]\n",
      "Downloading:   1%|          | 5.55M/478M [00:00<00:08, 58.2MB/s]\n",
      "Downloading:   1%|          | 5.65M/478M [00:00<00:08, 59.2MB/s]\n",
      "Downloading:   1%|          | 5.33M/478M [00:00<00:08, 55.9MB/s]\n",
      "Downloading:   2%|▏         | 11.8M/478M [00:00<00:07, 61.9MB/s]\n",
      "Downloading:   3%|▎         | 12.2M/478M [00:00<00:07, 64.3MB/s]\n",
      "Downloading:   2%|▏         | 11.6M/478M [00:00<00:08, 61.1MB/s]\n",
      "Downloading:   2%|▏         | 11.6M/478M [00:00<00:08, 61.0MB/s]\n",
      "Downloading:   1%|          | 5.81M/478M [00:00<00:08, 60.9MB/s]\n",
      "Downloading:   2%|▏         | 11.8M/478M [00:00<00:07, 61.8MB/s]\n",
      "Downloading:   2%|▏         | 11.5M/478M [00:00<00:08, 60.9MB/s]\n",
      "Downloading:   2%|▏         | 11.3M/478M [00:00<00:09, 53.5MB/s]\n",
      "Downloading:   2%|▏         | 11.1M/478M [00:00<00:08, 58.7MB/s]\n",
      "Downloading:   4%|▎         | 17.8M/478M [00:00<00:07, 62.4MB/s]\n",
      "Downloading:   4%|▍         | 18.6M/478M [00:00<00:07, 65.6MB/s]\n",
      "Downloading:   4%|▎         | 17.6M/478M [00:00<00:07, 61.6MB/s]\n",
      "Downloading:   4%|▎         | 17.5M/478M [00:00<00:07, 61.3MB/s]\n",
      "Downloading:   2%|▏         | 11.7M/478M [00:00<00:07, 61.6MB/s]\n",
      "Downloading:   4%|▎         | 17.8M/478M [00:00<00:07, 62.3MB/s]\n",
      "Downloading:   4%|▎         | 17.7M/478M [00:00<00:07, 62.4MB/s]\n",
      "Downloading:   4%|▎         | 17.1M/478M [00:00<00:08, 56.7MB/s]\n",
      "Downloading:   3%|▎         | 16.7M/478M [00:00<00:09, 51.3MB/s]\n",
      "Downloading:   5%|▍         | 23.8M/478M [00:00<00:07, 62.6MB/s]\n",
      "Downloading:   5%|▌         | 24.9M/478M [00:00<00:07, 60.5MB/s]\n",
      "Downloading:   5%|▍         | 23.6M/478M [00:00<00:07, 62.3MB/s]\n",
      "Downloading:   5%|▍         | 23.3M/478M [00:00<00:07, 60.9MB/s]\n",
      "Downloading:   4%|▎         | 17.6M/478M [00:00<00:07, 61.3MB/s]\n",
      "Downloading:   5%|▍         | 23.9M/478M [00:00<00:07, 63.1MB/s]\n",
      "Downloading:   5%|▍         | 23.7M/478M [00:00<00:07, 62.9MB/s]\n",
      "Downloading:   5%|▍         | 23.2M/478M [00:00<00:08, 59.4MB/s]\n",
      "Downloading:   5%|▍         | 22.2M/478M [00:00<00:08, 53.4MB/s]\n",
      "Downloading:   6%|▌         | 29.7M/478M [00:00<00:07, 61.4MB/s]\n",
      "Downloading:   6%|▋         | 30.9M/478M [00:00<00:07, 61.3MB/s]\n",
      "Downloading:   6%|▌         | 29.6M/478M [00:00<00:07, 60.7MB/s]\n",
      "Downloading:   6%|▌         | 29.1M/478M [00:00<00:07, 59.8MB/s]\n",
      "Downloading:   5%|▍         | 23.7M/478M [00:00<00:07, 62.2MB/s]\n",
      "Downloading:   6%|▋         | 30.0M/478M [00:00<00:07, 63.2MB/s]\n",
      "Downloading:   6%|▋         | 29.9M/478M [00:00<00:07, 63.5MB/s]\n",
      "Downloading:   6%|▌         | 29.3M/478M [00:00<00:07, 61.2MB/s]\n",
      "Downloading:   6%|▌         | 27.4M/478M [00:00<00:09, 50.9MB/s]\n",
      "Downloading:   8%|▊         | 35.8M/478M [00:00<00:07, 62.3MB/s]\n",
      "Downloading:   8%|▊         | 37.1M/478M [00:00<00:07, 62.5MB/s]\n",
      "Downloading:   7%|▋         | 35.4M/478M [00:00<00:07, 58.9MB/s]\n",
      "Downloading:   7%|▋         | 35.0M/478M [00:00<00:07, 60.3MB/s]\n",
      "Downloading:   6%|▌         | 29.7M/478M [00:00<00:07, 62.7MB/s]\n",
      "Downloading:   8%|▊         | 36.0M/478M [00:00<00:07, 63.4MB/s]\n",
      "Downloading:   8%|▊         | 36.0M/478M [00:00<00:07, 63.8MB/s]\n",
      "Downloading:   9%|▉         | 41.9M/478M [00:00<00:07, 62.8MB/s]\n",
      "Downloading:   9%|▉         | 43.2M/478M [00:00<00:07, 63.2MB/s]\n",
      "Downloading:   9%|▊         | 41.4M/478M [00:00<00:07, 60.4MB/s]\n",
      "Downloading:   9%|▊         | 40.9M/478M [00:00<00:07, 60.8MB/s]\n",
      "Downloading:   7%|▋         | 35.8M/478M [00:00<00:07, 62.8MB/s]\n",
      "Downloading:   9%|▉         | 42.1M/478M [00:00<00:07, 63.6MB/s]\n",
      "Downloading:   9%|▉         | 42.2M/478M [00:00<00:07, 64.0MB/s]\n",
      "Downloading:   7%|▋         | 35.2M/478M [00:00<00:10, 45.2MB/s]\n",
      "Downloading:   7%|▋         | 32.3M/478M [00:00<00:09, 48.9MB/s]\n",
      "Downloading:  10%|█         | 48.1M/478M [00:00<00:07, 63.3MB/s]\n",
      "Downloading:  10%|█         | 49.4M/478M [00:00<00:07, 63.8MB/s]\n",
      "Downloading:  10%|▉         | 47.2M/478M [00:00<00:07, 60.6MB/s]\n",
      "Downloading:  10%|▉         | 46.8M/478M [00:00<00:07, 61.0MB/s]\n",
      "Downloading:   9%|▉         | 41.8M/478M [00:00<00:07, 63.1MB/s]\n",
      "Downloading:  10%|█         | 48.2M/478M [00:00<00:07, 63.7MB/s]\n",
      "Downloading:  10%|█         | 48.3M/478M [00:00<00:07, 64.1MB/s]\n",
      "Downloading:   9%|▊         | 40.7M/478M [00:00<00:09, 48.6MB/s]\n",
      "Downloading:   8%|▊         | 37.6M/478M [00:00<00:09, 50.9MB/s]\n",
      "Downloading:  11%|█▏        | 54.1M/478M [00:00<00:07, 63.1MB/s]\n",
      "Downloading:  12%|█▏        | 55.6M/478M [00:00<00:06, 64.0MB/s]\n",
      "Downloading:  11%|█         | 53.1M/478M [00:00<00:07, 60.9MB/s]\n",
      "Downloading:  11%|█         | 52.6M/478M [00:00<00:07, 61.2MB/s]\n",
      "Downloading:  10%|█         | 47.9M/478M [00:00<00:07, 63.4MB/s]\n",
      "Downloading:  11%|█▏        | 54.5M/478M [00:00<00:06, 64.2MB/s]\n",
      "Downloading:  11%|█▏        | 54.5M/478M [00:00<00:06, 64.2MB/s]\n",
      "Downloading:  10%|▉         | 46.1M/478M [00:00<00:08, 50.6MB/s]\n",
      "Downloading:   9%|▉         | 42.9M/478M [00:00<00:08, 52.4MB/s]\n",
      "Downloading:  13%|█▎        | 60.1M/478M [00:01<00:06, 62.8MB/s]\n",
      "Downloading:  13%|█▎        | 61.7M/478M [00:01<00:06, 64.2MB/s]\n",
      "Downloading:  12%|█▏        | 58.9M/478M [00:01<00:07, 58.7MB/s]\n",
      "Downloading:  12%|█▏        | 58.5M/478M [00:01<00:07, 61.3MB/s]\n",
      "Downloading:  11%|█▏        | 54.0M/478M [00:00<00:07, 63.4MB/s]\n",
      "Downloading:  13%|█▎        | 60.6M/478M [00:01<00:06, 64.2MB/s]\n",
      "Downloading:  13%|█▎        | 60.6M/478M [00:01<00:06, 64.1MB/s]\n",
      "Downloading:  11%|█         | 52.2M/478M [00:01<00:08, 54.5MB/s]\n",
      "Downloading:  10%|█         | 47.9M/478M [00:00<00:09, 49.6MB/s]\n",
      "Downloading:  14%|█▍        | 66.2M/478M [00:01<00:06, 63.2MB/s]\n",
      "Downloading:  14%|█▍        | 67.9M/478M [00:01<00:06, 64.3MB/s]\n",
      "Downloading:  14%|█▎        | 64.9M/478M [00:01<00:07, 59.9MB/s]\n",
      "Downloading:  13%|█▎        | 64.3M/478M [00:01<00:07, 61.3MB/s]\n",
      "Downloading:  13%|█▎        | 60.0M/478M [00:01<00:06, 62.9MB/s]\n",
      "Downloading:  14%|█▍        | 66.7M/478M [00:01<00:06, 63.7MB/s]\n",
      "Downloading:  14%|█▍        | 66.7M/478M [00:01<00:06, 64.2MB/s]\n",
      "Downloading:  12%|█▏        | 58.4M/478M [00:01<00:07, 57.3MB/s]\n",
      "Downloading:  11%|█         | 52.7M/478M [00:01<00:10, 43.8MB/s]\n",
      "Downloading:  15%|█▌        | 72.3M/478M [00:01<00:06, 63.4MB/s]\n",
      "Downloading:  15%|█▌        | 74.1M/478M [00:01<00:06, 64.0MB/s]\n",
      "Downloading:  15%|█▍        | 70.9M/478M [00:01<00:07, 60.6MB/s]\n",
      "Downloading:  15%|█▍        | 70.2M/478M [00:01<00:06, 61.3MB/s]\n",
      "Downloading:  14%|█▍        | 66.0M/478M [00:01<00:07, 60.5MB/s]\n",
      "Downloading:  15%|█▌        | 72.8M/478M [00:01<00:07, 60.1MB/s]\n",
      "Downloading:  13%|█▎        | 64.5M/478M [00:01<00:07, 59.3MB/s]\n",
      "Downloading:  15%|█▌        | 73.0M/478M [00:01<00:06, 64.7MB/s]\n",
      "Downloading:  16%|█▋        | 78.5M/478M [00:01<00:06, 63.7MB/s]\n",
      "Downloading:  17%|█▋        | 80.2M/478M [00:01<00:06, 64.1MB/s]\n",
      "Downloading:  16%|█▌        | 76.9M/478M [00:01<00:06, 61.3MB/s]\n",
      "Downloading:  16%|█▌        | 76.0M/478M [00:01<00:06, 61.2MB/s]\n",
      "Downloading:  15%|█▌        | 72.1M/478M [00:01<00:06, 61.2MB/s]\n",
      "Downloading:  17%|█▋        | 78.9M/478M [00:01<00:06, 61.2MB/s]\n",
      "Downloading:  15%|█▍        | 70.4M/478M [00:01<00:07, 60.2MB/s]\n",
      "Downloading:  17%|█▋        | 79.2M/478M [00:01<00:06, 64.2MB/s]\n",
      "Downloading:  12%|█▏        | 57.0M/478M [00:01<00:11, 39.8MB/s]\n",
      "Downloading:  18%|█▊        | 84.6M/478M [00:01<00:06, 63.9MB/s]\n",
      "Downloading:  18%|█▊        | 86.4M/478M [00:01<00:06, 64.3MB/s]\n",
      "Downloading:  17%|█▋        | 82.8M/478M [00:01<00:06, 61.7MB/s]\n",
      "Downloading:  17%|█▋        | 81.9M/478M [00:01<00:06, 61.2MB/s]\n",
      "Downloading:  16%|█▋        | 78.0M/478M [00:01<00:06, 61.5MB/s]\n",
      "Downloading:  18%|█▊        | 85.0M/478M [00:01<00:06, 62.0MB/s]\n",
      "Downloading:  16%|█▌        | 76.6M/478M [00:01<00:06, 61.4MB/s]\n",
      "Downloading:  18%|█▊        | 85.4M/478M [00:01<00:06, 64.4MB/s]\n",
      "Downloading:  13%|█▎        | 61.5M/478M [00:01<00:10, 40.9MB/s]\n",
      "Downloading:  19%|█▉        | 90.8M/478M [00:01<00:06, 64.1MB/s]\n",
      "Downloading:  19%|█▉        | 92.5M/478M [00:01<00:06, 63.9MB/s]\n",
      "Downloading:  19%|█▊        | 88.8M/478M [00:01<00:06, 62.0MB/s]\n",
      "Downloading:  18%|█▊        | 87.7M/478M [00:01<00:06, 60.7MB/s]\n",
      "Downloading:  18%|█▊        | 83.9M/478M [00:01<00:06, 61.8MB/s]\n",
      "Downloading:  19%|█▉        | 91.1M/478M [00:01<00:06, 62.6MB/s]\n",
      "Downloading:  17%|█▋        | 82.7M/478M [00:01<00:06, 62.3MB/s]\n",
      "Downloading:  19%|█▉        | 91.6M/478M [00:01<00:06, 64.6MB/s]\n",
      "Downloading:  14%|█▍        | 66.4M/478M [00:01<00:09, 43.8MB/s]\n",
      "Downloading:  20%|██        | 96.9M/478M [00:01<00:06, 64.1MB/s]\n",
      "Downloading:  21%|██        | 98.7M/478M [00:01<00:06, 64.1MB/s]\n",
      "Downloading:  20%|█▉        | 94.9M/478M [00:01<00:06, 62.4MB/s]\n",
      "Downloading:  20%|█▉        | 93.6M/478M [00:01<00:06, 60.9MB/s]\n",
      "Downloading:  19%|█▉        | 89.9M/478M [00:01<00:06, 62.0MB/s]\n",
      "Downloading:  20%|██        | 97.3M/478M [00:01<00:06, 63.2MB/s]\n",
      "Downloading:  19%|█▊        | 88.8M/478M [00:01<00:06, 62.8MB/s]\n",
      "Downloading:  20%|██        | 97.8M/478M [00:01<00:06, 64.9MB/s]\n",
      "Downloading:  15%|█▍        | 71.7M/478M [00:01<00:09, 47.0MB/s]\n",
      "Downloading:  22%|██▏       | 103M/478M [00:01<00:06, 64.2MB/s] \n",
      "Downloading:  22%|██▏       | 105M/478M [00:01<00:06, 64.3MB/s] \n",
      "Downloading:  21%|██        | 101M/478M [00:01<00:06, 59.4MB/s] \n",
      "Downloading:  21%|██        | 99.4M/478M [00:01<00:06, 61.0MB/s]\n",
      "Downloading:  20%|██        | 95.8M/478M [00:01<00:06, 62.0MB/s]\n",
      "Downloading:  22%|██▏       | 103M/478M [00:01<00:06, 63.5MB/s] \n",
      "Downloading:  20%|█▉        | 95.0M/478M [00:01<00:06, 63.4MB/s]\n",
      "Downloading:  22%|██▏       | 104M/478M [00:01<00:06, 60.3MB/s] \n",
      "Downloading:  16%|█▌        | 76.5M/478M [00:01<00:09, 45.0MB/s]\n",
      "Downloading:  23%|██▎       | 109M/478M [00:01<00:06, 64.3MB/s]\n",
      "Downloading:  23%|██▎       | 111M/478M [00:01<00:05, 64.4MB/s]\n",
      "Downloading:  22%|██▏       | 107M/478M [00:01<00:06, 61.1MB/s]\n",
      "Downloading:  22%|██▏       | 105M/478M [00:01<00:06, 61.2MB/s] \n",
      "Downloading:  21%|██▏       | 102M/478M [00:01<00:06, 62.0MB/s] \n",
      "Downloading:  23%|██▎       | 108M/478M [00:01<00:06, 62.1MB/s]\n",
      "Downloading:  23%|██▎       | 109M/478M [00:01<00:06, 63.7MB/s]\n",
      "Downloading:  21%|██        | 101M/478M [00:01<00:06, 63.6MB/s] \n",
      "Downloading:  23%|██▎       | 110M/478M [00:01<00:06, 61.6MB/s]\n",
      "Downloading:  24%|██▍       | 115M/478M [00:01<00:05, 64.3MB/s]\n",
      "Downloading:  25%|██▍       | 117M/478M [00:01<00:05, 64.2MB/s]\n",
      "Downloading:  23%|██▎       | 111M/478M [00:01<00:06, 61.4MB/s]\n",
      "Downloading:  24%|██▍       | 114M/478M [00:01<00:06, 62.1MB/s]\n",
      "Downloading:  24%|██▍       | 116M/478M [00:01<00:05, 64.0MB/s]\n",
      "Downloading:  22%|██▏       | 107M/478M [00:01<00:06, 64.0MB/s]\n",
      "Downloading:  24%|██▍       | 116M/478M [00:01<00:06, 62.7MB/s]\n",
      "Downloading:  17%|█▋        | 80.9M/478M [00:01<00:12, 34.7MB/s]\n",
      "Downloading:  25%|██▌       | 121M/478M [00:02<00:05, 63.9MB/s]\n",
      "Downloading:  26%|██▌       | 123M/478M [00:02<00:05, 64.2MB/s]\n",
      "Downloading:  24%|██▎       | 113M/478M [00:01<00:06, 56.4MB/s]\n",
      "Downloading:  24%|██▍       | 117M/478M [00:02<00:06, 61.5MB/s]\n",
      "Downloading:  25%|██▌       | 122M/478M [00:02<00:05, 63.9MB/s]\n",
      "Downloading:  24%|██▎       | 114M/478M [00:02<00:05, 64.2MB/s]\n",
      "Downloading:  26%|██▌       | 123M/478M [00:02<00:05, 63.4MB/s]\n",
      "Downloading:  18%|█▊        | 84.6M/478M [00:02<00:12, 31.8MB/s]\n",
      "Downloading:  27%|██▋       | 128M/478M [00:02<00:05, 64.1MB/s]\n",
      "Downloading:  27%|██▋       | 129M/478M [00:02<00:05, 64.2MB/s]\n",
      "Downloading:  25%|██▍       | 118M/478M [00:02<00:07, 53.1MB/s]\n",
      "Downloading:  26%|██▌       | 123M/478M [00:02<00:06, 61.5MB/s]\n",
      "Downloading:  25%|██▌       | 120M/478M [00:02<00:07, 53.4MB/s]\n",
      "Downloading:  27%|██▋       | 128M/478M [00:02<00:05, 63.3MB/s]\n",
      "Downloading:  25%|██▌       | 120M/478M [00:02<00:05, 64.0MB/s]\n",
      "Downloading:  27%|██▋       | 129M/478M [00:02<00:05, 63.9MB/s]\n",
      "Downloading:  28%|██▊       | 134M/478M [00:02<00:05, 64.2MB/s]\n",
      "Downloading:  28%|██▊       | 136M/478M [00:02<00:05, 64.5MB/s]\n",
      "Downloading:  26%|██▌       | 124M/478M [00:02<00:07, 49.4MB/s]\n",
      "Downloading:  27%|██▋       | 129M/478M [00:02<00:05, 61.4MB/s]\n",
      "Downloading:  26%|██▌       | 125M/478M [00:02<00:07, 52.2MB/s]\n",
      "Downloading:  28%|██▊       | 134M/478M [00:02<00:05, 63.4MB/s]\n",
      "Downloading:  26%|██▋       | 126M/478M [00:02<00:05, 64.1MB/s]\n",
      "Downloading:  28%|██▊       | 135M/478M [00:02<00:05, 64.3MB/s]\n",
      "Downloading:  29%|██▉       | 140M/478M [00:02<00:05, 64.3MB/s]\n",
      "Downloading:  30%|██▉       | 142M/478M [00:02<00:05, 64.5MB/s]\n",
      "Downloading:  27%|██▋       | 129M/478M [00:02<00:06, 52.7MB/s]\n",
      "Downloading:  28%|██▊       | 135M/478M [00:02<00:05, 61.4MB/s]\n",
      "Downloading:  27%|██▋       | 131M/478M [00:02<00:06, 55.0MB/s]\n",
      "Downloading:  29%|██▉       | 140M/478M [00:02<00:05, 63.8MB/s]\n",
      "Downloading:  28%|██▊       | 132M/478M [00:02<00:05, 63.3MB/s]\n",
      "Downloading:  18%|█▊        | 87.9M/478M [00:02<00:16, 24.3MB/s]\n",
      "Downloading:  30%|██▉       | 141M/478M [00:02<00:05, 64.1MB/s]\n",
      "Downloading:  31%|███       | 146M/478M [00:02<00:05, 64.3MB/s]\n",
      "Downloading:  31%|███       | 148M/478M [00:02<00:05, 64.7MB/s]\n",
      "Downloading:  28%|██▊       | 135M/478M [00:02<00:06, 55.2MB/s]\n",
      "Downloading:  31%|███       | 147M/478M [00:02<00:05, 62.4MB/s]\n",
      "Downloading:  29%|██▊       | 137M/478M [00:02<00:06, 57.5MB/s]\n",
      "Downloading:  31%|███       | 146M/478M [00:02<00:05, 63.8MB/s]\n",
      "Downloading:  29%|██▉       | 138M/478M [00:02<00:05, 63.7MB/s]\n",
      "Downloading:  19%|█▉        | 90.6M/478M [00:02<00:18, 22.5MB/s]\n",
      "Downloading:  31%|███       | 147M/478M [00:02<00:05, 64.4MB/s]\n",
      "Downloading:  32%|███▏      | 152M/478M [00:02<00:05, 64.3MB/s]\n",
      "Downloading:  32%|███▏      | 154M/478M [00:02<00:05, 64.2MB/s]\n",
      "Downloading:  30%|██▉       | 141M/478M [00:02<00:06, 57.5MB/s]\n",
      "Downloading:  32%|███▏      | 153M/478M [00:02<00:05, 63.5MB/s]\n",
      "Downloading:  30%|██▉       | 143M/478M [00:02<00:05, 59.0MB/s]\n",
      "Downloading:  32%|███▏      | 152M/478M [00:02<00:05, 63.9MB/s]\n",
      "Downloading:  30%|███       | 144M/478M [00:02<00:05, 63.8MB/s]\n",
      "Downloading:  20%|██        | 95.6M/478M [00:02<00:14, 28.5MB/s]\n",
      "Downloading:  32%|███▏      | 154M/478M [00:02<00:05, 64.6MB/s]\n",
      "Downloading:  33%|███▎      | 158M/478M [00:02<00:05, 64.2MB/s]\n",
      "Downloading:  34%|███▎      | 160M/478M [00:02<00:05, 64.0MB/s]\n",
      "Downloading:  31%|███       | 147M/478M [00:02<00:06, 54.7MB/s]\n",
      "Downloading:  33%|███▎      | 159M/478M [00:02<00:05, 64.3MB/s]\n",
      "Downloading:  31%|███       | 149M/478M [00:02<00:06, 56.0MB/s]\n",
      "Downloading:  33%|███▎      | 158M/478M [00:02<00:05, 63.9MB/s]\n",
      "Downloading:  31%|███▏      | 150M/478M [00:02<00:06, 55.8MB/s]\n",
      "Downloading:  21%|██        | 101M/478M [00:02<00:11, 34.4MB/s] \n",
      "Downloading:  33%|███▎      | 160M/478M [00:02<00:05, 64.6MB/s]\n",
      "Downloading:  34%|███▍      | 164M/478M [00:02<00:05, 64.2MB/s]\n",
      "Downloading:  35%|███▍      | 166M/478M [00:02<00:05, 64.0MB/s]\n",
      "Downloading:  32%|███▏      | 152M/478M [00:02<00:06, 54.9MB/s]\n",
      "Downloading:  35%|███▍      | 166M/478M [00:02<00:05, 65.2MB/s]\n",
      "Downloading:  32%|███▏      | 155M/478M [00:02<00:05, 57.9MB/s]\n",
      "Downloading:  34%|███▍      | 164M/478M [00:02<00:05, 63.5MB/s]\n",
      "Downloading:  22%|██▏       | 106M/478M [00:02<00:10, 38.8MB/s]\n",
      "Downloading:  35%|███▍      | 166M/478M [00:02<00:05, 64.7MB/s]\n",
      "Downloading:  36%|███▌      | 171M/478M [00:02<00:05, 64.3MB/s]\n",
      "Downloading:  36%|███▌      | 173M/478M [00:02<00:04, 64.2MB/s]\n",
      "Downloading:  33%|███▎      | 158M/478M [00:02<00:05, 57.2MB/s]\n",
      "Downloading:  36%|███▌      | 172M/478M [00:02<00:04, 65.9MB/s]\n",
      "Downloading:  34%|███▎      | 161M/478M [00:02<00:05, 59.2MB/s]\n",
      "Downloading:  33%|███▎      | 156M/478M [00:02<00:06, 51.1MB/s]\n",
      "Downloading:  36%|███▌      | 171M/478M [00:02<00:05, 63.8MB/s]\n",
      "Downloading:  23%|██▎       | 111M/478M [00:02<00:08, 42.8MB/s]\n",
      "Downloading:  36%|███▌      | 172M/478M [00:02<00:04, 64.7MB/s]\n",
      "Downloading:  37%|███▋      | 177M/478M [00:02<00:04, 64.3MB/s]\n",
      "Downloading:  37%|███▋      | 179M/478M [00:02<00:04, 64.5MB/s]\n",
      "Downloading:  34%|███▍      | 164M/478M [00:02<00:05, 59.1MB/s]\n",
      "Downloading:  37%|███▋      | 179M/478M [00:03<00:04, 66.1MB/s]\n",
      "Downloading:  35%|███▍      | 167M/478M [00:02<00:05, 60.2MB/s]\n",
      "Downloading:  34%|███▍      | 161M/478M [00:02<00:06, 53.4MB/s]\n",
      "Downloading:  37%|███▋      | 177M/478M [00:02<00:04, 64.0MB/s]\n",
      "Downloading:  24%|██▍       | 116M/478M [00:02<00:08, 44.3MB/s]\n",
      "Downloading:  37%|███▋      | 178M/478M [00:02<00:04, 65.0MB/s]\n",
      "Downloading:  38%|███▊      | 183M/478M [00:03<00:04, 63.9MB/s]\n",
      "Downloading:  39%|███▊      | 185M/478M [00:03<00:04, 65.3MB/s]\n",
      "Downloading:  36%|███▌      | 170M/478M [00:03<00:05, 56.3MB/s]\n",
      "Downloading:  39%|███▊      | 185M/478M [00:03<00:04, 66.2MB/s]\n",
      "Downloading:  36%|███▌      | 172M/478M [00:03<00:05, 60.6MB/s]\n",
      "Downloading:  35%|███▌      | 168M/478M [00:03<00:05, 56.3MB/s]\n",
      "Downloading:  38%|███▊      | 183M/478M [00:03<00:04, 64.0MB/s]\n",
      "Downloading:  25%|██▌       | 120M/478M [00:03<00:08, 43.7MB/s]\n",
      "Downloading:  39%|███▊      | 185M/478M [00:03<00:04, 65.0MB/s]\n",
      "Downloading:  40%|███▉      | 189M/478M [00:03<00:04, 64.2MB/s]\n",
      "Downloading:  40%|████      | 192M/478M [00:03<00:04, 65.6MB/s]\n",
      "Downloading:  40%|███▉      | 191M/478M [00:03<00:04, 66.2MB/s]\n",
      "Downloading:  37%|███▋      | 178M/478M [00:03<00:05, 61.2MB/s]\n",
      "Downloading:  36%|███▋      | 174M/478M [00:03<00:05, 58.5MB/s]\n",
      "Downloading:  40%|███▉      | 189M/478M [00:03<00:04, 63.7MB/s]\n",
      "Downloading:  40%|███▉      | 191M/478M [00:03<00:04, 64.7MB/s]\n",
      "Downloading:  41%|████      | 195M/478M [00:03<00:04, 64.6MB/s]\n",
      "Downloading:  41%|████▏     | 198M/478M [00:03<00:04, 65.9MB/s]\n",
      "Downloading:  37%|███▋      | 175M/478M [00:03<00:06, 50.9MB/s]\n",
      "Downloading:  41%|████▏     | 197M/478M [00:03<00:04, 66.1MB/s]\n",
      "Downloading:  39%|███▊      | 184M/478M [00:03<00:05, 61.3MB/s]\n",
      "Downloading:  38%|███▊      | 180M/478M [00:03<00:05, 60.2MB/s]\n",
      "Downloading:  41%|████      | 195M/478M [00:03<00:04, 63.8MB/s]\n",
      "Downloading:  26%|██▌       | 125M/478M [00:03<00:08, 41.8MB/s]\n",
      "Downloading:  41%|████      | 197M/478M [00:03<00:04, 64.9MB/s]\n",
      "Downloading:  42%|████▏     | 201M/478M [00:03<00:04, 64.5MB/s]\n",
      "Downloading:  43%|████▎     | 204M/478M [00:03<00:04, 66.0MB/s]\n",
      "Downloading:  38%|███▊      | 181M/478M [00:03<00:05, 54.4MB/s]\n",
      "Downloading:  43%|████▎     | 204M/478M [00:03<00:04, 66.2MB/s]\n",
      "Downloading:  40%|███▉      | 190M/478M [00:03<00:04, 61.8MB/s]\n",
      "Downloading:  39%|███▉      | 186M/478M [00:03<00:05, 60.6MB/s]\n",
      "Downloading:  42%|████▏     | 201M/478M [00:03<00:04, 63.8MB/s]\n",
      "Downloading:  27%|██▋       | 129M/478M [00:03<00:09, 38.8MB/s]\n",
      "Downloading:  43%|████▎     | 203M/478M [00:03<00:04, 64.5MB/s]\n",
      "Downloading:  43%|████▎     | 208M/478M [00:03<00:04, 64.6MB/s]\n",
      "Downloading:  44%|████▍     | 211M/478M [00:03<00:04, 66.4MB/s]\n",
      "Downloading:  39%|███▉      | 187M/478M [00:03<00:05, 56.9MB/s]\n",
      "Downloading:  44%|████▍     | 210M/478M [00:03<00:04, 65.8MB/s]\n",
      "Downloading:  41%|████      | 196M/478M [00:03<00:04, 62.2MB/s]\n",
      "Downloading:  40%|████      | 192M/478M [00:03<00:04, 61.2MB/s]\n",
      "Downloading:  43%|████▎     | 207M/478M [00:03<00:04, 63.8MB/s]\n",
      "Downloading:  28%|██▊       | 133M/478M [00:03<00:09, 38.1MB/s]\n",
      "Downloading:  44%|████▍     | 209M/478M [00:03<00:04, 64.5MB/s]\n",
      "Downloading:  45%|████▍     | 214M/478M [00:03<00:04, 64.8MB/s]\n",
      "Downloading:  45%|████▌     | 217M/478M [00:03<00:04, 66.0MB/s]\n",
      "Downloading:  40%|████      | 194M/478M [00:03<00:05, 58.9MB/s]\n",
      "Downloading:  45%|████▌     | 216M/478M [00:03<00:04, 66.0MB/s]\n",
      "Downloading:  42%|████▏     | 202M/478M [00:03<00:04, 62.6MB/s]\n",
      "Downloading:  41%|████▏     | 198M/478M [00:03<00:04, 62.0MB/s]\n",
      "Downloading:  45%|████▍     | 213M/478M [00:03<00:04, 63.8MB/s]\n",
      "Downloading:  29%|██▉       | 138M/478M [00:03<00:08, 42.7MB/s]\n",
      "Downloading:  45%|████▌     | 216M/478M [00:03<00:04, 64.8MB/s]\n",
      "Downloading:  46%|████▌     | 220M/478M [00:03<00:04, 65.0MB/s]\n",
      "Downloading:  47%|████▋     | 223M/478M [00:03<00:04, 66.3MB/s]\n",
      "Downloading:  42%|████▏     | 199M/478M [00:03<00:04, 59.0MB/s]\n",
      "Downloading:  47%|████▋     | 223M/478M [00:03<00:04, 66.1MB/s]\n",
      "Downloading:  44%|████▎     | 208M/478M [00:03<00:04, 63.0MB/s]\n",
      "Downloading:  43%|████▎     | 204M/478M [00:03<00:04, 62.8MB/s]\n",
      "Downloading:  46%|████▌     | 220M/478M [00:03<00:04, 64.0MB/s]\n",
      "Downloading:  30%|██▉       | 142M/478M [00:03<00:08, 42.1MB/s]\n",
      "Downloading:  46%|████▋     | 222M/478M [00:03<00:04, 65.0MB/s]\n",
      "Downloading:  47%|████▋     | 226M/478M [00:03<00:04, 65.3MB/s]\n",
      "Downloading:  48%|████▊     | 230M/478M [00:03<00:03, 66.6MB/s]\n",
      "Downloading:  43%|████▎     | 205M/478M [00:03<00:04, 59.8MB/s]\n",
      "Downloading:  48%|████▊     | 229M/478M [00:03<00:03, 66.1MB/s]\n",
      "Downloading:  45%|████▍     | 214M/478M [00:03<00:04, 59.9MB/s]\n",
      "Downloading:  44%|████▍     | 210M/478M [00:03<00:04, 63.4MB/s]\n",
      "Downloading:  47%|████▋     | 226M/478M [00:03<00:04, 64.0MB/s]\n",
      "Downloading:  31%|███       | 146M/478M [00:03<00:08, 39.9MB/s]\n",
      "Downloading:  48%|████▊     | 228M/478M [00:03<00:04, 65.1MB/s]\n",
      "Downloading:  49%|████▊     | 233M/478M [00:03<00:03, 65.4MB/s]\n",
      "Downloading:  49%|████▉     | 236M/478M [00:03<00:03, 66.9MB/s]\n",
      "Downloading:  44%|████▍     | 211M/478M [00:03<00:04, 60.9MB/s]\n",
      "Downloading:  49%|████▉     | 235M/478M [00:03<00:03, 66.3MB/s]\n",
      "Downloading:  46%|████▌     | 220M/478M [00:03<00:04, 59.4MB/s]\n",
      "Downloading:  45%|████▌     | 216M/478M [00:03<00:04, 63.7MB/s]\n",
      "Downloading:  48%|████▊     | 232M/478M [00:03<00:04, 64.1MB/s]\n",
      "Downloading:  31%|███▏      | 150M/478M [00:03<00:08, 40.7MB/s]\n",
      "Downloading:  50%|████▉     | 239M/478M [00:03<00:03, 65.6MB/s]\n",
      "Downloading:  49%|████▉     | 234M/478M [00:03<00:03, 65.1MB/s]\n",
      "Downloading:  51%|█████     | 243M/478M [00:03<00:03, 66.8MB/s]\n",
      "Downloading:  45%|████▌     | 217M/478M [00:03<00:04, 61.8MB/s]\n",
      "Downloading:  51%|█████     | 242M/478M [00:04<00:03, 66.5MB/s]\n",
      "Downloading:  47%|████▋     | 226M/478M [00:03<00:04, 60.4MB/s]\n",
      "Downloading:  47%|████▋     | 222M/478M [00:03<00:04, 64.0MB/s]\n",
      "Downloading:  50%|████▉     | 238M/478M [00:03<00:03, 64.2MB/s]\n",
      "Downloading:  32%|███▏      | 154M/478M [00:03<00:08, 41.4MB/s]\n",
      "Downloading:  51%|█████▏    | 245M/478M [00:04<00:03, 65.1MB/s]\n",
      "Downloading:  50%|█████     | 241M/478M [00:03<00:03, 65.1MB/s]\n",
      "Downloading:  52%|█████▏    | 249M/478M [00:04<00:03, 66.2MB/s]\n",
      "Downloading:  47%|████▋     | 223M/478M [00:04<00:04, 62.3MB/s]\n",
      "Downloading:  52%|█████▏    | 248M/478M [00:04<00:03, 66.6MB/s]\n",
      "Downloading:  49%|████▊     | 232M/478M [00:04<00:04, 60.7MB/s]\n",
      "Downloading:  48%|████▊     | 229M/478M [00:04<00:04, 64.3MB/s]\n",
      "Downloading:  51%|█████     | 244M/478M [00:04<00:03, 64.0MB/s]\n",
      "Downloading:  33%|███▎      | 158M/478M [00:04<00:08, 41.1MB/s]\n",
      "Downloading:  53%|█████▎    | 251M/478M [00:04<00:03, 65.2MB/s]\n",
      "Downloading:  52%|█████▏    | 247M/478M [00:04<00:03, 65.1MB/s]\n",
      "Downloading:  53%|█████▎    | 255M/478M [00:04<00:03, 65.7MB/s]\n",
      "Downloading:  48%|████▊     | 229M/478M [00:04<00:04, 62.6MB/s]\n",
      "Downloading:  53%|█████▎    | 255M/478M [00:04<00:03, 66.7MB/s]\n",
      "Downloading:  50%|████▉     | 238M/478M [00:04<00:04, 61.9MB/s]\n",
      "Downloading:  50%|█████     | 241M/478M [00:04<00:03, 64.4MB/s]\n",
      "Downloading:  52%|█████▏    | 250M/478M [00:04<00:03, 63.4MB/s]\n",
      "Downloading:  34%|███▍      | 164M/478M [00:04<00:07, 44.6MB/s]\n",
      "Downloading:  54%|█████▍    | 258M/478M [00:04<00:03, 65.5MB/s]\n",
      "Downloading:  53%|█████▎    | 253M/478M [00:04<00:03, 65.1MB/s]\n",
      "Downloading:  55%|█████▍    | 262M/478M [00:04<00:03, 65.5MB/s]\n",
      "Downloading:  49%|████▉     | 236M/478M [00:04<00:04, 63.0MB/s]\n",
      "Downloading:  55%|█████▍    | 261M/478M [00:04<00:03, 66.7MB/s]\n",
      "Downloading:  51%|█████     | 244M/478M [00:04<00:04, 58.7MB/s]\n",
      "Downloading:  54%|█████▎    | 256M/478M [00:04<00:03, 63.5MB/s]\n",
      "Downloading:  35%|███▌      | 168M/478M [00:04<00:07, 44.7MB/s]\n",
      "Downloading:  55%|█████▌    | 264M/478M [00:04<00:03, 65.5MB/s]\n",
      "Downloading:  54%|█████▍    | 259M/478M [00:04<00:03, 65.3MB/s]\n",
      "Downloading:  56%|█████▌    | 268M/478M [00:04<00:03, 65.3MB/s]\n",
      "Downloading:  51%|█████     | 242M/478M [00:04<00:03, 63.2MB/s]\n",
      "Downloading:  56%|█████▌    | 267M/478M [00:04<00:03, 66.7MB/s]\n",
      "Downloading:  52%|█████▏    | 250M/478M [00:04<00:04, 59.6MB/s]\n",
      "Downloading:  52%|█████▏    | 247M/478M [00:04<00:03, 63.9MB/s]\n",
      "Downloading:  53%|█████▎    | 253M/478M [00:04<00:03, 63.9MB/s]\n",
      "Downloading:  55%|█████▍    | 262M/478M [00:04<00:03, 63.7MB/s]\n",
      "Downloading:  36%|███▌      | 172M/478M [00:04<00:07, 44.7MB/s]\n",
      "Downloading:  57%|█████▋    | 270M/478M [00:04<00:03, 65.5MB/s]\n",
      "Downloading:  52%|█████▏    | 248M/478M [00:04<00:03, 63.2MB/s]\n",
      "Downloading:  57%|█████▋    | 274M/478M [00:04<00:03, 65.1MB/s]\n",
      "Downloading:  56%|█████▌    | 266M/478M [00:04<00:03, 64.9MB/s]\n",
      "Downloading:  57%|█████▋    | 274M/478M [00:04<00:03, 66.3MB/s]\n",
      "Downloading:  54%|█████▎    | 256M/478M [00:04<00:03, 60.3MB/s]\n",
      "Downloading:  54%|█████▍    | 259M/478M [00:04<00:03, 64.0MB/s]\n",
      "Downloading:  56%|█████▌    | 268M/478M [00:04<00:03, 63.6MB/s]\n",
      "Downloading:  37%|███▋      | 177M/478M [00:04<00:06, 46.7MB/s]\n",
      "Downloading:  58%|█████▊    | 277M/478M [00:04<00:03, 65.7MB/s]\n",
      "Downloading:  53%|█████▎    | 254M/478M [00:04<00:03, 63.4MB/s]\n",
      "Downloading:  59%|█████▊    | 280M/478M [00:04<00:03, 64.4MB/s]\n",
      "Downloading:  57%|█████▋    | 272M/478M [00:04<00:03, 64.9MB/s]\n",
      "Downloading:  59%|█████▊    | 280M/478M [00:04<00:03, 66.5MB/s]\n",
      "Downloading:  55%|█████▍    | 262M/478M [00:04<00:03, 60.4MB/s]\n",
      "Downloading:  56%|█████▌    | 266M/478M [00:04<00:03, 65.1MB/s]\n",
      "Downloading:  57%|█████▋    | 275M/478M [00:04<00:03, 63.8MB/s]\n",
      "Downloading:  38%|███▊      | 182M/478M [00:04<00:06, 49.4MB/s]\n",
      "Downloading:  59%|█████▉    | 283M/478M [00:04<00:03, 65.0MB/s]\n",
      "Downloading:  54%|█████▍    | 260M/478M [00:04<00:03, 63.1MB/s]\n",
      "Downloading:  60%|█████▉    | 286M/478M [00:04<00:03, 64.1MB/s]\n",
      "Downloading:  58%|█████▊    | 278M/478M [00:04<00:03, 64.6MB/s]\n",
      "Downloading:  60%|█████▉    | 286M/478M [00:04<00:03, 64.3MB/s]\n",
      "Downloading:  56%|█████▌    | 268M/478M [00:04<00:03, 61.6MB/s]\n",
      "Downloading:  57%|█████▋    | 272M/478M [00:04<00:03, 66.1MB/s]\n",
      "Downloading:  59%|█████▊    | 281M/478M [00:04<00:03, 62.7MB/s]\n",
      "Downloading:  60%|██████    | 289M/478M [00:04<00:03, 64.7MB/s]\n",
      "Downloading:  56%|█████▌    | 266M/478M [00:04<00:03, 62.9MB/s]\n",
      "Downloading:  61%|██████    | 292M/478M [00:04<00:03, 64.0MB/s]\n",
      "Downloading:  59%|█████▉    | 284M/478M [00:04<00:03, 64.2MB/s]\n",
      "Downloading:  57%|█████▋    | 274M/478M [00:04<00:03, 62.1MB/s]\n",
      "Downloading:  58%|█████▊    | 279M/478M [00:04<00:03, 67.0MB/s]\n",
      "Downloading:  60%|█████▉    | 287M/478M [00:04<00:03, 61.9MB/s]\n",
      "Downloading:  39%|███▉      | 187M/478M [00:04<00:06, 43.8MB/s]\n",
      "Downloading:  62%|██████▏   | 295M/478M [00:04<00:02, 65.0MB/s]\n",
      "Downloading:  57%|█████▋    | 272M/478M [00:04<00:03, 63.6MB/s]\n",
      "Downloading:  62%|██████▏   | 299M/478M [00:04<00:02, 64.3MB/s]\n",
      "Downloading:  61%|██████    | 290M/478M [00:04<00:03, 64.3MB/s]\n",
      "Downloading:  61%|██████    | 293M/478M [00:04<00:03, 53.9MB/s]\n",
      "Downloading:  59%|█████▊    | 280M/478M [00:04<00:03, 61.9MB/s]\n",
      "Downloading:  60%|█████▉    | 286M/478M [00:04<00:02, 67.8MB/s]\n",
      "Downloading:  61%|██████▏   | 293M/478M [00:04<00:03, 63.0MB/s]\n",
      "Downloading:  40%|████      | 191M/478M [00:04<00:07, 41.6MB/s]\n",
      "Downloading:  63%|██████▎   | 302M/478M [00:04<00:02, 65.1MB/s]\n",
      "Downloading:  58%|█████▊    | 278M/478M [00:04<00:03, 64.4MB/s]\n",
      "Downloading:  60%|█████▉    | 285M/478M [00:05<00:03, 65.0MB/s]\n",
      "Downloading:  64%|██████▍   | 305M/478M [00:04<00:02, 64.3MB/s]\n",
      "Downloading:  63%|██████▎   | 303M/478M [00:04<00:02, 64.4MB/s]\n",
      "Downloading:  62%|██████▏   | 298M/478M [00:04<00:03, 55.9MB/s]\n",
      "Downloading:  60%|█████▉    | 286M/478M [00:04<00:03, 62.1MB/s]\n",
      "Downloading:  61%|██████    | 292M/478M [00:05<00:02, 68.2MB/s]\n",
      "Downloading:  63%|██████▎   | 299M/478M [00:04<00:02, 63.8MB/s]\n",
      "Downloading:  41%|████      | 196M/478M [00:04<00:07, 42.0MB/s]\n",
      "Downloading:  64%|██████▍   | 308M/478M [00:05<00:02, 65.1MB/s]\n",
      "Downloading:  61%|██████    | 291M/478M [00:05<00:02, 65.5MB/s]\n",
      "Downloading:  65%|██████▌   | 311M/478M [00:05<00:02, 63.9MB/s]\n",
      "Downloading:  65%|██████▍   | 309M/478M [00:05<00:02, 64.4MB/s]\n",
      "Downloading:  64%|██████▎   | 304M/478M [00:05<00:03, 57.2MB/s]\n",
      "Downloading:  61%|██████    | 292M/478M [00:05<00:03, 61.8MB/s]\n",
      "Downloading:  62%|██████▏   | 299M/478M [00:05<00:02, 68.3MB/s]\n",
      "Downloading:  64%|██████▍   | 305M/478M [00:05<00:02, 64.3MB/s]\n",
      "Downloading:  42%|████▏     | 201M/478M [00:05<00:06, 46.1MB/s]\n",
      "Downloading:  66%|██████▌   | 314M/478M [00:05<00:02, 64.7MB/s]\n",
      "Downloading:  62%|██████▏   | 297M/478M [00:05<00:02, 65.9MB/s]\n",
      "Downloading:  66%|██████▋   | 317M/478M [00:05<00:02, 64.0MB/s]\n",
      "Downloading:  65%|██████▍   | 310M/478M [00:05<00:02, 59.5MB/s]\n",
      "Downloading:  62%|██████▏   | 298M/478M [00:05<00:03, 62.3MB/s]\n",
      "Downloading:  64%|██████▍   | 305M/478M [00:05<00:02, 68.4MB/s]\n",
      "Downloading:  65%|██████▌   | 312M/478M [00:05<00:02, 64.1MB/s]\n",
      "Downloading:  43%|████▎     | 205M/478M [00:05<00:06, 44.9MB/s]\n",
      "Downloading:  67%|██████▋   | 320M/478M [00:05<00:02, 64.8MB/s]\n",
      "Downloading:  68%|██████▊   | 323M/478M [00:05<00:02, 64.3MB/s]\n",
      "Downloading:  66%|██████▌   | 315M/478M [00:05<00:02, 59.5MB/s]\n",
      "Downloading:  66%|██████▌   | 316M/478M [00:05<00:02, 60.2MB/s]\n",
      "Downloading:  64%|██████▎   | 304M/478M [00:05<00:02, 62.5MB/s]\n",
      "Downloading:  65%|██████▌   | 312M/478M [00:05<00:02, 68.3MB/s]\n",
      "Downloading:  66%|██████▋   | 318M/478M [00:05<00:02, 64.6MB/s]\n",
      "Downloading:  44%|████▍     | 211M/478M [00:05<00:05, 49.0MB/s]\n",
      "Downloading:  68%|██████▊   | 326M/478M [00:05<00:02, 65.0MB/s]\n",
      "Downloading:  64%|██████▎   | 304M/478M [00:05<00:02, 64.4MB/s]\n",
      "Downloading:  69%|██████▉   | 329M/478M [00:05<00:02, 64.5MB/s]\n",
      "Downloading:  67%|██████▋   | 321M/478M [00:05<00:02, 60.5MB/s]\n",
      "Downloading:  68%|██████▊   | 323M/478M [00:05<00:02, 62.0MB/s]\n",
      "Downloading:  65%|██████▍   | 310M/478M [00:05<00:02, 62.8MB/s]\n",
      "Downloading:  67%|██████▋   | 318M/478M [00:05<00:02, 68.4MB/s]\n",
      "Downloading:  68%|██████▊   | 324M/478M [00:05<00:02, 64.8MB/s]\n",
      "Downloading:  45%|████▌     | 216M/478M [00:05<00:05, 51.1MB/s]\n",
      "Downloading:  70%|██████▉   | 333M/478M [00:05<00:02, 65.1MB/s]\n",
      "Downloading:  66%|██████▌   | 316M/478M [00:05<00:02, 65.6MB/s]\n",
      "Downloading:  70%|███████   | 336M/478M [00:05<00:02, 64.7MB/s]\n",
      "Downloading:  68%|██████▊   | 327M/478M [00:05<00:02, 61.2MB/s]\n",
      "Downloading:  69%|██████▉   | 329M/478M [00:05<00:02, 61.7MB/s]\n",
      "Downloading:  66%|██████▌   | 316M/478M [00:05<00:02, 63.2MB/s]\n",
      "Downloading:  68%|██████▊   | 325M/478M [00:05<00:02, 68.4MB/s]\n",
      "Downloading:  69%|██████▉   | 330M/478M [00:05<00:02, 64.6MB/s]\n",
      "Downloading:  46%|████▋     | 221M/478M [00:05<00:06, 43.8MB/s]\n",
      "Downloading:  71%|███████   | 339M/478M [00:05<00:02, 65.3MB/s]\n",
      "Downloading:  68%|██████▊   | 323M/478M [00:05<00:02, 65.6MB/s]\n",
      "Downloading:  72%|███████▏  | 342M/478M [00:05<00:02, 64.3MB/s]\n",
      "Downloading:  70%|██████▉   | 333M/478M [00:05<00:02, 62.0MB/s]\n",
      "Downloading:  70%|███████   | 335M/478M [00:05<00:02, 63.1MB/s]\n",
      "Downloading:  67%|██████▋   | 322M/478M [00:05<00:02, 63.5MB/s]\n",
      "Downloading:  69%|██████▉   | 331M/478M [00:05<00:02, 68.5MB/s]\n",
      "Downloading:  70%|███████   | 336M/478M [00:05<00:02, 64.7MB/s]\n",
      "Downloading:  47%|████▋     | 226M/478M [00:05<00:05, 45.1MB/s]\n",
      "Downloading:  72%|███████▏  | 345M/478M [00:05<00:02, 65.2MB/s]\n",
      "Downloading:  69%|██████▉   | 329M/478M [00:05<00:02, 65.4MB/s]\n",
      "Downloading:  73%|███████▎  | 348M/478M [00:05<00:02, 64.7MB/s]\n",
      "Downloading:  71%|███████   | 339M/478M [00:05<00:02, 62.8MB/s]\n",
      "Downloading:  71%|███████▏  | 341M/478M [00:05<00:02, 64.2MB/s]\n",
      "Downloading:  69%|██████▊   | 328M/478M [00:05<00:02, 63.6MB/s]\n",
      "Downloading:  71%|███████   | 338M/478M [00:05<00:02, 68.7MB/s]\n",
      "Downloading:  72%|███████▏  | 343M/478M [00:05<00:02, 64.9MB/s]\n",
      "Downloading:  48%|████▊     | 232M/478M [00:05<00:05, 49.0MB/s]\n",
      "Downloading:  74%|███████▎  | 351M/478M [00:05<00:02, 64.7MB/s]\n",
      "Downloading:  70%|███████   | 335M/478M [00:05<00:02, 65.8MB/s]\n",
      "Downloading:  74%|███████▍  | 354M/478M [00:05<00:02, 64.7MB/s]\n",
      "Downloading:  72%|███████▏  | 345M/478M [00:05<00:02, 63.1MB/s]\n",
      "Downloading:  74%|███████▎  | 351M/478M [00:05<00:02, 63.5MB/s]\n",
      "Downloading:  73%|███████▎  | 348M/478M [00:05<00:02, 64.9MB/s]\n",
      "Downloading:  70%|██████▉   | 334M/478M [00:05<00:02, 63.5MB/s]\n",
      "Downloading:  72%|███████▏  | 345M/478M [00:05<00:02, 68.7MB/s]\n",
      "Downloading:  73%|███████▎  | 349M/478M [00:05<00:02, 65.0MB/s]\n",
      "Downloading:  75%|███████▍  | 358M/478M [00:05<00:01, 64.9MB/s]\n",
      "Downloading:  71%|███████▏  | 342M/478M [00:05<00:02, 65.6MB/s]\n",
      "Downloading:  75%|███████▌  | 360M/478M [00:05<00:01, 64.8MB/s]\n",
      "Downloading:  75%|███████▍  | 357M/478M [00:05<00:01, 63.7MB/s]\n",
      "Downloading:  74%|███████▍  | 354M/478M [00:05<00:01, 65.4MB/s]\n",
      "Downloading:  75%|███████▌  | 361M/478M [00:05<00:01, 65.9MB/s]\n",
      "Downloading:  71%|███████   | 340M/478M [00:05<00:02, 63.6MB/s]\n",
      "Downloading:  73%|███████▎  | 351M/478M [00:05<00:01, 69.0MB/s]\n",
      "Downloading:  74%|███████▍  | 355M/478M [00:05<00:01, 65.2MB/s]\n",
      "Downloading:  50%|████▉     | 237M/478M [00:05<00:05, 46.6MB/s]\n",
      "Downloading:  76%|███████▌  | 364M/478M [00:05<00:01, 64.9MB/s]\n",
      "Downloading:  73%|███████▎  | 348M/478M [00:06<00:02, 65.9MB/s]\n",
      "Downloading:  77%|███████▋  | 367M/478M [00:05<00:01, 64.9MB/s]\n",
      "Downloading:  76%|███████▌  | 364M/478M [00:05<00:01, 63.9MB/s]\n",
      "Downloading:  77%|███████▋  | 367M/478M [00:06<00:01, 66.2MB/s]\n",
      "Downloading:  72%|███████▏  | 346M/478M [00:05<00:02, 63.6MB/s]\n",
      "Downloading:  75%|███████▍  | 358M/478M [00:06<00:01, 68.9MB/s]\n",
      "Downloading:  76%|███████▌  | 361M/478M [00:05<00:01, 65.3MB/s]\n",
      "Downloading:  51%|█████     | 242M/478M [00:05<00:05, 48.2MB/s]\n",
      "Downloading:  77%|███████▋  | 370M/478M [00:06<00:01, 64.9MB/s]\n",
      "Downloading:  74%|███████▍  | 354M/478M [00:06<00:01, 66.2MB/s]\n",
      "Downloading:  78%|███████▊  | 373M/478M [00:06<00:01, 64.8MB/s]\n",
      "Downloading:  77%|███████▋  | 370M/478M [00:06<00:01, 64.0MB/s]\n",
      "Downloading:  78%|███████▊  | 373M/478M [00:06<00:01, 66.4MB/s]\n",
      "Downloading:  76%|███████▌  | 364M/478M [00:06<00:01, 67.8MB/s]\n",
      "Downloading:  74%|███████▎  | 352M/478M [00:06<00:02, 63.3MB/s]\n",
      "Downloading:  77%|███████▋  | 368M/478M [00:06<00:01, 65.3MB/s]\n",
      "Downloading:  52%|█████▏    | 247M/478M [00:06<00:05, 42.2MB/s]\n",
      "Downloading:  79%|███████▊  | 376M/478M [00:06<00:01, 64.6MB/s]\n",
      "Downloading:  75%|███████▌  | 361M/478M [00:06<00:01, 66.4MB/s]\n",
      "Downloading:  79%|███████▉  | 379M/478M [00:06<00:01, 64.8MB/s]\n",
      "Downloading:  79%|███████▊  | 376M/478M [00:06<00:01, 64.3MB/s]\n",
      "Downloading:  79%|███████▉  | 380M/478M [00:06<00:01, 66.4MB/s]\n",
      "Downloading:  78%|███████▊  | 371M/478M [00:06<00:01, 68.0MB/s]\n",
      "Downloading:  75%|███████▌  | 359M/478M [00:06<00:01, 63.5MB/s]\n",
      "Downloading:  78%|███████▊  | 374M/478M [00:06<00:01, 64.7MB/s]\n",
      "Downloading:  53%|█████▎    | 252M/478M [00:06<00:05, 46.1MB/s]\n",
      "Downloading:  80%|███████▉  | 382M/478M [00:06<00:01, 64.7MB/s]\n",
      "Downloading:  77%|███████▋  | 367M/478M [00:06<00:01, 66.7MB/s]\n",
      "Downloading:  81%|████████  | 385M/478M [00:06<00:01, 64.9MB/s]\n",
      "Downloading:  80%|███████▉  | 382M/478M [00:06<00:01, 64.7MB/s]\n",
      "Downloading:  81%|████████  | 386M/478M [00:06<00:01, 66.6MB/s]\n",
      "Downloading:  79%|███████▉  | 377M/478M [00:06<00:01, 67.6MB/s]\n",
      "Downloading:  76%|███████▋  | 365M/478M [00:06<00:01, 63.7MB/s]\n",
      "Downloading:  80%|███████▉  | 380M/478M [00:06<00:01, 65.0MB/s]\n",
      "Downloading:  54%|█████▍    | 258M/478M [00:06<00:04, 50.2MB/s]\n",
      "Downloading:  81%|████████▏ | 389M/478M [00:06<00:01, 64.7MB/s]\n",
      "Downloading:  78%|███████▊  | 374M/478M [00:06<00:01, 66.8MB/s]\n",
      "Downloading:  82%|████████▏ | 391M/478M [00:06<00:01, 64.8MB/s]\n",
      "Downloading:  81%|████████▏ | 388M/478M [00:06<00:01, 64.2MB/s]\n",
      "Downloading:  82%|████████▏ | 392M/478M [00:06<00:01, 66.1MB/s]\n",
      "Downloading:  80%|████████  | 384M/478M [00:06<00:01, 68.1MB/s]\n",
      "Downloading:  81%|████████  | 386M/478M [00:06<00:01, 65.1MB/s]\n",
      "Downloading:  78%|███████▊  | 371M/478M [00:06<00:01, 63.7MB/s]\n",
      "Downloading:  55%|█████▌    | 263M/478M [00:06<00:04, 50.9MB/s]\n",
      "Downloading:  83%|████████▎ | 395M/478M [00:06<00:01, 64.7MB/s]\n",
      "Downloading:  83%|████████▎ | 398M/478M [00:06<00:01, 64.7MB/s]\n",
      "Downloading:  83%|████████▎ | 399M/478M [00:06<00:01, 66.1MB/s]\n",
      "Downloading:  82%|████████▏ | 390M/478M [00:06<00:01, 68.2MB/s]\n",
      "Downloading:  83%|████████▎ | 399M/478M [00:06<00:01, 64.8MB/s]\n",
      "Downloading:  56%|█████▌    | 268M/478M [00:06<00:04, 50.4MB/s]\n",
      "Downloading:  79%|███████▉  | 377M/478M [00:06<00:01, 63.7MB/s]\n",
      "Downloading:  84%|████████▍ | 401M/478M [00:06<00:01, 64.6MB/s]\n",
      "Downloading:  79%|███████▉  | 380M/478M [00:06<00:01, 60.8MB/s]\n",
      "Downloading:  84%|████████▍ | 404M/478M [00:06<00:01, 64.0MB/s]\n",
      "Downloading:  83%|████████▎ | 395M/478M [00:06<00:01, 54.8MB/s]\n",
      "Downloading:  85%|████████▍ | 405M/478M [00:06<00:01, 66.3MB/s]\n",
      "Downloading:  83%|████████▎ | 397M/478M [00:06<00:01, 68.3MB/s]\n",
      "Downloading:  85%|████████▍ | 405M/478M [00:06<00:01, 65.0MB/s]\n",
      "Downloading:  57%|█████▋    | 274M/478M [00:06<00:04, 53.0MB/s]\n",
      "Downloading:  80%|████████  | 383M/478M [00:06<00:01, 62.9MB/s]\n",
      "Downloading:  85%|████████▌ | 407M/478M [00:06<00:01, 64.7MB/s]\n",
      "Downloading:  81%|████████  | 386M/478M [00:06<00:01, 62.0MB/s]\n",
      "Downloading:  86%|████████▌ | 410M/478M [00:06<00:01, 64.0MB/s]\n",
      "Downloading:  86%|████████▌ | 411M/478M [00:06<00:01, 66.5MB/s]\n",
      "Downloading:  84%|████████▍ | 404M/478M [00:06<00:01, 68.5MB/s]\n",
      "Downloading:  86%|████████▌ | 411M/478M [00:06<00:01, 65.1MB/s]\n",
      "Downloading:  58%|█████▊    | 279M/478M [00:06<00:03, 52.9MB/s]\n",
      "Downloading:  81%|████████▏ | 389M/478M [00:06<00:01, 63.0MB/s]\n",
      "Downloading:  86%|████████▋ | 413M/478M [00:06<00:01, 64.8MB/s]\n",
      "Downloading:  82%|████████▏ | 392M/478M [00:06<00:01, 53.7MB/s]\n",
      "Downloading:  87%|████████▋ | 416M/478M [00:06<00:01, 64.2MB/s]\n",
      "Downloading:  84%|████████▎ | 400M/478M [00:06<00:01, 44.7MB/s]\n",
      "Downloading:  87%|████████▋ | 418M/478M [00:06<00:00, 66.6MB/s]\n",
      "Downloading:  86%|████████▌ | 410M/478M [00:06<00:01, 68.5MB/s]\n",
      "Downloading:  87%|████████▋ | 417M/478M [00:06<00:00, 65.2MB/s]\n",
      "Downloading:  59%|█████▉    | 284M/478M [00:06<00:03, 52.1MB/s]\n",
      "Downloading:  83%|████████▎ | 395M/478M [00:06<00:01, 57.4MB/s]\n",
      "Downloading:  88%|████████▊ | 420M/478M [00:06<00:00, 64.8MB/s]\n",
      "Downloading:  83%|████████▎ | 398M/478M [00:06<00:01, 56.2MB/s]\n",
      "Downloading:  88%|████████▊ | 422M/478M [00:06<00:00, 64.3MB/s]\n",
      "Downloading:  85%|████████▍ | 405M/478M [00:06<00:01, 45.8MB/s]\n",
      "Downloading:  89%|████████▊ | 424M/478M [00:06<00:00, 66.7MB/s]\n",
      "Downloading:  87%|████████▋ | 417M/478M [00:06<00:00, 68.8MB/s]\n",
      "Downloading:  89%|████████▊ | 424M/478M [00:06<00:00, 65.3MB/s]\n",
      "Downloading:  89%|████████▉ | 426M/478M [00:06<00:00, 65.0MB/s]\n",
      "Downloading:  84%|████████▍ | 401M/478M [00:06<00:01, 59.0MB/s]\n",
      "Downloading:  85%|████████▍ | 404M/478M [00:07<00:01, 57.8MB/s]\n",
      "Downloading:  90%|████████▉ | 428M/478M [00:06<00:00, 64.6MB/s]\n",
      "Downloading:  86%|████████▌ | 410M/478M [00:06<00:01, 47.2MB/s]\n",
      "Downloading:  90%|█████████ | 431M/478M [00:07<00:00, 66.8MB/s]\n",
      "Downloading:  89%|████████▊ | 423M/478M [00:07<00:00, 68.8MB/s]\n",
      "Downloading:  90%|████████▉ | 430M/478M [00:07<00:00, 65.4MB/s]\n",
      "Downloading:  60%|██████    | 289M/478M [00:06<00:04, 46.2MB/s]\n",
      "Downloading:  90%|█████████ | 432M/478M [00:07<00:00, 65.1MB/s]\n",
      "Downloading:  85%|████████▌ | 407M/478M [00:06<00:01, 59.5MB/s]\n",
      "Downloading:  86%|████████▌ | 410M/478M [00:07<00:01, 60.2MB/s]\n",
      "Downloading:  91%|█████████ | 435M/478M [00:07<00:00, 64.9MB/s]\n",
      "Downloading:  92%|█████████▏| 441M/478M [00:07<00:00, 64.8MB/s]\n",
      "Downloading:  87%|████████▋ | 415M/478M [00:07<00:01, 49.2MB/s]\n",
      "Downloading:  91%|█████████▏| 437M/478M [00:07<00:00, 66.9MB/s]\n",
      "Downloading:  90%|████████▉ | 430M/478M [00:07<00:00, 68.8MB/s]\n",
      "Downloading:  61%|██████▏   | 294M/478M [00:07<00:04, 46.6MB/s]\n",
      "Downloading:  92%|█████████▏| 438M/478M [00:07<00:00, 64.9MB/s]\n",
      "Downloading:  86%|████████▋ | 413M/478M [00:07<00:01, 60.2MB/s]\n",
      "Downloading:  87%|████████▋ | 416M/478M [00:07<00:01, 55.2MB/s]\n",
      "Downloading:  94%|█████████▎| 447M/478M [00:07<00:00, 64.8MB/s]\n",
      "Downloading:  88%|████████▊ | 421M/478M [00:07<00:01, 52.8MB/s]\n",
      "Downloading:  93%|█████████▎| 443M/478M [00:07<00:00, 67.0MB/s]\n",
      "Downloading:  91%|█████████▏| 436M/478M [00:07<00:00, 68.7MB/s]\n",
      "Downloading:  91%|█████████▏| 436M/478M [00:07<00:00, 59.3MB/s]\n",
      "Downloading:  62%|██████▏   | 298M/478M [00:07<00:04, 43.3MB/s]\n",
      "Downloading:  93%|█████████▎| 444M/478M [00:07<00:00, 65.0MB/s]\n",
      "Downloading:  88%|████████▊ | 418M/478M [00:07<00:01, 56.9MB/s]\n",
      "Downloading:  88%|████████▊ | 422M/478M [00:07<00:01, 58.0MB/s]\n",
      "Downloading:  95%|█████████▍| 453M/478M [00:07<00:00, 64.8MB/s]\n",
      "Downloading:  89%|████████▉ | 427M/478M [00:07<00:00, 56.3MB/s]\n",
      "Downloading:  94%|█████████▍| 450M/478M [00:07<00:00, 65.5MB/s]\n",
      "Downloading:  93%|█████████▎| 443M/478M [00:07<00:00, 68.2MB/s]\n",
      "Downloading:  92%|█████████▏| 442M/478M [00:07<00:00, 58.1MB/s]\n",
      "Downloading:  64%|██████▎   | 304M/478M [00:07<00:03, 47.4MB/s]\n",
      "Downloading:  94%|█████████▍| 451M/478M [00:07<00:00, 65.2MB/s]\n",
      "Downloading:  96%|█████████▌| 457M/478M [00:07<00:00, 65.2MB/s]\n",
      "Downloading:  90%|████████▉ | 429M/478M [00:07<00:00, 60.4MB/s]\n",
      "Downloading:  89%|████████▉ | 424M/478M [00:07<00:00, 58.4MB/s]\n",
      "Downloading:  96%|█████████▌| 459M/478M [00:07<00:00, 64.8MB/s]\n",
      "Downloading:  91%|█████████ | 433M/478M [00:07<00:00, 58.7MB/s]\n",
      "Downloading:  95%|█████████▌| 456M/478M [00:07<00:00, 65.3MB/s]\n",
      "Downloading:  94%|█████████▍| 450M/478M [00:07<00:00, 68.4MB/s]\n",
      "Downloading:  94%|█████████▎| 448M/478M [00:07<00:00, 58.0MB/s]\n",
      "Downloading:  97%|█████████▋| 463M/478M [00:07<00:00, 65.3MB/s]\n",
      "Downloading:  91%|█████████ | 435M/478M [00:07<00:00, 62.2MB/s]\n",
      "Downloading:  90%|█████████ | 431M/478M [00:07<00:00, 60.2MB/s]\n",
      "Downloading:  97%|█████████▋| 466M/478M [00:07<00:00, 64.3MB/s]\n",
      "Downloading:  92%|█████████▏| 439M/478M [00:07<00:00, 56.8MB/s]\n",
      "Downloading:  97%|█████████▋| 462M/478M [00:07<00:00, 65.8MB/s]\n",
      "Downloading:  95%|█████████▌| 456M/478M [00:07<00:00, 68.1MB/s]\n",
      "Downloading:  65%|██████▍   | 308M/478M [00:07<00:04, 38.2MB/s]\n",
      "Downloading:  95%|█████████▍| 454M/478M [00:07<00:00, 60.0MB/s]\n",
      "Downloading:  98%|█████████▊| 469M/478M [00:07<00:00, 65.3MB/s]\n",
      "Downloading:  92%|█████████▏| 442M/478M [00:07<00:00, 63.4MB/s]\n",
      "Downloading:  91%|█████████▏| 437M/478M [00:07<00:00, 61.2MB/s]\n",
      "Downloading:  99%|█████████▊| 472M/478M [00:07<00:00, 64.4MB/s]\n",
      "Downloading:  93%|█████████▎| 445M/478M [00:07<00:00, 58.8MB/s]\n",
      "Downloading:  98%|█████████▊| 469M/478M [00:07<00:00, 66.1MB/s]\n",
      "Downloading:  97%|█████████▋| 463M/478M [00:07<00:00, 68.2MB/s]\n",
      "Downloading:  65%|██████▌   | 312M/478M [00:07<00:04, 38.7MB/s]\n",
      "Downloading:  96%|█████████▌| 460M/478M [00:07<00:00, 61.5MB/s]\n",
      "Downloading: 100%|█████████▉| 476M/478M [00:07<00:00, 65.3MB/s]\n",
      "Downloading:  94%|█████████▎| 448M/478M [00:07<00:00, 62.4MB/s]\n",
      "Downloading: 100%|█████████▉| 478M/478M [00:07<00:00, 63.1MB/s]\n",
      "Downloading:  93%|█████████▎| 443M/478M [00:07<00:00, 62.0MB/s]\n",
      "Downloading: 100%|██████████| 478M/478M [00:07<00:00, 64.5MB/s]\n",
      "Downloading:  94%|█████████▍| 452M/478M [00:07<00:00, 61.6MB/s]\n",
      "Downloading:  99%|█████████▉| 475M/478M [00:07<00:00, 66.4MB/s]\n",
      "Downloading:  98%|█████████▊| 469M/478M [00:07<00:00, 68.6MB/s]\n",
      "Downloading:  67%|██████▋   | 318M/478M [00:07<00:03, 44.1MB/s]\n",
      "Downloading:  97%|█████████▋| 466M/478M [00:07<00:00, 60.7MB/s]\n",
      "Downloading: 100%|██████████| 478M/478M [00:07<00:00, 64.5MB/s]\n",
      "Downloading:  95%|█████████▍| 454M/478M [00:07<00:00, 63.1MB/s]\n",
      "Downloading:  94%|█████████▍| 449M/478M [00:07<00:00, 62.8MB/s]\n",
      "Downloading:  96%|█████████▌| 458M/478M [00:07<00:00, 63.8MB/s]\n",
      "Downloading: 100%|██████████| 478M/478M [00:07<00:00, 63.8MB/s]\n",
      "Downloading: 100%|██████████| 478M/478M [00:07<00:00, 63.7MB/s]\n",
      "Downloading:  68%|██████▊   | 324M/478M [00:07<00:03, 48.0MB/s]\n",
      "Downloading:  99%|█████████▊| 472M/478M [00:07<00:00, 61.8MB/s]\n",
      "Downloading:  96%|█████████▋| 460M/478M [00:07<00:00, 64.1MB/s]\n",
      "Downloading:  95%|█████████▌| 455M/478M [00:07<00:00, 63.3MB/s]\n",
      "Downloading:  97%|█████████▋| 465M/478M [00:07<00:00, 65.3MB/s]\n",
      "Downloading:  69%|██████▊   | 329M/478M [00:07<00:03, 46.2MB/s]\n",
      "Downloading: 100%|██████████| 478M/478M [00:07<00:00, 63.5MB/s]\n",
      "Downloading:  98%|█████████▊| 467M/478M [00:08<00:00, 64.8MB/s]\n",
      "Downloading:  96%|█████████▋| 461M/478M [00:07<00:00, 63.5MB/s]\n",
      "Downloading:  99%|█████████▊| 471M/478M [00:07<00:00, 66.3MB/s]\n",
      "Downloading:  70%|██████▉   | 333M/478M [00:08<00:03, 45.6MB/s]\n",
      "Downloading:  99%|█████████▉| 473M/478M [00:08<00:00, 65.2MB/s]\n",
      "Downloading:  98%|█████████▊| 467M/478M [00:08<00:00, 63.3MB/s]\n",
      "Downloading: 100%|██████████| 478M/478M [00:08<00:00, 62.4MB/s]\n",
      "Downloading:  71%|███████   | 338M/478M [00:08<00:03, 41.2MB/s]\n",
      "Downloading: 100%|██████████| 478M/478M [00:08<00:00, 61.1MB/s]\n",
      "Downloading:  72%|███████▏  | 343M/478M [00:08<00:03, 45.2MB/s]\n",
      "Downloading: 100%|██████████| 478M/478M [00:08<00:00, 60.6MB/s]\n",
      "Downloading:  73%|███████▎  | 348M/478M [00:08<00:02, 47.9MB/s]\n",
      "Downloading:  74%|███████▍  | 354M/478M [00:08<00:02, 50.9MB/s]\n",
      "Downloading:  75%|███████▌  | 359M/478M [00:08<00:02, 53.3MB/s]\n",
      "Downloading:  76%|███████▋  | 365M/478M [00:08<00:02, 53.7MB/s]\n",
      "Downloading:  77%|███████▋  | 370M/478M [00:08<00:02, 53.7MB/s]\n",
      "Downloading:  79%|███████▊  | 375M/478M [00:08<00:01, 55.0MB/s]\n",
      "Downloading:  80%|███████▉  | 381M/478M [00:08<00:01, 56.9MB/s]\n",
      "Downloading:  81%|████████  | 387M/478M [00:09<00:01, 53.3MB/s]\n",
      "Running tokenizer on dataset:   0%|          | 0/6 [00:00<?, ?ba/s]\n",
      "Running tokenizer on dataset:   0%|          | 0/6 [00:00<?, ?ba/s]\n",
      "Downloading:  82%|████████▏ | 392M/478M [00:09<00:01, 53.2MB/s]\n",
      "Running tokenizer on dataset:   0%|          | 0/6 [00:00<?, ?ba/s]\n",
      "Running tokenizer on dataset:   0%|          | 0/6 [00:00<?, ?ba/s]\n",
      "Running tokenizer on dataset:  17%|█▋        | 1/6 [00:00<00:00,  8.03ba/s]\n",
      "Running tokenizer on dataset:  17%|█▋        | 1/6 [00:00<00:00,  7.99ba/s]\n",
      "Running tokenizer on dataset:  17%|█▋        | 1/6 [00:00<00:00,  7.40ba/s]\n",
      "Running tokenizer on dataset:   0%|          | 0/6 [00:00<?, ?ba/s]\n",
      "Running tokenizer on dataset:  33%|███▎      | 2/6 [00:00<00:00,  8.51ba/s]\n",
      "Downloading:  83%|████████▎ | 397M/478M [00:09<00:01, 50.5MB/s]\n",
      "Running tokenizer on dataset:  33%|███▎      | 2/6 [00:00<00:00,  8.48ba/s]\n",
      "Running tokenizer on dataset:  33%|███▎      | 2/6 [00:00<00:00,  7.97ba/s]\n",
      "Running tokenizer on dataset:  17%|█▋        | 1/6 [00:00<00:00,  7.97ba/s]\n",
      "Running tokenizer on dataset:  17%|█▋        | 1/6 [00:00<00:00,  7.88ba/s]\n",
      "Running tokenizer on dataset:  50%|█████     | 3/6 [00:00<00:00,  8.69ba/s]\n",
      "Downloading:  84%|████████▍ | 402M/478M [00:09<00:01, 46.8MB/s]\n",
      "Running tokenizer on dataset:  50%|█████     | 3/6 [00:00<00:00,  8.49ba/s]\n",
      "Running tokenizer on dataset:   0%|          | 0/6 [00:00<?, ?ba/s]\n",
      "Running tokenizer on dataset:  50%|█████     | 3/6 [00:00<00:00,  8.25ba/s]\n",
      "Running tokenizer on dataset:  33%|███▎      | 2/6 [00:00<00:00,  8.70ba/s]\n",
      "Running tokenizer on dataset:  33%|███▎      | 2/6 [00:00<00:00,  8.39ba/s]\n",
      "Running tokenizer on dataset:  67%|██████▋   | 4/6 [00:00<00:00,  8.87ba/s]\n",
      "Downloading:  85%|████████▌ | 406M/478M [00:09<00:01, 47.0MB/s]\n",
      "Running tokenizer on dataset:  67%|██████▋   | 4/6 [00:00<00:00,  8.68ba/s]\n",
      "Running tokenizer on dataset:   0%|          | 0/6 [00:00<?, ?ba/s]\n",
      "Running tokenizer on dataset:  17%|█▋        | 1/6 [00:00<00:00,  7.95ba/s]\n",
      "Running tokenizer on dataset:  50%|█████     | 3/6 [00:00<00:00,  8.96ba/s]\n",
      "Running tokenizer on dataset:  50%|█████     | 3/6 [00:00<00:00,  8.51ba/s]\n",
      "Running tokenizer on dataset:  83%|████████▎ | 5/6 [00:00<00:00,  8.96ba/s]\n",
      "Downloading:  86%|████████▌ | 412M/478M [00:09<00:01, 49.5MB/s]\n",
      "Running tokenizer on dataset:   0%|          | 0/6 [00:00<?, ?ba/s]\n",
      "Running tokenizer on dataset:  83%|████████▎ | 5/6 [00:00<00:00,  8.80ba/s]\n",
      "Running tokenizer on dataset:  67%|██████▋   | 4/6 [00:00<00:00,  8.49ba/s]\n",
      "Running tokenizer on dataset:  33%|███▎      | 2/6 [00:00<00:00,  8.41ba/s]\n",
      "Running tokenizer on dataset:  67%|██████▋   | 4/6 [00:00<00:00,  9.03ba/s]\n",
      "Running tokenizer on dataset:  67%|██████▋   | 4/6 [00:00<00:00,  8.72ba/s]\n",
      "Running tokenizer on dataset: 100%|██████████| 6/6 [00:00<00:00,  9.55ba/s]\n",
      "Running tokenizer on dataset:   0%|          | 0/1 [00:00<?, ?ba/s]\n",
      "Downloading:  87%|████████▋ | 417M/478M [00:09<00:01, 49.3MB/s]\n",
      "Running tokenizer on dataset:  17%|█▋        | 1/6 [00:00<00:00,  7.86ba/s]\n",
      "Running tokenizer on dataset: 100%|██████████| 6/6 [00:00<00:00,  9.40ba/s]\n",
      "Running tokenizer on dataset: 100%|██████████| 1/1 [00:00<00:00, 26.21ba/s]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=22616, ip=172.31.21.170)\u001b[0m /tmp/ray/session_2022-06-30_22-56-34_696525_30806/runtime_resources/pip/cd84599724d6bddefa1f21463b30c7087483d3c0/virtualenv/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=22616, ip=172.31.21.170)\u001b[0m   FutureWarning,\n",
      "Running tokenizer on dataset:  17%|█▋        | 1/6 [00:00<00:00,  7.85ba/s]\n",
      "Running tokenizer on dataset: 100%|██████████| 6/6 [00:00<00:00,  9.09ba/s]\n",
      "Running tokenizer on dataset:  50%|█████     | 3/6 [00:00<00:00,  8.56ba/s]\n",
      "Running tokenizer on dataset: 100%|██████████| 6/6 [00:00<00:00,  9.77ba/s]\n",
      "Running tokenizer on dataset:  83%|████████▎ | 5/6 [00:00<00:00,  8.83ba/s]\n",
      "Running tokenizer on dataset: 100%|██████████| 1/1 [00:00<00:00, 26.39ba/s]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=22493, ip=172.31.20.70)\u001b[0m /tmp/ray/session_2022-06-30_22-56-34_696525_30806/runtime_resources/pip/cd84599724d6bddefa1f21463b30c7087483d3c0/virtualenv/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=22493, ip=172.31.20.70)\u001b[0m   FutureWarning,\n",
      "Downloading builder script: 4.21kB [00:00, 3.95MB/s]                   \n",
      "Downloading:  88%|████████▊ | 421M/478M [00:09<00:01, 46.1MB/s]\n",
      "Running tokenizer on dataset:  33%|███▎      | 2/6 [00:00<00:00,  8.43ba/s]\n",
      "Downloading builder script: 4.21kB [00:00, 4.01MB/s]                   \n",
      "  0%|          | 0/100 [00:00<?, ?it/s]=172.31.21.170)\u001b[0m \n",
      "Running tokenizer on dataset:  33%|███▎      | 2/6 [00:00<00:00,  7.94ba/s]\n",
      "Running tokenizer on dataset: 100%|██████████| 1/1 [00:00<00:00, 25.63ba/s]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=22513, ip=172.31.26.121)\u001b[0m /tmp/ray/session_2022-06-30_22-56-34_696525_30806/runtime_resources/pip/cd84599724d6bddefa1f21463b30c7087483d3c0/virtualenv/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=22513, ip=172.31.26.121)\u001b[0m   FutureWarning,\n",
      "Running tokenizer on dataset:  67%|██████▋   | 4/6 [00:00<00:00,  8.66ba/s]\n",
      "Running tokenizer on dataset: 100%|██████████| 1/1 [00:00<00:00, 27.23ba/s]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=22578, ip=172.31.24.251)\u001b[0m /tmp/ray/session_2022-06-30_22-56-34_696525_30806/runtime_resources/pip/cd84599724d6bddefa1f21463b30c7087483d3c0/virtualenv/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=22578, ip=172.31.24.251)\u001b[0m   FutureWarning,\n",
      "Running tokenizer on dataset: 100%|██████████| 6/6 [00:00<00:00,  9.41ba/s]\n",
      "Running tokenizer on dataset:   0%|          | 0/1 [00:00<?, ?ba/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]=172.31.20.70)\u001b[0m \n",
      "Downloading:  89%|████████▉ | 426M/478M [00:09<00:01, 46.5MB/s]\n",
      "Running tokenizer on dataset:  50%|█████     | 3/6 [00:00<00:00,  8.58ba/s]\n",
      "Running tokenizer on dataset:  50%|█████     | 3/6 [00:00<00:00,  8.18ba/s]\n",
      "Downloading builder script: 4.21kB [00:00, 2.89MB/s]                   \n",
      "  0%|          | 0/100 [00:00<?, ?it/s]=172.31.26.121)\u001b[0m \n",
      "Running tokenizer on dataset:  83%|████████▎ | 5/6 [00:00<00:00,  8.68ba/s]\n",
      "Downloading builder script: 4.21kB [00:00, 4.47MB/s]                   \n",
      "  0%|          | 0/100 [00:00<?, ?it/s]=172.31.24.251)\u001b[0m \n",
      "Running tokenizer on dataset: 100%|██████████| 1/1 [00:00<00:00, 25.63ba/s]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=22493, ip=172.31.22.253)\u001b[0m /tmp/ray/session_2022-06-30_22-56-34_696525_30806/runtime_resources/pip/cd84599724d6bddefa1f21463b30c7087483d3c0/virtualenv/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=22493, ip=172.31.22.253)\u001b[0m   FutureWarning,\n",
      "Downloading:  90%|█████████ | 431M/478M [00:10<00:01, 49.0MB/s]\n",
      "Running tokenizer on dataset:  67%|██████▋   | 4/6 [00:00<00:00,  8.67ba/s]\n",
      "Running tokenizer on dataset:  67%|██████▋   | 4/6 [00:00<00:00,  8.21ba/s]\n",
      "Running tokenizer on dataset: 100%|██████████| 6/6 [00:00<00:00,  9.27ba/s]\n",
      "Running tokenizer on dataset:   0%|          | 0/1 [00:00<?, ?ba/s]\n",
      "Downloading builder script: 4.21kB [00:00, 3.78MB/s]                   \n",
      "  0%|          | 0/100 [00:00<?, ?it/s]=172.31.22.253)\u001b[0m \n",
      "Downloading:  91%|█████████ | 436M/478M [00:10<00:00, 48.4MB/s]\n",
      "Running tokenizer on dataset:  83%|████████▎ | 5/6 [00:00<00:00,  8.64ba/s]\n",
      "Running tokenizer on dataset:  83%|████████▎ | 5/6 [00:00<00:00,  8.37ba/s]\n",
      "Running tokenizer on dataset: 100%|██████████| 1/1 [00:00<00:00, 25.79ba/s]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=8825, ip=172.31.25.104)\u001b[0m /usr/local/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=8825, ip=172.31.25.104)\u001b[0m   FutureWarning,\n",
      "Downloading builder script: 4.21kB [00:00, 4.20MB/s]                   \n",
      "Downloading:  92%|█████████▏| 441M/478M [00:10<00:00, 48.7MB/s]\n",
      "Running tokenizer on dataset: 100%|██████████| 6/6 [00:00<00:00,  9.30ba/s]\n",
      "Running tokenizer on dataset:   0%|          | 0/1 [00:00<?, ?ba/s]\n",
      "Running tokenizer on dataset: 100%|██████████| 6/6 [00:00<00:00,  8.85ba/s]\n",
      "Running tokenizer on dataset:   0%|          | 0/1 [00:00<?, ?ba/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]172.31.25.104)\u001b[0m \n",
      "Downloading:  93%|█████████▎| 445M/478M [00:10<00:00, 46.1MB/s]\n",
      "Running tokenizer on dataset: 100%|██████████| 1/1 [00:00<00:00, 25.44ba/s]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=22546, ip=172.31.19.54)\u001b[0m /tmp/ray/session_2022-06-30_22-56-34_696525_30806/runtime_resources/pip/cd84599724d6bddefa1f21463b30c7087483d3c0/virtualenv/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=22546, ip=172.31.19.54)\u001b[0m   FutureWarning,\n",
      "Downloading builder script: 4.21kB [00:00, 4.49MB/s]                   \n",
      "  0%|          | 0/100 [00:00<?, ?it/s]=172.31.19.54)\u001b[0m \n",
      "Running tokenizer on dataset: 100%|██████████| 1/1 [00:00<00:00, 25.11ba/s]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=9374, ip=172.31.26.25)\u001b[0m /usr/local/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=9374, ip=172.31.26.25)\u001b[0m   FutureWarning,\n",
      "Downloading:  94%|█████████▍| 451M/478M [00:10<00:00, 49.2MB/s]\n",
      "Downloading builder script: 4.21kB [00:00, 2.58MB/s]                   \n",
      "  0%|          | 0/100 [00:00<?, ?it/s]172.31.26.25)\u001b[0m \n",
      "Downloading:  95%|█████████▌| 456M/478M [00:10<00:00, 51.2MB/s]\n",
      "Downloading:  96%|█████████▋| 461M/478M [00:10<00:00, 51.2MB/s]\n",
      "Downloading:  97%|█████████▋| 466M/478M [00:10<00:00, 51.6MB/s]\n",
      "Downloading:  99%|█████████▊| 471M/478M [00:10<00:00, 52.9MB/s]\n",
      "Downloading: 100%|██████████| 478M/478M [00:11<00:00, 45.2MB/s]\n",
      "Running tokenizer on dataset:   0%|          | 0/6 [00:00<?, ?ba/s]\n",
      "Running tokenizer on dataset:  17%|█▋        | 1/6 [00:00<00:00,  7.75ba/s]\n",
      "Running tokenizer on dataset:  33%|███▎      | 2/6 [00:00<00:00,  8.48ba/s]\n",
      "Running tokenizer on dataset:  50%|█████     | 3/6 [00:00<00:00,  8.68ba/s]\n",
      "Running tokenizer on dataset:  67%|██████▋   | 4/6 [00:00<00:00,  8.87ba/s]\n",
      "Running tokenizer on dataset: 100%|██████████| 6/6 [00:00<00:00,  9.52ba/s]\n",
      "Running tokenizer on dataset: 100%|██████████| 1/1 [00:00<00:00, 26.56ba/s]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=22499, ip=172.31.26.71)\u001b[0m /tmp/ray/session_2022-06-30_22-56-34_696525_30806/runtime_resources/pip/cd84599724d6bddefa1f21463b30c7087483d3c0/virtualenv/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=22499, ip=172.31.26.71)\u001b[0m   FutureWarning,\n",
      "Downloading builder script: 4.21kB [00:00, 4.16MB/s]                   \n",
      "  0%|          | 0/100 [00:00<?, ?it/s]=172.31.26.71)\u001b[0m \n",
      "  1%|          | 1/100 [00:10<18:05, 10.96s/it]24.251)\u001b[0m \n",
      "  1%|          | 1/100 [00:11<18:21, 11.13s/it]20.70)\u001b[0m \n",
      "  1%|          | 1/100 [00:11<18:21, 11.13s/it]21.170)\u001b[0m \n",
      "  1%|          | 1/100 [00:11<18:29, 11.21s/it]26.121)\u001b[0m \n",
      "  1%|          | 1/100 [00:11<18:20, 11.12s/it]5.104)\u001b[0m \n",
      "  1%|          | 1/100 [00:11<18:36, 11.28s/it]22.253)\u001b[0m \n",
      "  1%|          | 1/100 [00:10<18:07, 10.99s/it]19.54)\u001b[0m \n",
      "  1%|          | 1/100 [00:11<18:39, 11.31s/it]6.25)\u001b[0m \n",
      "  1%|          | 1/100 [00:11<18:18, 11.10s/it]26.71)\u001b[0m \n",
      "  2%|▏         | 2/100 [00:21<17:32, 10.74s/it]24.251)\u001b[0m \n",
      "  2%|▏         | 2/100 [00:21<17:49, 10.91s/it]21.170)\u001b[0m \n",
      "  2%|▏         | 2/100 [00:21<17:36, 10.78s/it]19.54)\u001b[0m \n",
      "  2%|▏         | 2/100 [00:21<17:53, 10.96s/it]26.121)\u001b[0m \n",
      "  2%|▏         | 2/100 [00:22<18:14, 11.17s/it]20.70)\u001b[0m \n",
      "  2%|▏         | 2/100 [00:22<18:12, 11.14s/it]5.104)\u001b[0m \n",
      "  2%|▏         | 2/100 [00:22<18:19, 11.22s/it]22.253)\u001b[0m \n",
      "  2%|▏         | 2/100 [00:22<18:25, 11.28s/it]6.25)\u001b[0m \n",
      "  2%|▏         | 2/100 [00:21<17:46, 10.88s/it]26.71)\u001b[0m \n",
      "  3%|▎         | 3/100 [00:31<16:42, 10.33s/it]24.251)\u001b[0m \n",
      "  3%|▎         | 3/100 [00:31<16:57, 10.49s/it]21.170)\u001b[0m \n",
      "  3%|▎         | 3/100 [00:31<16:49, 10.40s/it]19.54)\u001b[0m \n",
      "  3%|▎         | 3/100 [00:31<16:59, 10.51s/it]26.121)\u001b[0m \n",
      "  3%|▎         | 3/100 [00:32<17:39, 10.92s/it]20.70)\u001b[0m \n",
      "  3%|▎         | 3/100 [00:32<17:34, 10.87s/it]5.104)\u001b[0m \n",
      "  3%|▎         | 3/100 [00:33<17:43, 10.96s/it]22.253)\u001b[0m \n",
      "  3%|▎         | 3/100 [00:33<17:46, 10.99s/it]6.25)\u001b[0m \n",
      "  3%|▎         | 3/100 [00:31<16:56, 10.47s/it]26.71)\u001b[0m \n",
      "  4%|▍         | 4/100 [00:41<16:22, 10.24s/it]24.251)\u001b[0m \n",
      "  4%|▍         | 4/100 [00:41<16:32, 10.34s/it]21.170)\u001b[0m \n",
      "  4%|▍         | 4/100 [00:41<16:27, 10.29s/it]19.54)\u001b[0m \n",
      "  4%|▍         | 4/100 [00:42<16:54, 10.57s/it]26.121)\u001b[0m \n",
      "  4%|▍         | 4/100 [00:43<16:56, 10.59s/it]20.70)\u001b[0m \n",
      "  4%|▍         | 4/100 [00:42<16:50, 10.53s/it]5.104)\u001b[0m \n",
      "  4%|▍         | 4/100 [00:43<16:58, 10.61s/it]22.253)\u001b[0m \n",
      "  4%|▍         | 4/100 [00:43<17:00, 10.63s/it]6.25)\u001b[0m \n",
      "  4%|▍         | 4/100 [00:41<16:33, 10.35s/it]26.71)\u001b[0m \n",
      "  5%|▌         | 5/100 [00:51<16:01, 10.12s/it]24.251)\u001b[0m \n",
      "  5%|▌         | 5/100 [00:51<16:06, 10.18s/it]21.170)\u001b[0m \n",
      "  5%|▌         | 5/100 [00:51<16:05, 10.16s/it]19.54)\u001b[0m \n",
      "  5%|▌         | 5/100 [00:52<16:24, 10.37s/it]26.121)\u001b[0m \n",
      "  5%|▌         | 5/100 [00:53<16:24, 10.37s/it]20.70)\u001b[0m \n",
      "  5%|▌         | 5/100 [00:52<16:22, 10.34s/it]5.104)\u001b[0m \n",
      "  5%|▌         | 5/100 [00:53<16:30, 10.42s/it]22.253)\u001b[0m \n",
      "  5%|▌         | 5/100 [00:53<16:31, 10.44s/it]6.25)\u001b[0m \n",
      "  5%|▌         | 5/100 [00:51<16:08, 10.19s/it]26.71)\u001b[0m \n",
      "  6%|▌         | 6/100 [01:01<15:47, 10.08s/it]24.251)\u001b[0m \n",
      "  6%|▌         | 6/100 [01:01<15:49, 10.10s/it]21.170)\u001b[0m \n",
      "  6%|▌         | 6/100 [01:01<15:52, 10.13s/it]19.54)\u001b[0m \n",
      "  6%|▌         | 6/100 [01:02<16:10, 10.32s/it]26.121)\u001b[0m \n",
      "  6%|▌         | 6/100 [01:03<16:04, 10.26s/it]20.70)\u001b[0m \n",
      "  6%|▌         | 6/100 [01:02<15:59, 10.20s/it]5.104)\u001b[0m \n",
      "  6%|▌         | 6/100 [01:03<16:09, 10.31s/it]22.253)\u001b[0m \n",
      "  6%|▌         | 6/100 [01:03<16:09, 10.32s/it]6.25)\u001b[0m \n",
      "  6%|▌         | 6/100 [01:01<15:52, 10.13s/it]26.71)\u001b[0m \n",
      "  7%|▋         | 7/100 [01:11<15:31, 10.02s/it]24.251)\u001b[0m \n",
      "  7%|▋         | 7/100 [01:11<15:33, 10.04s/it]21.170)\u001b[0m \n",
      "  7%|▋         | 7/100 [01:11<15:34, 10.05s/it]19.54)\u001b[0m \n",
      "  7%|▋         | 7/100 [01:12<15:49, 10.21s/it]26.121)\u001b[0m \n",
      "  7%|▋         | 7/100 [01:12<15:41, 10.12s/it]5.104)\u001b[0m \n",
      "  7%|▋         | 7/100 [01:13<15:47, 10.19s/it]20.70)\u001b[0m \n",
      "  7%|▋         | 7/100 [01:13<15:50, 10.22s/it]22.253)\u001b[0m \n",
      "  7%|▋         | 7/100 [01:13<15:50, 10.22s/it]6.25)\u001b[0m \n",
      "  7%|▋         | 7/100 [01:11<15:37, 10.08s/it]26.71)\u001b[0m \n",
      "  8%|▊         | 8/100 [01:21<15:21, 10.02s/it]24.251)\u001b[0m \n",
      "  8%|▊         | 8/100 [01:21<15:20, 10.00s/it]21.170)\u001b[0m \n",
      "  8%|▊         | 8/100 [01:21<15:17,  9.98s/it]19.54)\u001b[0m \n",
      "  8%|▊         | 8/100 [01:22<15:33, 10.15s/it]26.121)\u001b[0m \n",
      "  8%|▊         | 8/100 [01:22<15:26, 10.08s/it]5.104)\u001b[0m \n",
      "  8%|▊         | 8/100 [01:23<15:33, 10.15s/it]20.70)\u001b[0m \n",
      "  8%|▊         | 8/100 [01:23<15:35, 10.16s/it]22.253)\u001b[0m \n",
      "  8%|▊         | 8/100 [01:23<15:33, 10.15s/it]6.25)\u001b[0m \n",
      "  8%|▊         | 8/100 [01:21<15:24, 10.05s/it]26.71)\u001b[0m \n",
      "  9%|▉         | 9/100 [01:31<15:06,  9.97s/it]24.251)\u001b[0m \n",
      "  9%|▉         | 9/100 [01:31<15:05,  9.95s/it]21.170)\u001b[0m \n",
      "  9%|▉         | 9/100 [01:31<15:04,  9.94s/it]19.54)\u001b[0m \n",
      "  9%|▉         | 9/100 [01:32<15:18, 10.09s/it]26.121)\u001b[0m \n",
      "  9%|▉         | 9/100 [01:33<15:19, 10.10s/it]20.70)\u001b[0m \n",
      "  9%|▉         | 9/100 [01:32<15:16, 10.07s/it]5.104)\u001b[0m \n",
      "  9%|▉         | 9/100 [01:33<15:20, 10.12s/it]22.253)\u001b[0m \n",
      "  9%|▉         | 9/100 [01:33<15:20, 10.12s/it]6.25)\u001b[0m \n",
      "  9%|▉         | 9/100 [01:32<15:26, 10.18s/it]26.71)\u001b[0m \n",
      " 10%|█         | 10/100 [01:40<14:53,  9.93s/it]4.251)\u001b[0m \n",
      " 10%|█         | 10/100 [01:41<14:54,  9.94s/it]1.170)\u001b[0m \n",
      " 10%|█         | 10/100 [01:41<14:52,  9.92s/it]9.54)\u001b[0m \n",
      " 10%|█         | 10/100 [01:42<15:06, 10.08s/it]6.121)\u001b[0m \n",
      " 10%|█         | 10/100 [01:43<15:06, 10.07s/it]0.70)\u001b[0m \n",
      " 10%|█         | 10/100 [01:42<15:03, 10.04s/it].104)\u001b[0m \n",
      " 10%|█         | 10/100 [01:43<15:07, 10.08s/it]2.253)\u001b[0m \n",
      " 10%|█         | 10/100 [01:43<15:05, 10.07s/it].25)\u001b[0m \n",
      " 10%|█         | 10/100 [01:42<15:09, 10.10s/it]6.71)\u001b[0m \n",
      " 11%|█         | 11/100 [01:50<14:41,  9.90s/it]4.251)\u001b[0m \n",
      " 11%|█         | 11/100 [01:51<14:43,  9.92s/it]1.170)\u001b[0m \n",
      " 11%|█         | 11/100 [01:51<14:41,  9.91s/it]9.54)\u001b[0m \n",
      " 11%|█         | 11/100 [01:52<14:53, 10.04s/it]6.121)\u001b[0m \n",
      " 11%|█         | 11/100 [01:52<14:51, 10.02s/it].104)\u001b[0m \n",
      " 11%|█         | 11/100 [01:53<14:56, 10.08s/it]2.253)\u001b[0m \n",
      " 11%|█         | 11/100 [01:53<15:11, 10.24s/it]0.70)\u001b[0m \n",
      " 11%|█         | 11/100 [01:53<14:54, 10.05s/it].25)\u001b[0m \n",
      " 11%|█         | 11/100 [01:52<14:54, 10.05s/it]6.71)\u001b[0m \n",
      " 12%|█▏        | 12/100 [02:00<14:29,  9.88s/it]4.251)\u001b[0m \n",
      " 12%|█▏        | 12/100 [02:01<14:30,  9.89s/it]1.170)\u001b[0m \n",
      " 12%|█▏        | 12/100 [02:00<14:31,  9.90s/it]9.54)\u001b[0m \n",
      " 12%|█▏        | 12/100 [02:02<14:41, 10.02s/it].104)\u001b[0m \n",
      " 12%|█▏        | 12/100 [02:02<14:45, 10.06s/it]6.121)\u001b[0m \n",
      " 12%|█▏        | 12/100 [02:03<14:53, 10.15s/it]0.70)\u001b[0m \n",
      " 12%|█▏        | 12/100 [02:03<14:43, 10.03s/it].25)\u001b[0m \n",
      " 12%|█▏        | 12/100 [02:04<15:00, 10.23s/it]2.253)\u001b[0m \n",
      " 12%|█▏        | 12/100 [02:02<14:42, 10.03s/it]6.71)\u001b[0m \n",
      " 13%|█▎        | 13/100 [02:10<14:17,  9.86s/it]4.251)\u001b[0m \n",
      " 13%|█▎        | 13/100 [02:10<14:19,  9.88s/it]1.170)\u001b[0m \n",
      " 13%|█▎        | 13/100 [02:10<14:21,  9.90s/it]9.54)\u001b[0m \n",
      " 13%|█▎        | 13/100 [02:12<14:33, 10.05s/it]6.121)\u001b[0m \n",
      " 13%|█▎        | 13/100 [02:12<14:32, 10.02s/it].104)\u001b[0m \n",
      " 13%|█▎        | 13/100 [02:13<14:37, 10.09s/it]0.70)\u001b[0m \n",
      " 13%|█▎        | 13/100 [02:13<14:31, 10.02s/it].25)\u001b[0m \n",
      " 13%|█▎        | 13/100 [02:14<14:43, 10.15s/it]2.253)\u001b[0m \n",
      " 13%|█▎        | 13/100 [02:12<14:30, 10.00s/it]6.71)\u001b[0m \n",
      " 14%|█▍        | 14/100 [02:20<14:06,  9.85s/it]4.251)\u001b[0m \n",
      " 14%|█▍        | 14/100 [02:20<14:10,  9.89s/it]1.170)\u001b[0m \n",
      " 14%|█▍        | 14/100 [02:20<14:12,  9.92s/it]9.54)\u001b[0m \n",
      " 14%|█▍        | 14/100 [02:22<14:20, 10.00s/it].104)\u001b[0m \n",
      " 14%|█▍        | 14/100 [02:23<14:28, 10.10s/it]6.121)\u001b[0m \n",
      " 14%|█▍        | 14/100 [02:23<14:24, 10.05s/it]0.70)\u001b[0m \n",
      " 14%|█▍        | 14/100 [02:23<14:21, 10.02s/it].25)\u001b[0m \n",
      " 14%|█▍        | 14/100 [02:24<14:29, 10.11s/it]2.253)\u001b[0m \n",
      " 14%|█▍        | 14/100 [02:22<14:20, 10.00s/it]6.71)\u001b[0m \n",
      " 15%|█▌        | 15/100 [02:30<13:56,  9.84s/it]4.251)\u001b[0m \n",
      " 15%|█▌        | 15/100 [02:30<13:59,  9.87s/it]1.170)\u001b[0m \n",
      " 15%|█▌        | 15/100 [02:30<14:03,  9.92s/it]9.54)\u001b[0m \n",
      " 15%|█▌        | 15/100 [02:32<14:08,  9.98s/it].104)\u001b[0m \n",
      " 15%|█▌        | 15/100 [02:33<14:19, 10.11s/it]6.121)\u001b[0m \n",
      " 15%|█▌        | 15/100 [02:33<14:11, 10.02s/it]0.70)\u001b[0m \n",
      " 15%|█▌        | 15/100 [02:33<14:10, 10.01s/it].25)\u001b[0m \n",
      " 15%|█▌        | 15/100 [02:34<14:17, 10.09s/it]2.253)\u001b[0m \n",
      " 15%|█▌        | 15/100 [02:32<14:08,  9.98s/it]6.71)\u001b[0m \n",
      " 16%|█▌        | 16/100 [02:40<13:48,  9.86s/it]4.251)\u001b[0m \n",
      " 16%|█▌        | 16/100 [02:40<13:50,  9.89s/it]1.170)\u001b[0m \n",
      " 16%|█▌        | 16/100 [02:40<13:52,  9.91s/it]9.54)\u001b[0m \n",
      " 16%|█▌        | 16/100 [02:42<13:56,  9.96s/it].104)\u001b[0m \n",
      " 16%|█▌        | 16/100 [02:43<13:59, 10.00s/it]0.70)\u001b[0m \n",
      " 16%|█▌        | 16/100 [02:43<14:11, 10.13s/it]6.121)\u001b[0m \n",
      " 16%|█▌        | 16/100 [02:43<13:59, 10.00s/it].25)\u001b[0m \n",
      " 16%|█▌        | 16/100 [02:44<14:05, 10.07s/it]2.253)\u001b[0m \n",
      " 16%|█▌        | 16/100 [02:42<14:00, 10.01s/it]6.71)\u001b[0m \n",
      " 17%|█▋        | 17/100 [02:50<13:41,  9.90s/it]4.251)\u001b[0m \n",
      " 17%|█▋        | 17/100 [02:50<13:39,  9.88s/it]1.170)\u001b[0m \n",
      " 17%|█▋        | 17/100 [02:50<13:44,  9.93s/it]9.54)\u001b[0m \n",
      " 17%|█▋        | 17/100 [02:52<13:45,  9.95s/it].104)\u001b[0m \n",
      " 17%|█▋        | 17/100 [02:53<13:49,  9.99s/it]0.70)\u001b[0m \n",
      " 17%|█▋        | 17/100 [02:53<13:58, 10.10s/it]6.121)\u001b[0m \n",
      " 17%|█▋        | 17/100 [02:53<13:49,  9.99s/it].25)\u001b[0m \n",
      " 17%|█▋        | 17/100 [02:54<13:53, 10.04s/it]2.253)\u001b[0m \n",
      " 17%|█▋        | 17/100 [02:52<13:53, 10.04s/it]6.71)\u001b[0m \n",
      " 18%|█▊        | 18/100 [02:59<13:32,  9.91s/it]4.251)\u001b[0m \n",
      " 18%|█▊        | 18/100 [03:00<13:27,  9.85s/it]1.170)\u001b[0m \n",
      " 18%|█▊        | 18/100 [03:00<13:36,  9.95s/it]9.54)\u001b[0m \n",
      " 18%|█▊        | 18/100 [03:02<13:35,  9.94s/it].104)\u001b[0m \n",
      " 18%|█▊        | 18/100 [03:03<13:38,  9.99s/it]0.70)\u001b[0m \n",
      " 18%|█▊        | 18/100 [03:03<13:46, 10.07s/it]6.121)\u001b[0m \n",
      " 18%|█▊        | 18/100 [03:03<13:39, 10.00s/it].25)\u001b[0m \n",
      " 18%|█▊        | 18/100 [03:04<13:43, 10.05s/it]2.253)\u001b[0m \n",
      " 18%|█▊        | 18/100 [03:02<13:45, 10.07s/it]6.71)\u001b[0m \n",
      " 19%|█▉        | 19/100 [03:09<13:23,  9.92s/it]4.251)\u001b[0m \n",
      " 19%|█▉        | 19/100 [03:10<13:17,  9.85s/it]1.170)\u001b[0m \n",
      " 19%|█▉        | 19/100 [03:10<13:24,  9.93s/it]9.54)\u001b[0m \n",
      " 19%|█▉        | 19/100 [03:12<13:26,  9.95s/it].104)\u001b[0m \n",
      " 19%|█▉        | 19/100 [03:13<13:31, 10.02s/it]0.70)\u001b[0m \n",
      " 19%|█▉        | 19/100 [03:13<13:34, 10.05s/it]6.121)\u001b[0m \n",
      " 19%|█▉        | 19/100 [03:13<13:27,  9.96s/it].25)\u001b[0m \n",
      " 19%|█▉        | 19/100 [03:14<13:36, 10.07s/it]2.253)\u001b[0m \n",
      " 19%|█▉        | 19/100 [03:12<13:32, 10.03s/it]6.71)\u001b[0m \n",
      " 20%|██        | 20/100 [03:19<13:07,  9.85s/it]1.170)\u001b[0m \n",
      " 20%|██        | 20/100 [03:19<13:13,  9.92s/it]4.251)\u001b[0m \n",
      " 20%|██        | 20/100 [03:20<13:14,  9.93s/it]9.54)\u001b[0m \n",
      " 20%|██        | 20/100 [03:22<13:17,  9.97s/it].104)\u001b[0m \n",
      " 20%|██        | 20/100 [03:23<13:22, 10.03s/it]6.121)\u001b[0m \n",
      " 20%|██        | 20/100 [03:23<13:23, 10.04s/it]0.70)\u001b[0m \n",
      " 20%|██        | 20/100 [03:23<13:13,  9.92s/it].25)\u001b[0m \n",
      " 20%|██        | 20/100 [03:24<13:28, 10.11s/it]2.253)\u001b[0m \n",
      " 20%|██        | 20/100 [03:22<13:23, 10.05s/it]6.71)\u001b[0m \n",
      " 21%|██        | 21/100 [03:29<12:58,  9.85s/it]1.170)\u001b[0m \n",
      " 21%|██        | 21/100 [03:29<13:03,  9.92s/it]4.251)\u001b[0m \n",
      " 21%|██        | 21/100 [03:30<13:05,  9.94s/it]9.54)\u001b[0m \n",
      " 21%|██        | 21/100 [03:32<13:09,  9.99s/it].104)\u001b[0m \n",
      " 21%|██        | 21/100 [03:32<13:01,  9.89s/it].25)\u001b[0m \n",
      " 21%|██        | 21/100 [03:33<13:10, 10.01s/it]6.121)\u001b[0m \n",
      " 21%|██        | 21/100 [03:33<13:11, 10.01s/it]0.70)\u001b[0m \n",
      " 21%|██        | 21/100 [03:34<13:18, 10.11s/it]2.253)\u001b[0m \n",
      " 21%|██        | 21/100 [03:32<13:11, 10.02s/it]6.71)\u001b[0m \n",
      " 22%|██▏       | 22/100 [03:39<12:52,  9.90s/it]4.251)\u001b[0m \n",
      " 22%|██▏       | 22/100 [03:39<12:51,  9.90s/it]1.170)\u001b[0m \n",
      " 22%|██▏       | 22/100 [03:40<12:53,  9.92s/it]9.54)\u001b[0m \n",
      " 22%|██▏       | 22/100 [03:42<13:00, 10.01s/it].104)\u001b[0m \n",
      " 22%|██▏       | 22/100 [03:42<12:49,  9.87s/it].25)\u001b[0m \n",
      " 22%|██▏       | 22/100 [03:43<13:00, 10.00s/it]6.121)\u001b[0m \n",
      " 22%|██▏       | 22/100 [03:43<12:58,  9.99s/it]0.70)\u001b[0m \n",
      " 22%|██▏       | 22/100 [03:44<13:05, 10.07s/it]2.253)\u001b[0m \n",
      " 22%|██▏       | 22/100 [03:42<13:00, 10.01s/it]6.71)\u001b[0m \n",
      " 23%|██▎       | 23/100 [03:49<12:40,  9.88s/it]4.251)\u001b[0m \n",
      " 23%|██▎       | 23/100 [03:49<12:42,  9.90s/it]1.170)\u001b[0m \n",
      " 23%|██▎       | 23/100 [03:50<12:42,  9.90s/it]9.54)\u001b[0m \n",
      " 23%|██▎       | 23/100 [03:52<12:52, 10.03s/it].104)\u001b[0m \n",
      " 23%|██▎       | 23/100 [03:52<12:38,  9.85s/it].25)\u001b[0m \n",
      " 23%|██▎       | 23/100 [03:53<12:49,  9.99s/it]6.121)\u001b[0m \n",
      " 23%|██▎       | 23/100 [03:53<12:48,  9.98s/it]0.70)\u001b[0m \n",
      " 23%|██▎       | 23/100 [03:54<12:54, 10.06s/it]2.253)\u001b[0m \n",
      " 23%|██▎       | 23/100 [03:52<12:49,  9.99s/it]6.71)\u001b[0m \n",
      " 24%|██▍       | 24/100 [03:59<12:29,  9.86s/it]4.251)\u001b[0m \n",
      " 24%|██▍       | 24/100 [03:59<12:33,  9.91s/it]1.170)\u001b[0m \n",
      " 24%|██▍       | 24/100 [03:59<12:32,  9.91s/it]9.54)\u001b[0m \n",
      " 24%|██▍       | 24/100 [04:02<12:28,  9.84s/it].25)\u001b[0m \n",
      " 24%|██▍       | 24/100 [04:02<12:43, 10.05s/it].104)\u001b[0m \n",
      " 24%|██▍       | 24/100 [04:03<12:37,  9.96s/it]0.70)\u001b[0m \n",
      " 24%|██▍       | 24/100 [04:03<12:38,  9.98s/it]6.121)\u001b[0m \n",
      " 24%|██▍       | 24/100 [04:04<12:44, 10.06s/it]2.253)\u001b[0m \n",
      " 24%|██▍       | 24/100 [04:02<12:38,  9.99s/it]6.71)\u001b[0m \n",
      " 25%|██▌       | 25/100 [04:09<12:18,  9.85s/it]4.251)\u001b[0m \n",
      " 25%|██▌       | 25/100 [04:09<12:23,  9.92s/it]1.170)\u001b[0m \n",
      " 25%|██▌       | 25/100 [04:09<12:21,  9.89s/it]9.54)\u001b[0m \n",
      " 25%|██▌       | 25/100 [04:12<12:18,  9.85s/it].25)\u001b[0m \n",
      " 25%|██▌       | 25/100 [04:12<12:33, 10.05s/it].104)\u001b[0m \n",
      " 25%|██▌       | 25/100 [04:13<12:27,  9.97s/it]0.70)\u001b[0m \n",
      " 25%|██▌       | 25/100 [04:13<12:30, 10.01s/it]6.121)\u001b[0m \n",
      " 25%|██▌       | 25/100 [04:14<12:31, 10.03s/it]2.253)\u001b[0m \n",
      " 25%|██▌       | 25/100 [04:12<12:27,  9.97s/it]6.71)\u001b[0m \n",
      " 26%|██▌       | 26/100 [04:19<12:12,  9.89s/it]1.170)\u001b[0m \n",
      " 26%|██▌       | 26/100 [04:19<12:21, 10.02s/it]4.251)\u001b[0m \n",
      " 26%|██▌       | 26/100 [04:19<12:11,  9.89s/it]9.54)\u001b[0m \n",
      " 26%|██▌       | 26/100 [04:22<12:08,  9.84s/it].25)\u001b[0m \n",
      " 26%|██▌       | 26/100 [04:22<12:24, 10.06s/it].104)\u001b[0m \n",
      " 26%|██▌       | 26/100 [04:23<12:16,  9.96s/it]0.70)\u001b[0m \n",
      " 26%|██▌       | 26/100 [04:23<12:21, 10.02s/it]6.121)\u001b[0m \n",
      " 26%|██▌       | 26/100 [04:24<12:20, 10.01s/it]2.253)\u001b[0m \n",
      " 26%|██▌       | 26/100 [04:22<12:18,  9.98s/it]6.71)\u001b[0m \n",
      " 27%|██▋       | 27/100 [04:29<12:03,  9.91s/it]1.170)\u001b[0m \n",
      " 27%|██▋       | 27/100 [04:29<12:07,  9.96s/it]4.251)\u001b[0m \n",
      " 27%|██▋       | 27/100 [04:29<12:01,  9.88s/it]9.54)\u001b[0m \n",
      " 27%|██▋       | 27/100 [04:31<11:57,  9.83s/it].25)\u001b[0m \n",
      " 27%|██▋       | 27/100 [04:32<12:13, 10.05s/it].104)\u001b[0m \n",
      " 27%|██▋       | 27/100 [04:33<12:06,  9.95s/it]0.70)\u001b[0m \n",
      " 27%|██▋       | 27/100 [04:33<12:11, 10.02s/it]6.121)\u001b[0m \n",
      " 27%|██▋       | 27/100 [04:34<12:10, 10.01s/it]2.253)\u001b[0m \n",
      " 27%|██▋       | 27/100 [04:32<12:08,  9.98s/it]6.71)\u001b[0m \n",
      " 28%|██▊       | 28/100 [04:39<11:53,  9.91s/it]1.170)\u001b[0m \n",
      " 28%|██▊       | 28/100 [04:39<11:55,  9.94s/it]4.251)\u001b[0m \n",
      " 28%|██▊       | 28/100 [04:39<11:49,  9.86s/it]9.54)\u001b[0m \n",
      " 28%|██▊       | 28/100 [04:41<11:46,  9.82s/it].25)\u001b[0m \n",
      " 28%|██▊       | 28/100 [04:42<12:02, 10.03s/it].104)\u001b[0m \n",
      " 28%|██▊       | 28/100 [04:43<11:56,  9.94s/it]0.70)\u001b[0m \n",
      " 28%|██▊       | 28/100 [04:43<12:01, 10.02s/it]6.121)\u001b[0m \n",
      " 28%|██▊       | 28/100 [04:44<12:00, 10.00s/it]2.253)\u001b[0m \n",
      " 28%|██▊       | 28/100 [04:42<11:57,  9.97s/it]6.71)\u001b[0m \n",
      " 29%|██▉       | 29/100 [04:49<11:43,  9.91s/it]4.251)\u001b[0m \n",
      " 29%|██▉       | 29/100 [04:49<11:45,  9.94s/it]1.170)\u001b[0m \n",
      " 29%|██▉       | 29/100 [04:49<11:43,  9.91s/it]9.54)\u001b[0m \n",
      " 29%|██▉       | 29/100 [04:51<11:39,  9.85s/it].25)\u001b[0m \n",
      " 29%|██▉       | 29/100 [04:52<11:53, 10.05s/it].104)\u001b[0m \n",
      " 29%|██▉       | 29/100 [04:53<11:51, 10.02s/it]0.70)\u001b[0m \n",
      " 29%|██▉       | 29/100 [04:53<11:53, 10.05s/it]6.121)\u001b[0m \n",
      " 29%|██▉       | 29/100 [04:54<11:50, 10.00s/it]2.253)\u001b[0m \n",
      " 29%|██▉       | 29/100 [04:52<11:52, 10.04s/it]6.71)\u001b[0m \n",
      " 30%|███       | 30/100 [04:59<11:35,  9.93s/it]1.170)\u001b[0m \n",
      " 30%|███       | 30/100 [04:59<11:40, 10.01s/it]4.251)\u001b[0m \n",
      " 30%|███       | 30/100 [04:59<11:32,  9.89s/it]9.54)\u001b[0m \n",
      " 30%|███       | 30/100 [05:01<11:29,  9.85s/it].25)\u001b[0m \n",
      " 30%|███       | 30/100 [05:03<11:40, 10.01s/it]0.70)\u001b[0m \n",
      " 30%|███       | 30/100 [05:03<11:53, 10.19s/it].104)\u001b[0m \n",
      " 30%|███       | 30/100 [05:03<11:46, 10.09s/it]6.121)\u001b[0m \n",
      " 30%|███       | 30/100 [05:04<11:42, 10.04s/it]2.253)\u001b[0m \n",
      " 30%|███       | 30/100 [05:02<11:41, 10.02s/it]6.71)\u001b[0m \n",
      " 31%|███       | 31/100 [05:09<11:23,  9.91s/it]1.170)\u001b[0m \n",
      " 31%|███       | 31/100 [05:09<11:35, 10.07s/it]4.251)\u001b[0m \n",
      " 31%|███       | 31/100 [05:09<11:25,  9.93s/it]9.54)\u001b[0m \n",
      " 31%|███       | 31/100 [05:11<11:24,  9.92s/it].25)\u001b[0m \n",
      " 31%|███       | 31/100 [05:13<11:36, 10.10s/it]0.70)\u001b[0m \n",
      " 31%|███       | 31/100 [05:13<11:45, 10.23s/it].104)\u001b[0m \n",
      " 31%|███       | 31/100 [05:14<11:46, 10.23s/it]6.121)\u001b[0m \n",
      " 31%|███       | 31/100 [05:14<11:36, 10.09s/it]2.253)\u001b[0m \n",
      " 31%|███       | 31/100 [05:12<11:36, 10.09s/it]6.71)\u001b[0m \n",
      " 32%|███▏      | 32/100 [05:19<11:21, 10.02s/it]1.170)\u001b[0m \n",
      " 32%|███▏      | 32/100 [05:19<11:32, 10.18s/it]4.251)\u001b[0m \n",
      " 32%|███▏      | 32/100 [05:19<11:22, 10.04s/it]9.54)\u001b[0m \n",
      " 32%|███▏      | 32/100 [05:21<11:16,  9.95s/it].25)\u001b[0m \n",
      " 32%|███▏      | 32/100 [05:23<11:27, 10.11s/it]0.70)\u001b[0m \n",
      " 32%|███▏      | 32/100 [05:23<11:33, 10.19s/it].104)\u001b[0m \n",
      " 32%|███▏      | 32/100 [05:24<11:37, 10.26s/it]6.121)\u001b[0m \n",
      " 32%|███▏      | 32/100 [05:25<11:27, 10.10s/it]2.253)\u001b[0m \n",
      " 32%|███▏      | 32/100 [05:22<11:30, 10.15s/it]6.71)\u001b[0m \n",
      " 33%|███▎      | 33/100 [05:30<11:22, 10.18s/it]4.251)\u001b[0m \n",
      " 33%|███▎      | 33/100 [05:30<11:34, 10.36s/it]1.170)\u001b[0m \n",
      " 33%|███▎      | 33/100 [05:30<11:32, 10.34s/it]9.54)\u001b[0m \n",
      " 33%|███▎      | 33/100 [05:31<11:10, 10.01s/it].25)\u001b[0m \n",
      " 33%|███▎      | 33/100 [05:34<11:20, 10.16s/it]0.70)\u001b[0m \n",
      " 33%|███▎      | 33/100 [05:34<11:33, 10.35s/it].104)\u001b[0m \n",
      " 33%|███▎      | 33/100 [05:34<11:27, 10.26s/it]6.121)\u001b[0m \n",
      " 33%|███▎      | 33/100 [05:35<11:19, 10.15s/it]2.253)\u001b[0m \n",
      " 33%|███▎      | 33/100 [05:33<11:21, 10.17s/it]6.71)\u001b[0m \n",
      " 34%|███▍      | 34/100 [05:40<11:11, 10.17s/it]4.251)\u001b[0m \n",
      " 34%|███▍      | 34/100 [05:40<11:17, 10.27s/it]1.170)\u001b[0m \n",
      " 34%|███▍      | 34/100 [05:40<11:16, 10.25s/it]9.54)\u001b[0m \n",
      " 34%|███▍      | 34/100 [05:41<11:00, 10.01s/it].25)\u001b[0m \n",
      " 34%|███▍      | 34/100 [05:44<11:09, 10.14s/it]0.70)\u001b[0m \n",
      " 34%|███▍      | 34/100 [05:45<11:18, 10.28s/it]6.121)\u001b[0m \n",
      " 34%|███▍      | 34/100 [05:45<11:32, 10.49s/it].104)\u001b[0m \n",
      " 34%|███▍      | 34/100 [05:45<11:10, 10.16s/it]2.253)\u001b[0m \n",
      " 34%|███▍      | 34/100 [05:43<11:11, 10.17s/it]6.71)\u001b[0m \n",
      " 35%|███▌      | 35/100 [05:50<11:00, 10.17s/it]4.251)\u001b[0m \n",
      " 35%|███▌      | 35/100 [05:50<11:04, 10.22s/it]1.170)\u001b[0m \n",
      " 35%|███▌      | 35/100 [05:50<11:03, 10.21s/it]9.54)\u001b[0m \n",
      " 35%|███▌      | 35/100 [05:51<10:50, 10.00s/it].25)\u001b[0m \n",
      " 35%|███▌      | 35/100 [05:54<10:58, 10.13s/it]0.70)\u001b[0m \n",
      " 35%|███▌      | 35/100 [05:55<11:05, 10.23s/it]6.121)\u001b[0m \n",
      " 35%|███▌      | 35/100 [05:55<10:58, 10.13s/it]2.253)\u001b[0m \n",
      " 35%|███▌      | 35/100 [05:55<11:18, 10.44s/it].104)\u001b[0m \n",
      " 35%|███▌      | 35/100 [05:53<10:57, 10.12s/it]6.71)\u001b[0m \n",
      " 36%|███▌      | 36/100 [06:00<10:44, 10.06s/it]4.251)\u001b[0m \n",
      " 36%|███▌      | 36/100 [06:00<10:48, 10.13s/it]1.170)\u001b[0m \n",
      " 36%|███▌      | 36/100 [06:00<10:47, 10.11s/it]9.54)\u001b[0m \n",
      " 36%|███▌      | 36/100 [06:01<10:38,  9.98s/it].25)\u001b[0m \n",
      " 36%|███▌      | 36/100 [06:04<10:45, 10.08s/it]0.70)\u001b[0m \n",
      " 36%|███▌      | 36/100 [06:05<10:50, 10.16s/it]6.121)\u001b[0m \n",
      " 36%|███▌      | 36/100 [06:05<10:46, 10.10s/it]2.253)\u001b[0m \n",
      " 36%|███▌      | 36/100 [06:05<10:59, 10.31s/it].104)\u001b[0m \n",
      " 36%|███▌      | 36/100 [06:03<10:44, 10.07s/it]6.71)\u001b[0m \n",
      " 37%|███▋      | 37/100 [06:10<10:29,  9.99s/it]4.251)\u001b[0m \n",
      " 37%|███▋      | 37/100 [06:10<10:32, 10.04s/it]1.170)\u001b[0m \n",
      " 37%|███▋      | 37/100 [06:10<10:33, 10.05s/it]9.54)\u001b[0m \n",
      " 37%|███▋      | 37/100 [06:11<10:27,  9.96s/it].25)\u001b[0m \n",
      " 37%|███▋      | 37/100 [06:14<10:33, 10.06s/it]0.70)\u001b[0m \n",
      " 37%|███▋      | 37/100 [06:15<10:37, 10.12s/it]6.121)\u001b[0m \n",
      " 37%|███▋      | 37/100 [06:15<10:34, 10.07s/it]2.253)\u001b[0m \n",
      " 37%|███▋      | 37/100 [06:15<10:43, 10.22s/it].104)\u001b[0m \n",
      " 37%|███▋      | 37/100 [06:13<10:32, 10.05s/it]6.71)\u001b[0m \n",
      " 38%|███▊      | 38/100 [06:19<10:17,  9.96s/it]4.251)\u001b[0m \n",
      " 38%|███▊      | 38/100 [06:20<10:19,  9.99s/it]1.170)\u001b[0m \n",
      " 38%|███▊      | 38/100 [06:20<10:21, 10.02s/it]9.54)\u001b[0m \n",
      " 38%|███▊      | 38/100 [06:21<10:16,  9.95s/it].25)\u001b[0m \n",
      " 38%|███▊      | 38/100 [06:24<10:23, 10.05s/it]0.70)\u001b[0m \n",
      " 38%|███▊      | 38/100 [06:25<10:24, 10.08s/it]6.121)\u001b[0m \n",
      " 38%|███▊      | 38/100 [06:25<10:23, 10.06s/it]2.253)\u001b[0m \n",
      " 38%|███▊      | 38/100 [06:25<10:32, 10.20s/it].104)\u001b[0m \n",
      " 38%|███▊      | 38/100 [06:23<10:23, 10.06s/it]6.71)\u001b[0m \n",
      " 39%|███▉      | 39/100 [06:29<10:05,  9.92s/it]4.251)\u001b[0m \n",
      " 39%|███▉      | 39/100 [06:30<10:07,  9.95s/it]1.170)\u001b[0m \n",
      " 39%|███▉      | 39/100 [06:30<10:08,  9.98s/it]9.54)\u001b[0m \n",
      " 39%|███▉      | 39/100 [06:31<10:06,  9.94s/it].25)\u001b[0m \n",
      " 39%|███▉      | 39/100 [06:34<10:11, 10.03s/it]0.70)\u001b[0m \n",
      " 39%|███▉      | 39/100 [06:35<10:12, 10.05s/it]6.121)\u001b[0m \n",
      " 39%|███▉      | 39/100 [06:35<10:13, 10.06s/it]2.253)\u001b[0m \n",
      " 39%|███▉      | 39/100 [06:35<10:18, 10.14s/it].104)\u001b[0m \n",
      " 39%|███▉      | 39/100 [06:33<10:12, 10.04s/it]6.71)\u001b[0m \n",
      " 40%|████      | 40/100 [06:39<09:55,  9.92s/it]4.251)\u001b[0m \n",
      " 40%|████      | 40/100 [06:40<09:56,  9.93s/it]1.170)\u001b[0m \n",
      " 40%|████      | 40/100 [06:40<09:56,  9.94s/it]9.54)\u001b[0m \n",
      " 40%|████      | 40/100 [06:41<09:55,  9.93s/it].25)\u001b[0m \n",
      " 40%|████      | 40/100 [06:44<10:00, 10.01s/it]0.70)\u001b[0m \n",
      " 40%|████      | 40/100 [06:45<10:01, 10.03s/it]6.121)\u001b[0m \n",
      " 40%|████      | 40/100 [06:45<10:03, 10.05s/it]2.253)\u001b[0m \n",
      " 40%|████      | 40/100 [06:45<10:06, 10.10s/it].104)\u001b[0m \n",
      " 40%|████      | 40/100 [06:43<10:03, 10.05s/it]6.71)\u001b[0m \n",
      " 41%|████      | 41/100 [06:49<09:43,  9.90s/it]4.251)\u001b[0m \n",
      " 41%|████      | 41/100 [06:49<09:45,  9.92s/it]1.170)\u001b[0m \n",
      " 41%|████      | 41/100 [06:50<09:47,  9.96s/it]9.54)\u001b[0m \n",
      " 41%|████      | 41/100 [06:51<09:45,  9.92s/it].25)\u001b[0m \n",
      " 41%|████      | 41/100 [06:54<09:50, 10.00s/it]0.70)\u001b[0m \n",
      " 41%|████      | 41/100 [06:55<09:50, 10.01s/it]6.121)\u001b[0m \n",
      " 41%|████      | 41/100 [06:55<09:52, 10.05s/it]2.253)\u001b[0m \n",
      " 41%|████      | 41/100 [06:56<09:57, 10.12s/it].104)\u001b[0m \n",
      " 41%|████      | 41/100 [06:53<09:52, 10.04s/it]6.71)\u001b[0m \n",
      " 42%|████▏     | 42/100 [06:59<09:33,  9.89s/it]4.251)\u001b[0m \n",
      " 42%|████▏     | 42/100 [06:59<09:34,  9.91s/it]1.170)\u001b[0m \n",
      " 42%|████▏     | 42/100 [07:00<09:39,  9.98s/it]9.54)\u001b[0m \n",
      " 42%|████▏     | 42/100 [07:01<09:35,  9.92s/it].25)\u001b[0m \n",
      " 42%|████▏     | 42/100 [07:04<09:39,  9.99s/it]0.70)\u001b[0m \n",
      " 42%|████▏     | 42/100 [07:05<09:41, 10.03s/it]6.121)\u001b[0m \n",
      " 42%|████▏     | 42/100 [07:05<09:43, 10.06s/it]2.253)\u001b[0m \n",
      " 42%|████▏     | 42/100 [07:05<09:43, 10.07s/it].104)\u001b[0m \n",
      " 42%|████▏     | 42/100 [07:03<09:40, 10.01s/it]6.71)\u001b[0m \n",
      " 43%|████▎     | 43/100 [07:09<09:23,  9.88s/it]4.251)\u001b[0m \n",
      " 43%|████▎     | 43/100 [07:09<09:25,  9.92s/it]1.170)\u001b[0m \n",
      " 43%|████▎     | 43/100 [07:10<09:28,  9.97s/it]9.54)\u001b[0m \n",
      " 43%|████▎     | 43/100 [07:11<09:25,  9.92s/it].25)\u001b[0m \n",
      " 43%|████▎     | 43/100 [07:14<09:28,  9.97s/it]0.70)\u001b[0m \n",
      " 43%|████▎     | 43/100 [07:15<09:33, 10.06s/it]6.121)\u001b[0m \n",
      " 43%|████▎     | 43/100 [07:15<09:33, 10.06s/it]2.253)\u001b[0m \n",
      " 43%|████▎     | 43/100 [07:16<09:33, 10.06s/it].104)\u001b[0m \n",
      " 43%|████▎     | 43/100 [07:13<09:30, 10.01s/it]6.71)\u001b[0m \n",
      " 44%|████▍     | 44/100 [07:19<09:13,  9.89s/it]4.251)\u001b[0m \n",
      " 44%|████▍     | 44/100 [07:19<09:14,  9.89s/it]1.170)\u001b[0m \n",
      " 44%|████▍     | 44/100 [07:20<09:16,  9.94s/it]9.54)\u001b[0m \n",
      " 44%|████▍     | 44/100 [07:20<09:14,  9.91s/it].25)\u001b[0m \n",
      " 44%|████▍     | 44/100 [07:24<09:17,  9.95s/it]0.70)\u001b[0m \n",
      " 44%|████▍     | 44/100 [07:25<09:22, 10.04s/it]6.121)\u001b[0m \n",
      " 44%|████▍     | 44/100 [07:26<09:23, 10.06s/it]2.253)\u001b[0m \n",
      " 44%|████▍     | 44/100 [07:26<09:21, 10.03s/it].104)\u001b[0m \n",
      " 44%|████▍     | 44/100 [07:23<09:20, 10.00s/it]6.71)\u001b[0m \n",
      " 45%|████▌     | 45/100 [07:29<09:03,  9.88s/it]4.251)\u001b[0m \n",
      " 45%|████▌     | 45/100 [07:29<09:05,  9.91s/it]1.170)\u001b[0m \n",
      " 45%|████▌     | 45/100 [07:30<09:06,  9.93s/it]9.54)\u001b[0m \n",
      " 45%|████▌     | 45/100 [07:30<09:04,  9.90s/it].25)\u001b[0m \n",
      " 45%|████▌     | 45/100 [07:34<09:07,  9.96s/it]0.70)\u001b[0m \n",
      " 45%|████▌     | 45/100 [07:35<09:10, 10.01s/it]6.121)\u001b[0m \n",
      " 45%|████▌     | 45/100 [07:36<09:12, 10.05s/it]2.253)\u001b[0m \n",
      " 45%|████▌     | 45/100 [07:35<09:10, 10.01s/it].104)\u001b[0m \n",
      " 45%|████▌     | 45/100 [07:33<09:11, 10.02s/it]6.71)\u001b[0m \n",
      " 46%|████▌     | 46/100 [07:38<08:53,  9.87s/it]4.251)\u001b[0m \n",
      " 46%|████▌     | 46/100 [07:39<08:54,  9.90s/it]1.170)\u001b[0m \n",
      " 46%|████▌     | 46/100 [07:39<08:55,  9.91s/it]9.54)\u001b[0m \n",
      " 46%|████▌     | 46/100 [07:40<08:56,  9.93s/it].25)\u001b[0m \n",
      " 46%|████▌     | 46/100 [07:44<09:00, 10.01s/it]0.70)\u001b[0m \n",
      " 46%|████▌     | 46/100 [07:45<09:03, 10.06s/it]6.121)\u001b[0m \n",
      " 46%|████▌     | 46/100 [07:46<09:12, 10.23s/it]2.253)\u001b[0m \n",
      " 46%|████▌     | 46/100 [07:43<09:04, 10.08s/it]6.71)\u001b[0m \n",
      " 46%|████▌     | 46/100 [07:46<09:16, 10.30s/it].104)\u001b[0m \n",
      " 47%|████▋     | 47/100 [07:50<08:57, 10.15s/it]1.170)\u001b[0m \n",
      " 47%|████▋     | 47/100 [07:50<09:09, 10.36s/it]4.251)\u001b[0m \n",
      " 47%|████▋     | 47/100 [07:50<09:00, 10.20s/it]9.54)\u001b[0m \n",
      " 47%|████▋     | 47/100 [07:54<09:43, 11.01s/it].25)\u001b[0m \n",
      " 47%|████▋     | 47/100 [07:55<09:12, 10.42s/it]0.70)\u001b[0m \n",
      " 47%|████▋     | 47/100 [07:56<09:05, 10.30s/it]6.121)\u001b[0m \n",
      " 47%|████▋     | 47/100 [07:53<08:56, 10.12s/it]6.71)\u001b[0m \n",
      " 47%|████▋     | 47/100 [07:57<09:15, 10.49s/it]2.253)\u001b[0m \n",
      " 48%|████▊     | 48/100 [08:00<08:43, 10.07s/it]1.170)\u001b[0m \n",
      " 47%|████▋     | 47/100 [07:59<09:44, 11.04s/it].104)\u001b[0m \n",
      " 48%|████▊     | 48/100 [08:00<08:50, 10.21s/it]4.251)\u001b[0m \n",
      " 48%|████▊     | 48/100 [08:00<08:46, 10.13s/it]9.54)\u001b[0m \n",
      " 48%|████▊     | 48/100 [08:04<09:14, 10.67s/it].25)\u001b[0m \n",
      " 48%|████▊     | 48/100 [08:05<08:53, 10.27s/it]0.70)\u001b[0m \n",
      " 48%|████▊     | 48/100 [08:06<08:50, 10.20s/it]6.121)\u001b[0m \n",
      " 48%|████▊     | 48/100 [08:03<08:44, 10.08s/it]6.71)\u001b[0m \n",
      " 48%|████▊     | 48/100 [08:07<08:58, 10.35s/it]2.253)\u001b[0m \n",
      " 49%|████▉     | 49/100 [08:09<08:29, 10.00s/it]1.170)\u001b[0m \n",
      " 48%|████▊     | 48/100 [08:09<09:16, 10.70s/it].104)\u001b[0m \n",
      " 49%|████▉     | 49/100 [08:10<08:35, 10.11s/it]4.251)\u001b[0m \n",
      " 49%|████▉     | 49/100 [08:10<08:31, 10.04s/it]9.54)\u001b[0m \n",
      " 49%|████▉     | 49/100 [08:14<08:52, 10.44s/it].25)\u001b[0m \n",
      " 49%|████▉     | 49/100 [08:15<08:38, 10.17s/it]0.70)\u001b[0m \n",
      " 49%|████▉     | 49/100 [08:16<08:36, 10.12s/it]6.121)\u001b[0m \n",
      " 49%|████▉     | 49/100 [08:13<08:34, 10.09s/it]6.71)\u001b[0m \n",
      " 49%|████▉     | 49/100 [08:17<08:43, 10.27s/it]2.253)\u001b[0m \n",
      " 50%|█████     | 50/100 [08:19<08:17,  9.95s/it]1.170)\u001b[0m \n",
      " 49%|████▉     | 49/100 [08:19<08:53, 10.47s/it].104)\u001b[0m \n",
      " 50%|█████     | 50/100 [08:19<08:21, 10.02s/it]4.251)\u001b[0m \n",
      " 50%|█████     | 50/100 [08:20<08:18,  9.98s/it]9.54)\u001b[0m \n",
      " 50%|█████     | 50/100 [08:24<08:33, 10.28s/it].25)\u001b[0m \n",
      " 50%|█████     | 50/100 [08:25<08:25, 10.10s/it]0.70)\u001b[0m \n",
      " 50%|█████     | 50/100 [08:26<08:23, 10.06s/it]6.121)\u001b[0m \n",
      " 50%|█████     | 50/100 [08:23<08:22, 10.06s/it]6.71)\u001b[0m \n",
      " 50%|█████     | 50/100 [08:27<08:29, 10.19s/it]2.253)\u001b[0m \n",
      " 51%|█████     | 51/100 [08:29<08:06,  9.93s/it]1.170)\u001b[0m \n",
      " 50%|█████     | 50/100 [08:29<08:37, 10.35s/it].104)\u001b[0m \n",
      " 51%|█████     | 51/100 [08:29<08:10, 10.01s/it]4.251)\u001b[0m \n",
      " 51%|█████     | 51/100 [08:30<08:08,  9.97s/it]9.54)\u001b[0m \n",
      " 51%|█████     | 51/100 [08:33<08:18, 10.16s/it].25)\u001b[0m \n",
      " 51%|█████     | 51/100 [08:35<08:12, 10.04s/it]0.70)\u001b[0m \n",
      " 51%|█████     | 51/100 [08:36<08:10, 10.01s/it]6.121)\u001b[0m \n",
      " 51%|█████     | 51/100 [08:33<08:12, 10.04s/it]6.71)\u001b[0m \n",
      " 51%|█████     | 51/100 [08:37<08:16, 10.14s/it]2.253)\u001b[0m \n",
      " 52%|█████▏    | 52/100 [08:39<07:55,  9.90s/it]1.170)\u001b[0m \n",
      " 52%|█████▏    | 52/100 [08:39<07:59, 10.00s/it]4.251)\u001b[0m \n",
      " 51%|█████     | 51/100 [08:39<08:22, 10.26s/it].104)\u001b[0m \n",
      " 52%|█████▏    | 52/100 [08:40<07:57,  9.94s/it]9.54)\u001b[0m \n",
      " 52%|█████▏    | 52/100 [08:43<08:03, 10.07s/it].25)\u001b[0m \n",
      " 52%|█████▏    | 52/100 [08:45<08:00, 10.01s/it]0.70)\u001b[0m \n",
      " 52%|█████▏    | 52/100 [08:46<07:59,  9.99s/it]6.121)\u001b[0m \n",
      " 52%|█████▏    | 52/100 [08:43<08:01, 10.04s/it]6.71)\u001b[0m \n",
      " 52%|█████▏    | 52/100 [08:47<08:05, 10.11s/it]2.253)\u001b[0m \n",
      " 53%|█████▎    | 53/100 [08:49<07:44,  9.88s/it]1.170)\u001b[0m \n",
      " 53%|█████▎    | 53/100 [08:49<07:48,  9.98s/it]4.251)\u001b[0m \n",
      " 52%|█████▏    | 52/100 [08:49<08:09, 10.20s/it].104)\u001b[0m \n",
      " 53%|█████▎    | 53/100 [08:50<07:46,  9.92s/it]9.54)\u001b[0m \n",
      " 53%|█████▎    | 53/100 [08:53<07:50, 10.01s/it].25)\u001b[0m \n",
      " 53%|█████▎    | 53/100 [08:55<07:49,  9.98s/it]0.70)\u001b[0m \n",
      " 53%|█████▎    | 53/100 [08:56<07:48,  9.96s/it]6.121)\u001b[0m \n",
      " 53%|█████▎    | 53/100 [08:53<07:51, 10.03s/it]6.71)\u001b[0m \n",
      " 53%|█████▎    | 53/100 [08:57<07:53, 10.07s/it]2.253)\u001b[0m \n",
      " 54%|█████▍    | 54/100 [08:59<07:34,  9.88s/it]1.170)\u001b[0m \n",
      " 54%|█████▍    | 54/100 [08:59<07:36,  9.93s/it]4.251)\u001b[0m \n",
      " 53%|█████▎    | 53/100 [08:59<07:57, 10.15s/it].104)\u001b[0m \n",
      " 54%|█████▍    | 54/100 [08:59<07:35,  9.90s/it]9.54)\u001b[0m \n",
      " 54%|█████▍    | 54/100 [09:03<07:37,  9.95s/it].25)\u001b[0m \n",
      " 54%|█████▍    | 54/100 [09:05<07:38,  9.97s/it]0.70)\u001b[0m \n",
      " 54%|█████▍    | 54/100 [09:05<07:37,  9.94s/it]6.121)\u001b[0m \n",
      " 54%|█████▍    | 54/100 [09:03<07:40, 10.00s/it]6.71)\u001b[0m \n",
      " 54%|█████▍    | 54/100 [09:07<07:42, 10.05s/it]2.253)\u001b[0m \n",
      " 55%|█████▌    | 55/100 [09:08<07:23,  9.86s/it]1.170)\u001b[0m \n",
      " 55%|█████▌    | 55/100 [09:09<07:25,  9.91s/it]4.251)\u001b[0m \n",
      " 54%|█████▍    | 54/100 [09:09<07:46, 10.13s/it].104)\u001b[0m \n",
      " 55%|█████▌    | 55/100 [09:09<07:24,  9.89s/it]9.54)\u001b[0m \n",
      " 55%|█████▌    | 55/100 [09:13<07:25,  9.90s/it].25)\u001b[0m \n",
      " 55%|█████▌    | 55/100 [09:14<07:27,  9.95s/it]0.70)\u001b[0m \n",
      " 55%|█████▌    | 55/100 [09:15<07:26,  9.93s/it]6.121)\u001b[0m \n",
      " 55%|█████▌    | 55/100 [09:13<07:29,  9.99s/it]6.71)\u001b[0m \n",
      " 55%|█████▌    | 55/100 [09:17<07:30, 10.01s/it]2.253)\u001b[0m \n",
      " 56%|█████▌    | 56/100 [09:18<07:14,  9.87s/it]1.170)\u001b[0m \n",
      " 56%|█████▌    | 56/100 [09:19<07:14,  9.87s/it]4.251)\u001b[0m \n",
      " 56%|█████▌    | 56/100 [09:19<07:14,  9.88s/it]9.54)\u001b[0m \n",
      " 55%|█████▌    | 55/100 [09:19<07:34, 10.11s/it].104)\u001b[0m \n",
      " 56%|█████▌    | 56/100 [09:23<07:14,  9.88s/it].25)\u001b[0m \n",
      " 56%|█████▌    | 56/100 [09:24<07:17,  9.95s/it]0.70)\u001b[0m \n",
      " 56%|█████▌    | 56/100 [09:25<07:16,  9.92s/it]6.121)\u001b[0m \n",
      " 56%|█████▌    | 56/100 [09:23<07:19,  9.99s/it]6.71)\u001b[0m \n",
      " 56%|█████▌    | 56/100 [09:27<07:19,  9.99s/it]2.253)\u001b[0m \n",
      " 57%|█████▋    | 57/100 [09:28<07:05,  9.90s/it]1.170)\u001b[0m \n",
      " 57%|█████▋    | 57/100 [09:29<07:04,  9.88s/it]4.251)\u001b[0m \n",
      " 57%|█████▋    | 57/100 [09:29<07:04,  9.87s/it]9.54)\u001b[0m \n",
      " 56%|█████▌    | 56/100 [09:29<07:24, 10.10s/it].104)\u001b[0m \n",
      " 57%|█████▋    | 57/100 [09:32<07:04,  9.86s/it].25)\u001b[0m \n",
      " 57%|█████▋    | 57/100 [09:34<07:06,  9.93s/it]0.70)\u001b[0m \n",
      " 57%|█████▋    | 57/100 [09:35<07:05,  9.91s/it]6.121)\u001b[0m \n",
      " 57%|█████▋    | 57/100 [09:33<07:09,  9.99s/it]6.71)\u001b[0m \n",
      " 57%|█████▋    | 57/100 [09:37<07:09,  9.99s/it]2.253)\u001b[0m \n",
      " 58%|█████▊    | 58/100 [09:38<06:58,  9.95s/it]1.170)\u001b[0m \n",
      " 58%|█████▊    | 58/100 [09:38<06:54,  9.86s/it]4.251)\u001b[0m \n",
      " 58%|█████▊    | 58/100 [09:39<06:55,  9.89s/it]9.54)\u001b[0m \n",
      " 57%|█████▋    | 57/100 [09:39<07:12, 10.07s/it].104)\u001b[0m \n",
      " 58%|█████▊    | 58/100 [09:42<06:54,  9.86s/it].25)\u001b[0m \n",
      " 58%|█████▊    | 58/100 [09:44<06:57,  9.95s/it]0.70)\u001b[0m \n",
      " 58%|█████▊    | 58/100 [09:45<06:55,  9.90s/it]6.121)\u001b[0m \n",
      " 58%|█████▊    | 58/100 [09:43<06:59,  9.99s/it]6.71)\u001b[0m \n",
      " 58%|█████▊    | 58/100 [09:47<07:00, 10.02s/it]2.253)\u001b[0m \n",
      " 59%|█████▉    | 59/100 [09:48<06:43,  9.85s/it]4.251)\u001b[0m \n",
      " 59%|█████▉    | 59/100 [09:49<06:50, 10.02s/it]1.170)\u001b[0m \n",
      " 59%|█████▉    | 59/100 [09:49<06:46,  9.91s/it]9.54)\u001b[0m \n",
      " 58%|█████▊    | 58/100 [09:49<07:01, 10.04s/it].104)\u001b[0m \n",
      " 59%|█████▉    | 59/100 [09:52<06:45,  9.90s/it].25)\u001b[0m \n",
      " 59%|█████▉    | 59/100 [09:54<06:48,  9.96s/it]0.70)\u001b[0m \n",
      " 59%|█████▉    | 59/100 [09:55<06:46,  9.92s/it]6.121)\u001b[0m \n",
      " 59%|█████▉    | 59/100 [09:53<06:50, 10.01s/it]6.71)\u001b[0m \n",
      " 59%|█████▉    | 59/100 [09:57<06:51, 10.04s/it]2.253)\u001b[0m \n",
      " 60%|██████    | 60/100 [09:58<06:33,  9.85s/it]4.251)\u001b[0m \n",
      " 60%|██████    | 60/100 [09:59<06:42, 10.06s/it]1.170)\u001b[0m \n",
      " 60%|██████    | 60/100 [09:59<06:36,  9.90s/it]9.54)\u001b[0m \n",
      " 59%|█████▉    | 59/100 [09:59<06:50, 10.01s/it].104)\u001b[0m \n",
      " 60%|██████    | 60/100 [10:02<06:35,  9.89s/it].25)\u001b[0m \n",
      " 60%|██████    | 60/100 [10:04<06:37,  9.94s/it]0.70)\u001b[0m \n",
      " 60%|██████    | 60/100 [10:05<06:36,  9.92s/it]6.121)\u001b[0m \n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "\n",
    "ray.shutdown()\n",
    "\n",
    "#\"\"\" Finetuning a 🤗 Transformers model for sequence classification.\"\"\"\n",
    "import argparse\n",
    "import logging\n",
    "import math\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "\n",
    "from typing import Dict, Any\n",
    "import random\n",
    "import torch\n",
    "\n",
    "#import mlflow\n",
    "#mlflow.set_tracking_uri('http://172.31.28.127:5001')\n",
    "\n",
    "import datasets\n",
    "import ray\n",
    "import transformers\n",
    "from accelerate import Accelerator\n",
    "from datasets import load_dataset, load_metric\n",
    "from ray.train import Trainer\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    AutoConfig,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    PretrainedConfig,\n",
    "    SchedulerType,\n",
    "    default_data_collator,\n",
    "    get_scheduler,\n",
    "    set_seed,\n",
    ")\n",
    "from transformers.utils.versions import require_version\n",
    "\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"Finetune a transformers model on a text classification task\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-f\",\n",
    "        type=str,\n",
    "        default=None,\n",
    "        help=\"Ignore this!\",\n",
    "    )    \n",
    "    parser.add_argument(\n",
    "        \"--train_file\",\n",
    "        type=str,\n",
    "        default=\"data/train/part-algo-1-womens_clothing_ecommerce_reviews.csv\",\n",
    "        help=\"A csv or a json file containing the training data.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--validation_file\",\n",
    "        type=str,\n",
    "        default=\"data/validation/part-algo-1-womens_clothing_ecommerce_reviews.csv\",\n",
    "        help=\"A csv or a json file containing the validation data.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--max_length\",\n",
    "        type=int,\n",
    "        default=64,\n",
    "        help=(\n",
    "            \"The maximum total input sequence length after tokenization. \"\n",
    "            \"Sequences longer than this will be truncated, sequences shorter \"\n",
    "            \"will be padded if `--pad_to_max_lengh` is passed.\"\n",
    "        ),\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--pad_to_max_length\",\n",
    "        action=\"store_true\",\n",
    "        help=\"If passed, pad all samples to `max_length`. Otherwise, dynamic \"\n",
    "        \"padding is used.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--model_name_or_path\",\n",
    "        type=str,\n",
    "        help=\"Path to pretrained model or model identifier from \"\n",
    "        \"huggingface.co/models.\",\n",
    "        default=\"roberta-base\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--use_slow_tokenizer\",\n",
    "        action=\"store_true\",\n",
    "        help=\"If passed, will use a slow tokenizer (not backed by the 🤗 \"\n",
    "        \"Tokenizers library).\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--per_device_train_batch_size\",\n",
    "        type=int,\n",
    "        default=32,\n",
    "        help=\"Batch size (per device) for the training dataloader.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--per_device_eval_batch_size\",\n",
    "        type=int,\n",
    "        default=8,\n",
    "        help=\"Batch size (per device) for the evaluation dataloader.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--learning_rate\",\n",
    "        type=float,\n",
    "        default=5e-5,\n",
    "        help=\"Initial learning rate (after the potential warmup period) to use.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--weight_decay\", type=float, default=0.0, help=\"Weight decay to use.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--num_train_epochs\",\n",
    "        type=int,\n",
    "        default=3,\n",
    "        help=\"Total number of training epochs to perform.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--max_train_steps\",\n",
    "        type=int,\n",
    "        default=100,\n",
    "        help=\"Total number of training steps to perform. If provided, \"\n",
    "        \"overrides num_train_epochs.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--gradient_accumulation_steps\",\n",
    "        type=int,\n",
    "        default=1,\n",
    "        help=\"Number of updates steps to accumulate before performing a \"\n",
    "        \"backward/update pass.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--lr_scheduler_type\",\n",
    "        type=SchedulerType,\n",
    "        default=\"linear\",\n",
    "        help=\"The scheduler type to use.\",\n",
    "        choices=[\n",
    "            \"linear\",\n",
    "            \"cosine\",\n",
    "            \"cosine_with_restarts\",\n",
    "            \"polynomial\",\n",
    "            \"constant\",\n",
    "            \"constant_with_warmup\",\n",
    "        ],\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--num_warmup_steps\",\n",
    "        type=int,\n",
    "        default=0,\n",
    "        help=\"Number of steps for the warmup in the lr scheduler.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--output_dir\", type=str, default=None, help=\"Where to store the final model.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--seed\", type=int, default=None, help=\"A seed for reproducible training.\"\n",
    "    )\n",
    "\n",
    "    # Ray arguments.\n",
    "    parser.add_argument(\n",
    "        \"--start_local\", action=\"store_true\", help=\"Starts Ray on local machine.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--address\", \n",
    "        type=str, \n",
    "        default=\"ray://localhost:10001\", \n",
    "        help=\"Ray address to connect to.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--num_workers\", \n",
    "        type=int, \n",
    "        default=10, \n",
    "        help=\"Number of workers to use.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--use_gpu\", action=\"store_true\", help=\"If training should be done on GPUs.\"\n",
    "    )\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Sanity checks\n",
    "    if (\n",
    "#        args.task_name is None\n",
    "        args.train_file is None\n",
    "        and args.validation_file is None\n",
    "    ):\n",
    "        raise ValueError(\"Need a training/validation file.\")\n",
    "    else:\n",
    "        if args.train_file is not None:\n",
    "            extension = args.train_file.split(\".\")[-1]\n",
    "            assert extension in [\n",
    "                \"csv\",\n",
    "                \"json\",\n",
    "            ], \"`train_file` should be a csv or a json file.\"\n",
    "        if args.validation_file is not None:\n",
    "            extension = args.validation_file.split(\".\")[-1]\n",
    "            assert extension in [\n",
    "                \"csv\",\n",
    "                \"json\",\n",
    "            ], \"`validation_file` should be a csv or a json file.\"\n",
    "\n",
    "    if args.output_dir is not None:\n",
    "        os.makedirs(args.output_dir, exist_ok=True)\n",
    "\n",
    "    return args\n",
    "\n",
    "\n",
    "def train_func(config: Dict[str, Any]):\n",
    "    args = config[\"args\"]\n",
    "    # Initialize the accelerator. We will let the accelerator handle device\n",
    "    # placement for us in this example.\n",
    "    accelerator = Accelerator()\n",
    "    # Make one log on every process with the configuration for debugging.\n",
    "    logging.basicConfig(\n",
    "        format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "        level=logging.ERROR,\n",
    "    )\n",
    "    logger.info(accelerator.state)\n",
    "\n",
    "    # Setup logging, we only want one process per machine to log things on\n",
    "    # the screen. accelerator.is_local_main_process is only True for one\n",
    "    # process per machine.\n",
    "    logger.setLevel(\n",
    "        logging.ERROR if accelerator.is_local_main_process else logging.ERROR\n",
    "    )\n",
    "    if accelerator.is_local_main_process:\n",
    "        datasets.utils.logging.set_verbosity_error()\n",
    "        transformers.utils.logging.set_verbosity_error()\n",
    "    else:\n",
    "        datasets.utils.logging.set_verbosity_error()\n",
    "        transformers.utils.logging.set_verbosity_error()\n",
    "\n",
    "    # If passed along, set the training seed now.\n",
    "    if args.seed is not None:\n",
    "        set_seed(args.seed)\n",
    "\n",
    "    # Get the datasets: you can either provide your own CSV/JSON training and\n",
    "    # evaluation files (see below) or specify a GLUE benchmark task (the\n",
    "    # dataset will be downloaded automatically from the datasets Hub).\n",
    "\n",
    "    # For CSV/JSON files, this script will use as labels the column called\n",
    "    # 'label' and as pair of sentences the sentences in columns called\n",
    "    # 'sentence1' and 'sentence2' if such column exists or the first two\n",
    "    # columns not named label if at least two columns are provided.\n",
    "\n",
    "    # If the CSVs/JSONs contain only one non-label column, the script does\n",
    "    # single sentence classification on this single column. You can easily\n",
    "    # tweak this behavior (see below)\n",
    "\n",
    "    # In distributed training, the load_dataset function guarantee that only\n",
    "    # one local process can concurrently download the dataset.\n",
    "#    if args.task_name is not None:\n",
    "#        # Downloading and loading a dataset from the hub.\n",
    "#        raw_datasets = load_dataset(\"glue\", args.task_name)\n",
    "#    else:\n",
    "        # Loading the dataset from local csv or json file.\n",
    "    data_files = {}\n",
    "    if args.train_file is not None:\n",
    "        data_files[\"train\"] = args.train_file\n",
    "    if args.validation_file is not None:\n",
    "        data_files[\"validation\"] = args.validation_file\n",
    "    extension = (\n",
    "        args.train_file if args.train_file is not None else args.valid_file\n",
    "    ).split(\".\")[-1]\n",
    "\n",
    "    raw_datasets = load_dataset(extension, data_files=data_files)\n",
    "\n",
    "    label_list = raw_datasets[\"train\"].unique(\"sentiment\")\n",
    "    label_list.sort()  # Let's sort it for determinism\n",
    "    num_labels = len(label_list)\n",
    "\n",
    "    # Load pretrained model and tokenizer\n",
    "    #\n",
    "    # In distributed training, the .from_pretrained methods guarantee that\n",
    "    # only one local process can concurrently download model & vocab.\n",
    "    config = AutoConfig.from_pretrained(\n",
    "        args.model_name_or_path, num_labels=num_labels, \n",
    "    )\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        args.model_name_or_path, use_fast=not args.use_slow_tokenizer\n",
    "    )\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        args.model_name_or_path,\n",
    "        config=config,\n",
    "    )\n",
    "\n",
    "    # Preprocessing the datasets\n",
    "    sentence1_key, sentence2_key = \"review_body\", None\n",
    "\n",
    "    # Some models have set the order of the labels to use,\n",
    "    # so let's make sure we do use it.\n",
    "    label_to_id = None\n",
    "    label_to_id = {v: i for i, v in enumerate(label_list)}\n",
    "\n",
    "    if label_to_id is not None:\n",
    "        model.config.label2id = label_to_id\n",
    "        model.config.id2label = {id: label for label, id in config.label2id.items()}\n",
    "\n",
    "    padding = \"max_length\" if args.pad_to_max_length else False\n",
    "\n",
    "    def preprocess_function(examples):\n",
    "        # Tokenize the texts\n",
    "        texts = (\n",
    "            (examples[sentence1_key],)\n",
    "            if sentence2_key is None\n",
    "            else (examples[sentence1_key], examples[sentence2_key])\n",
    "        )\n",
    "        result = tokenizer(\n",
    "            *texts, padding=padding, max_length=args.max_length, truncation=True\n",
    "        )\n",
    "\n",
    "        if \"sentiment\" in examples:\n",
    "            if label_to_id is not None:\n",
    "                # Map labels to IDs (not necessary for GLUE tasks)\n",
    "                result[\"labels\"] = [\n",
    "                    label_to_id[l] for l in examples[\"sentiment\"]  # noqa:E741\n",
    "                ]\n",
    "            else:\n",
    "                # In all cases, rename the column to labels because the model\n",
    "                # will expect that.\n",
    "                result[\"labels\"] = examples[\"sentiment\"]\n",
    "\n",
    "        return result\n",
    "\n",
    "    processed_datasets = raw_datasets.map(\n",
    "        preprocess_function,\n",
    "        batched=True,\n",
    "        remove_columns=raw_datasets[\"train\"].column_names,\n",
    "        desc=\"Running tokenizer on dataset\",\n",
    "    )\n",
    "\n",
    "    train_dataset = processed_datasets[\"train\"]\n",
    "    eval_dataset = processed_datasets[\"validation\"]\n",
    "\n",
    "    # Log a few random samples from the training set:\n",
    "    for index in random.sample(range(len(train_dataset)), 3):\n",
    "        logger.info(f\"Sample {index} of the training set: {train_dataset[index]}.\")\n",
    "\n",
    "    # DataLoaders creation:\n",
    "    if args.pad_to_max_length:\n",
    "        # If padding was already done ot max length, we use the default data\n",
    "        # collator that will just convert everything to tensors.\n",
    "        data_collator = default_data_collator\n",
    "    else:\n",
    "        # Otherwise, `DataCollatorWithPadding` will apply dynamic padding for\n",
    "        # us (by padding to the maximum length of the samples passed). When\n",
    "        # using mixed precision, we add `pad_to_multiple_of=8` to pad all\n",
    "        # tensors to multiple of 8s, which will enable the use of Tensor\n",
    "        # Cores on NVIDIA hardware with compute capability >= 7.5 (Volta).\n",
    "        data_collator = DataCollatorWithPadding(\n",
    "            tokenizer, pad_to_multiple_of=(8 if accelerator.use_fp16 else None)\n",
    "        )\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        shuffle=True,\n",
    "        collate_fn=data_collator,\n",
    "        batch_size=args.per_device_train_batch_size,\n",
    "    )\n",
    "    eval_dataloader = DataLoader(\n",
    "        eval_dataset,\n",
    "        collate_fn=data_collator,\n",
    "        batch_size=args.per_device_eval_batch_size,\n",
    "    )\n",
    "\n",
    "    # Optimizer\n",
    "    # Split weights in two groups, one with weight decay and the other not.\n",
    "    no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_grouped_parameters = [\n",
    "        {\n",
    "            \"params\": [\n",
    "                p\n",
    "                for n, p in model.named_parameters()\n",
    "                if not any(nd in n for nd in no_decay)\n",
    "            ],\n",
    "            \"weight_decay\": args.weight_decay,\n",
    "        },\n",
    "        {\n",
    "            \"params\": [\n",
    "                p\n",
    "                for n, p in model.named_parameters()\n",
    "                if any(nd in n for nd in no_decay)\n",
    "            ],\n",
    "            \"weight_decay\": 0.0,\n",
    "        },\n",
    "    ]\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate)\n",
    "\n",
    "    # Prepare everything with our `accelerator`.\n",
    "    model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n",
    "        model, optimizer, train_dataloader, eval_dataloader\n",
    "    )\n",
    "\n",
    "#    model, optimizer, train_dataloader = accelerator.prepare(\n",
    "#        model, optimizer, train_dataloader\n",
    "#    )\n",
    "    # Note -> the training dataloader needs to be prepared before we grab\n",
    "    # his length below (cause its length will be shorter in multiprocess)\n",
    "\n",
    "    # Scheduler and math around the number of training steps.\n",
    "    num_update_steps_per_epoch = math.ceil(\n",
    "        len(train_dataloader) / args.gradient_accumulation_steps\n",
    "    )\n",
    "    if args.max_train_steps is None:\n",
    "        args.max_train_steps = args.num_train_epochs * num_update_steps_per_epoch\n",
    "    else:\n",
    "        args.num_train_epochs = math.ceil(\n",
    "            args.max_train_steps / num_update_steps_per_epoch\n",
    "        )\n",
    "\n",
    "    lr_scheduler = get_scheduler(\n",
    "        name=args.lr_scheduler_type,\n",
    "        optimizer=optimizer,\n",
    "        num_warmup_steps=args.num_warmup_steps,\n",
    "        num_training_steps=args.max_train_steps,\n",
    "    )\n",
    "\n",
    "    # Get the metric function\n",
    "#    if args.task_name is not None:\n",
    "#        metric = load_metric(\"glue\", args.task_name)\n",
    "#    else:\n",
    "    metric = load_metric(\"accuracy\")\n",
    "\n",
    "    # Train!\n",
    "    total_batch_size = (\n",
    "        args.per_device_train_batch_size\n",
    "        * accelerator.num_processes\n",
    "        * args.gradient_accumulation_steps\n",
    "    )\n",
    "\n",
    "    logger.info(\"***** Running training *****\")\n",
    "    logger.info(f\"  Num examples = {len(train_dataset)}\")\n",
    "    logger.info(f\"  Num epochs = {args.num_train_epochs}\")\n",
    "    logger.info(\n",
    "        f\"  Instantaneous batch size per device =\"\n",
    "        f\" {args.per_device_train_batch_size}\"\n",
    "    )\n",
    "    logger.info(\n",
    "        f\"  Total train batch size (w. parallel, distributed & accumulation) \"\n",
    "        f\"= {total_batch_size}\"\n",
    "    )\n",
    "    logger.info(f\"  Gradient Accumulation steps = {args.gradient_accumulation_steps}\")\n",
    "    logger.info(f\"  Total optimization steps = {args.max_train_steps}\")\n",
    "    # Only show the progress bar once on each machine.\n",
    "    progress_bar = tqdm(\n",
    "        range(args.max_train_steps), disable=not accelerator.is_local_main_process\n",
    "    )\n",
    "    completed_steps = 0\n",
    "\n",
    "    for epoch in range(args.num_train_epochs):\n",
    "        model.train()\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "            loss = loss / args.gradient_accumulation_steps\n",
    "            accelerator.backward(loss)\n",
    "            if (\n",
    "                step % args.gradient_accumulation_steps == 0\n",
    "                or step == len(train_dataloader) - 1\n",
    "            ):\n",
    "                optimizer.step()\n",
    "                lr_scheduler.step()\n",
    "                optimizer.zero_grad()\n",
    "                progress_bar.update(1)\n",
    "                completed_steps += 1\n",
    "\n",
    "            if completed_steps >= args.max_train_steps:\n",
    "                break\n",
    "\n",
    "        model.eval()\n",
    "        for step, batch in enumerate(eval_dataloader):\n",
    "            outputs = model(**batch)\n",
    "            predictions = (\n",
    "                outputs.logits.argmax(dim=-1)\n",
    "#                if not is_regression\n",
    "#                else outputs.logits.squeeze()\n",
    "            )\n",
    "            metric.add_batch(\n",
    "                predictions=accelerator.gather(predictions),\n",
    "                references=accelerator.gather(batch[\"labels\"]),\n",
    "            )\n",
    "\n",
    "#         mlflow.log_param(\"use_gpu\", args.use_gpu)\n",
    "#         mlflow.log_param(\"batch_size\", args.per_device_train_batch_size)\n",
    "#         mlflow.log_param(\"learning_rate\", args.learning_rate)\n",
    "#         mlflow.log_param(\"weight_decay\", args.weight_decay)\n",
    "#         mlflow.log_param(\"max_length\", args.max_length)\n",
    "\n",
    "        eval_metric = metric.compute()\n",
    "#        mlflow.log_metric(\"accuracy\", eval_metric['accuracy'])\n",
    "        \n",
    "        logger.info(f\"epoch {epoch}: {eval_metric}\")\n",
    "        print(f\"epoch {epoch}: {eval_metric}\")\n",
    "\n",
    "    if args.output_dir is not None:\n",
    "        accelerator.wait_for_everyone()\n",
    "        unwrapped_model = accelerator.unwrap_model(model)\n",
    "        unwrapped_model.save_pretrained(args.output_dir, save_function=accelerator.save)\n",
    "\n",
    "\n",
    "def main():\n",
    "    args = parse_args()\n",
    "    config = {\"args\": args}\n",
    "    args.use_gpu = False\n",
    "\n",
    "    if args.start_local or args.address or args.num_workers > 1 or args.use_gpu:\n",
    "        if args.start_local:\n",
    "            # Start a local Ray runtime.\n",
    "            ray.init(num_cpus=args.num_workers)\n",
    "        else:\n",
    "            # Connect to a Ray cluster for distributed training.\n",
    "            ray.init(address=\"ray://localhost:10001\",\n",
    "                     runtime_env={\"pip\": [\n",
    "                                            \"torch\", \n",
    "                                            \"scikit-learn\",\n",
    "                                            \"transformers\",\n",
    "                                            \"pandas\",\n",
    "                                            \"datasets\",\n",
    "                                            \"accelerate\",\n",
    "                                            \"scikit-learn\",\n",
    "                                            \"mlflow\", \n",
    "                                            \"tensorboard\"                         \n",
    "                                         ]\n",
    "                                 }\n",
    "                    )\n",
    "            \n",
    "        trainer = Trainer(\"torch\", num_workers=args.num_workers, use_gpu=args.use_gpu,\n",
    "                          resources_per_worker={'CPU': 4, 'GPU': 0})\n",
    "        trainer.start()\n",
    "        trainer.run(train_func, config)\n",
    "    else:\n",
    "        # Run training locally.\n",
    "        train_func(config)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!/emr/notebook-env/bin/ray monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
